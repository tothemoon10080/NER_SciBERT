In this study, a machine vision-based pattern matching technique was applied to estimate the location of an autonomous driving robot and perform 3D tunnel mapping in an underground mine environment. The autonomous driving robot continuously detects the wall of the tunnel in the horizontal direction using the light detection and ranging (LiDAR) sensor and performs pattern matching by recognizing the shape of the tunnel wall. The proposed method was designed to measure the heading of the robot by fusion with the inertial measurement units sensor according to the pattern matching accuracy; it is combined with the encoder sensor to estimate the location of the robot. In addition, when the robot is driving, the vertical direction of the underground mine is scanned through the vertical LiDAR sensor and stacked to create a 3D map of the underground mine. The performance of the proposed method was superior to that of previous studies; the mean absolute error achieved was 0.08 m for the X-Y axes. A root mean square error of 0.05 m2 was achieved by comparing the tunnel section maps that were created by the autonomous driving robot to those of manual surveying.