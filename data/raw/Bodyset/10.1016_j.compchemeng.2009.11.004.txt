Confidence intervals (CIs) are common methods to characterize the uncertain output of experimental measurements, process design calculations and simulations. Usually, probability distributions (pdfs) such as Gaussian and t-Student are used to quantify them. There are situations where the pdfs have anomalous behavior such as heavy tails, which can arise in uncertainty analysis of nonlinear computer models with input parameters subject to different sources of errors. We present a method for the estimation of CIs by analyzing the tails of the pdfs regardless of their nature. We present case studies in which heavy tail behavior appears due to the systematic errors in the input variables of the model. Taking into account the probability distributions behavior to estimate appropriate CIs is a more realistic approach to characterize and analyze the effect of random and systematic errors for uncertainty analysis of computer models.Confidence intervals are widely used to characterize random variables with a given probabilistic confidence. Typical methods of estimating confidence intervals are using standard normal or Student- In this work, we present a simple method to estimate confidence intervals when the probability distribution of output random variables tend to have heavy tail behavior caused by uncertainty in the input parameters of the model. We explore the effect that systematic and random errors have on the inter-quantile range estimation using Monte Carlo simulation with simple case studies. We compare the confidence interval estimation using traditional techniques and the proposed methodology. The results show that the differences can be significant when the nature of the probability distributions deviates in the tails from standard normal or Student- In general, appropriate estimation of confidence intervals is very important to evaluate the robustness of mathematical models and experimental data. It is common to assume that errors are Gaussian, particularly for experimental measurements. The presence of systematic errors can have significant effects, but it is more difficult to evaluate and it is usually not reported even for highly accurate measurements. One can find evidence of systematic errors in measurements by examining experimental data for the same system from different literature sources or by analysis of historical measurements ( Complex nonlinear computer models can induce heavy tail behavior in the output variables. In addition to computer models, there are many other situations such as anomalous diffusion  A classical example of systematic error is the effect that a bias in a calibration procedure would have on experimental measurements. For example, if during the calibration of a thermometer there is a calibration error of half of a degree, all the measurements performed with that instrument will be off by that amount. This is normally called a constant bias or calibration error, and it can be positive or negative. There are situations where the magnitude of the systematic and random errors can be a function of one or more of the measured variables involved As a consequence, procedures to quantify this type of uncertainty and its effects are difficult to find and are restricted mostly to the analysis of According to ANSI/ASME PTC 19.1 ( As mentioned earlier, Understanding how these errors propagate through computer models is important for uncertainty analysis. Analytical approaches are very limited because of the usual nonlinear complexity of engineering models. Current analytical methods are based on error propagation analysis using the Taylor’s series expansion ( A more practical approach is to use Monte Carlo methods ( To estimate confidence intervals of random variables, we need to take into account the probability distribution characteristics. Once the probability density is known, upper confidence bounds for the inter-quantile ranges are easily estimated by applying: The main idea is to characterize the probability distribution tails by using either an exponential or Pareto model. To find out which model is more appropriate one can plot the information on the tails using log–log and semi-log plots (see the densities Once a tail probability model has been chosen, simple linear regression can be used to obtain approximate parameter estimates. A more accurate method is to employ the conditional maximum likelihood estimates developed by For an exponential tail model, it is permissible to apply the above methods along with the relations Upper confidence bounds are easily obtained from the tail probability model once the parameters have been estimated. For Pareto tails the For the exponential model the It is important to point out that the estimators for The methodology used in this work consists of three general steps:  Monte Carlo simulation of random and systematic error effects. Characterization of tails for the cumulative probability distribution of output variables. Estimation of confidence intervals taking into account probability distribution tail characteristics. To analyze random and systematic error effects using Monte Carlo simulation, the approach proposed by An example adapted from The parameters definitions and their values for the ILCR model are given in   To illustrate the application of the confidence interval estimation method proposed, two liquid–liquid extraction cases using the UNIQUAC activity coefficient model The binary interaction parameters of the UNIQUAC model were regressed using an objective function based on the minimization of the distances between experimental and estimated mole fractions, using an inside–variance estimation regression method proposed by This is an example selected from To simulate both random and systematic errors, the first step consists of setting approximate bias limits based on experimental evidence. To do this, we plotted the different experimental data sets describing the equilibrium of the system in The data set of All 1000 random pseudo-data sets were generated including both types of errors following the procedure described above, which are then used to regress all 1000 sets of binary interaction parameters, which are passed through the ASPEN Plus process simulator to calculate the performance of the extraction operation. All 1000 performance evaluations were carried out for each level of systematic error considered. In this case study, 5 levels of systematic uncertainty were analyzed. They are 60%, 80%, 100%, 120%, and 140% of the bias limits defined in Then 99% confidence intervals were calculated for the percentage of acetic acid extracted using the Gaussian normal and exponential models. The results are presented in For this system, an example of a liquid–liquid extraction operation reported by The cumulative probability distributions obtained for the percentage of acetone extracted are presented in The 99% confidence intervals were calculated for the percentage of acetone extracted using the Gaussian normal and exponential models. The results are presented in An approach based on Monte Carlo simulation coupled with heavy and exponential probability tail analysis was presented to estimate confidence intervals under the effect of systematic and random errors on computer models. From the results it is observed that the cumulative probability distribution characteristics can be significantly affected by the error source or type. This suggests that traditional methods for estimating confidence intervals may not be appropriate under the presence of systematic and random errors. It was shown that the use of distribution tail analysis is a robust approach to estimate confidence intervals. For the thermodynamics case studies presented, the approach for confidence intervals estimation is able to resolve problems such as under and over-estimation of inter-quantile ranges present in the Gaussian approach. This is particularly important for cases where the empirical distributions seem very Gaussian (see the liquid–liquid extraction of acetone case). This work was supported, in part, by National Science Foundation grant CTS—96-96192.