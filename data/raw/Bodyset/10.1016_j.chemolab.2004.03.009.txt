Recent literature suggests difficulties calculating the variance of the Fundamental Error using Gy's Sampling Theory, especially for fine materials. There is a mineral grinding explanation, as some minerals of interest, such as gold, chromite, molybdenite, and many others are affected by delayed comminution, which is addressed in the Sampling Theory. Another problem is the contribution, sometimes obscure, of the analytical procedure variance, which may become significant if not effectively estimated and accounted for prior to calculating the Constant Factor of Constitution Heterogeneity. Results from experiments for gold and copper minerals suggest the Analytical Error must be considered in conjunction with Heterogeneity Tests to prevent empirical mixing of variances from different origins. Furthermore, the contribution of the variance of the Grouping and Segregation Error is often vastly underestimated. Solutions are proposed.The calculation of the variance of the Fundamental Error in Dr. Pierre Gy's work has been the object of passionate controversies. The objective of this paper is not to pursue who is wrong and who is right. The objective is to provide information accumulated from many experiments that may add positive arguments to protect the integrity of the Sampling Theory, and to help place recent developments in an appropriate perspective. For the sake of simplicity, it is assumed in this paper that the constituent of interest is gold, and results from only one experiment are presented. The problem encountered by practitioners resides in the experimental determination of the Constant Factor of Constitution Heterogeneity IH Now the question is: How can a meaningful experiment be conducted to accurately estimate parameters        A publication from Assibey-Bonsu Perhaps, it should be emphasized again that the gold-grain top size may have nothing to do with the liberation size that was defined earlier in this document. As a matter of fact, regardless of the size of the coarsest gold particles, as we crush and grind the material finer and finer, the liberation size of the gold may remain elusive as an impossible limit to reach. It is not rare indeed that a substantial amount of gold is so fine that no discrete particles of that gold can be observed under the microscope. Ingamells and Pitard addressed this important problem in various articles and in a textbook A slightly conservative and pragmatic solution can be used. Divide the total amount of gold in two fractions: One fraction could be called the coarse gold, or gold visible under the microscope. This could range from several millimeters to a few microns: On this gold alone identify the sampling characteristics to optimize the sampling protocol. Then, there is the “low background gold content” which is finely disseminated in the ore. For sampling purposes, ignore this easily sampled gold and concentrate attention on the difficult one. Then, redefine the liberation size Many experts favor “interleaving samples” The variance of the Grouping and Segregation Error, The variance of the increment Delimitation Error, The variance of the increment Extraction Error, The variance of the Preparation Errors, The variance of the Weighting Error, and The variance of the Analytical Error. Tests claiming that all these residual errors have been eliminated or made negligible should raise suspicion. Some of them (i.e., Delimitation, Extraction, and Preparation Errors) can be made negligible by following the very stringent rules of sampling correctness listed in the Sampling Theory, but very few people carefully follow these rules in most commercial laboratories. If casual grabbing of increments is made directly inside the bag containing the final pulverized sample, making the wishful thinking assumption the Distribution Heterogeneity is nil, these errors become devastating. Finally, it is unwise to pretend the Grouping and Segregation Error and Analytical Error would be made negligible in these suggested experiments. The statistically correct selection of one increment to make up a sample requires that all parts of the lot have exactly the same chance of being selected. Therefore, the geometrical boundary of an increment must coincide with an isotropic module of observation. Modules are: sphere if the lot is considered a three-dimensional object (e.g., a stockpile), cylinder if the lot is considered a two-dimensional object (e.g., a mining bench), and a complete and uniform slice if the lot is considered a one-dimensional object (e.g., a flowing stream). As a result of omnipresent gravity and transient segregation, any boundary deviation from the ideal module generates a non-constant bias. It is easy to minimize the variance of this error by using properly designed sampling equipment in a sampling protocol. However, there are places where enormous risks are taken, often in the name of practicality (e.g., grab sampling of blastholes, spear sampling of blastholes, scooping directly in the bag of a laboratory pulps to collect the analytical subsample), all considering the lot three-dimensional, which leads to nearly unsolvable sampling problems. Therefore, the primary sampling stage and last sampling stage of the “sample tree experiment” can be misleading if extraordinary precautions are not taken: let us face it, they are not often taken, because of practicality, or because of ignorance. However, it can be done. As the sampling tool contacts the material to be sampled, all material inside the isotropic module of observation, or every fragment with its center of gravity inside that module, must be recovered in the sample, and vice versa. Any deviation from that behavior generally results in an increment recovery loss, or gain. Again, as a result of omnipresent gravity, combined with a sampling device that is poorly designed, built, maintained, cleaned, and used, any deviation from that rule generates a non-constant bias. In the same way as for the Delimitation Error, the primary sampling stage and last sampling stage of the “sample tree experiment” can be misleading if extraordinary precautions are not taken. However, it can be done. Every non-selective process applied to the increment or to the sample, such as crushing, grinding, pulverizing, drying, screening, packaging, transfer of increments, etc. can introduce a loss, a contamination, or an alteration of the physical or chemical integrity of the sample. All complete sampling stages of the “sample tree experiment” can be misleading if extraordinary precautions are not taken. However, it can be done. The Grouping and Segregation Error (GE) is the direct effect of the Distribution Heterogeneity of a lot (DH This new variance is impossible to calculate accurately because the segregation factor When the analyst grabs increments in the final sample bag, the weight of each increment must be constant, relative to a pre-selected sampling ratio. Though the variance of this error may be small, it is certainly not nil. The Analytical Error does not include the last sampling stage consisting of collecting the analytical subsample from the final laboratory pulp sample. However, only if we know exactly what the variance of the Analytical Error is, it becomes impossible to calculate an accurate value of For trace constituents, and gold is often one of them, it is impossible to accurately estimate the sampling parameters leading to the sampling constant Duplicate samples can be collected at each stage of comminution, repeating the procedure until at least 30 pairs are obtained. Then, a variance analysis can sort out the exact variance affecting each sampling stage. This is often referred to as the “sample tree experiment”. A size fraction likely to be the one introducing the largest error in the entire sampling protocol can be investigated (e.g., a 1-cm size fraction for sampling of blasthole cuttings). This procedure should be combined with replicate sampling and assays from all size fractions likely to lead to a subsampling stage. Furthermore, this approach should also be combined with a careful investigation of the exact nature of the coarsest particles after the material is pulverized very fine at the laboratory. This investigation can be performed with a microscope, and conclusions may lead to a necessary correction of the conventional sampling nomograph for the last sampling stages involving very fine material where the coarsest particle of all may be a gold particle. Both approaches have their advantages and disadvantages, and by all means they are far from perfect. However, they are relatively quick and inexpensive, and may provide enough information to prevent gross mistakes in a sampling protocol. Also, if not carried out by a reliable sampling expert, both approaches can be largely misused. Details of this approach have been given to a great extent by D. Francois-Bongarçon In the literature, it is not rare to find a statement like: “Special precautions were taken in the sample tree experiment, so the Grouping and Segregation Error is negligible, and other sampling errors such as Delimitation Error, Extraction Error, and Preparation Errors are nil.” Furthermore, the final, important Analytical Error is often forgotten or calculated in a questionable way using ideal solutions or standard “pellets”. With all due respect to Analytical Chemistry, the behavior of the Analytical Error is far more complex, and also depends on the constantly changing matrix of unknown samples. The author disagrees with such convenient assumptions. Another problem in the “sample tree” approach is the precision of the variance of the Grouping and Segregation Error that can become extremely erratic when gold is liberated in finely ground material. A “sample tree experiment” led to the conclusion that the liberation size of gold was 0.12 cm and the one of copper was 0.23 cm, when well-documented mineral processing requirements led to the conclusion that gold and especially copper do not reach the liberation size unless the ore is ground to 95% −0.025 cm. It is such contradiction that raised the suspicion of the author about the unrecognized effects of residual variance in these experiments. Motives in Gy's Sampling Theory to design experiments by collecting fragments one at a time at random were very clear and clever: It was an effort to prevent the negative effects of residual variances in the calculation of the Constant Factor of Constitution Heterogeneity IH The Fundamental Error (FE) is the direct effect of the Constitution Heterogeneity of a lot (CH The estimation of IH This is the reference formula. It is complete, and carries no assumptions. The estimation of IH Experience shows that the gold content The study of a large number of real cases shows that the proportion Now, IH The calculation of Looking at single fragments. This approach is appropriate for large fragments, like the run off mine material coming out of a primary crusher on a conveyor belt. Collect After substitution and simplification: For the sake of simplicity, only individual large fragments were considered. However, for small fragments, the sample mass involved may not be sufficient. For example, to perform a test on blasthole material, or on material from a reverse circulation drilling machine, or on material delivered by a laboratory jaw crusher, it becomes necessary to collect groups of fragments. Looking at groups of fragments. Prepare 100 groups of If Relative to the tested size fraction, the value assigned to The Ingamells's approach. There is always a danger that the preliminary mineralogical study may not have been carried out in an ideal way, making the choice of How many types of gold mineralization have been identified in the deposit? What is the largest size of the gold particles? Do gold particles cluster? Do some areas show coarse gold with no fine gold around? Is gold associated with quartz veins? Does gold show enrichment along a geological contact, or a major quartz vein contact? Is gold associated with another major mineral (e.g., sulfides, pyrite, spinel, etc.)? Is gold alloyed with another metal? Etc. If there is any doubt, the following test may become necessary to prevent an unfortunate misconception about the heterogeneity of gold in the deposit. Ingamells and Pitard Searching for the largest gold particles in a given type of mineralization, near cutoff grade, and assuming in a first iteration that the gold is liberated, can give an answer to the difficult choice of selecting an appropriate value for In cases where most of the gold reports to size fractions above 80 μm, it is likely that the fine pulverization performed with laboratory mills will liberate the gold. In this category we may also include alluvial gold. By definition the gold is liberated, therefore the shape factor is a function of the density, thus: Develop this relation for the density class Obviously, the first term of the sum is negligible when compared to the second one. Furthermore, If Using this formula, convenient sampling nomographs can be calculated like the one illustrated in Similar derivations could be performed for other minerals of interest, and lead to their own version of In any gold project, it is essential to perform a Heterogeneity Test to calculate sampling nomographs and optimize sampling protocols. The test should be performed on each type of major mineralization or geological unit. A preliminary mineralogical study reveals that the test can be done on a 340-kg composite, using samples from the top size fraction, made of The composite is made of material from 50 different locations within a single type of mineralization. Dry the composite overnight, at 110 °C. After drying, the composite weighs about 340 kg. Crush the entire composite to roughly −2.00 cm using a clean jaw crusher with opening adjusted to about 2 cm. Divide the composite into four lots, using a fractional shoveling procedure, and call each lot A, B, C, and R, respectively: A=136 kg, B=68 kg, C=68 kg, and R=68 kg. The R lot is saved for potential tests that may need to be rerun. Screen lot A through 1.25, 0.63, 0.335, 0.17, 0.085, 0.0425, and 0.0212 cm screens. Weigh each size fraction and record these weights. Spread the −1.25+0.63 cm fraction on a clean surface: The Heterogeneity Test is performed on this fraction, where From this fraction, collect 100 samples. Each sample is made of Pulverize each sample directly in an enclosed ring and puck pulverizer to about 95% −106 μm (do not use a dusty plate pulverizer which is known to smear gold too much). Assay each sample for gold by fire assay and gravimetric finish, using the entire sample. Atomic Absorption (AA) finish is not recommended for the test, since the most relevant assays are the ones showing high gold contents. If AA is used, be very careful with dilutions. Results from a case study are shown in Crush all size fractions, and what is left from the −1.25+0.63 cm fraction, to 95% −0.17 cm, and collect a split about 1000 g from each size fraction. If the coarsest size fraction has less than 1000 g, use the entire fraction. Pulverize each 1000-g split to 95% −106 μm. Perform a screen fire assay using the entire sample and a 150-μm screen. Weigh and assay the entire +150-μm fraction, and perform two 50-g fire assays on the −150-μm fraction. Report all weights and assays, which are relevant for the interpretation of the test. Results from a case study are shown in Take lot B and split it into 16 equal splits, using a rotary divider equipped with 16 segments. An old-fashioned riffle splitter could be used but it is not recommended. Record all the exact weights. Crush each split to −0.30 cm, then pulverize the entire split to about 95% −106 μm. Spread each split in a large pan, and collect one 30-g sample made of about 12 random increments (assay it using the entire sample), and one 60-g sample made of about 24 random increments (assay it twice using about 30 g each time). Results from a case study are shown in Take lot C and crush it to about −0.30 cm. Then, split C into two equal lots C1 and C2 about 34 kg each. From lot C1 take a 16-kg split, then divide it into 16 equal splits, using a rotary divider. Record all exact weights. Take one split and perform a size distribution analysis using 0.63, 0.335, 0.17, and 0.085 cm screens. Report all weights. Recombine the size fractions, so we can use that split in the following steps. Pulverize each split to about 95% −106 μm. Spread each split in a large pan, and collect one 30-g sample made of about 12 random increments (assay it using the entire sample), and one 60-g sample made of about 24 random increments (assay it twice using about 30-g each time). Results from a case study are shown in Take lot C2 and crush it to about 95% −0.085 cm. From lot C2 take a 10,000-g fraction, and divide it into 16 equal splits using a rotary splitter. Record all exact weights. Take one split and perform a size distribution analysis using 0.17, 0.085, and 0.0425 cm screens. Report all weights. Recombine the size fractions, so that split can be used in the following steps. Pulverize each split to about 95% −106 μm. Spread each split in a large pan, and collect one 30-g sample made of about 12 random increments (assay it using the entire sample), and one 60-g sample made of about 24 increments (assay it twice using about 30 g each time). Results from a case study are shown in Recombine all rejects from the C2 16 splits, so an approximate 7.5-kg D lot that is about 95% −106 μm is obtained. Divide lot D into 16 equal splits, using a rotary splitter. Record all exact weights. Take one split and perform a size distribution analysis using 0.0425, 0.0212, and 0.0106 cm screens. Report all weights. Recombine the size fractions, so that split can be used in the following steps. Spread each split in a large pan, and collect one 30-g sample made of about 12 random increments (assay it using the entire sample), and one 60-g sample made of about 24 random increments (assay it twice using about 30 g each time). Results from a case study are shown in From any rejects from the test, prepare a 10,000-g sample (e.g., 10,000 g from lot C2). Screen the entire composite sample on a 212-μm screen. There is always a substantial amount of material that does not grind well. Wash this coarse material. Separate the heavy minerals by panning. With the heavy concentrate, prepare polished sections and find the exact nature of the material that does not comminute well.  The test accumulates an enormous amount of information at a reasonable cost. The Fundamental Error for the coarsest fragments (i.e., about 1 cm for blasthole chips, reverse circulation chips, or the product of a jaw crusher) is well known. It is indeed the primary sampling stage in ore grade control and exploration that is likely to introduce a large error. The experiment uses 1-cm fragments, therefore the sample weight and Differences in gold content between various size fractions are well documented. For example, if the −212-μm material contains two or three times more gold than the coarse fragments, then any loss of fines during the implementation of the sampling protocol would introduce large Extraction and Preparation Errors, which are all devastating non-constant bias generators. Screen fire assays performed on 1000-g pulps give valuable information about the behavior of gold particles after the material has been pulverized (i.e., delayed comminution). Polished sections can provide the necessary information to correct the calculated nomograph using The variance between replicate splits from different comminution stages provides valuable information about residual variances coming from sampling errors other than the Fundamental Error. The variance of the Analytical Error is negligible in the large variance between the 100 handpicked samples made of The histogram of the 100 assays performed on Since the Samples are assayed in their entirety, eliminating any potential problems with subsampling errors.  The 100 samples made of The test is performed on a calibrated size fraction, and is not representative of the grade in the total sample. This leads to a particle size distribution factor The entire test is performed on a single composite. However, material to be sampled at the mine and especially at the mill is often made of many areas as well. At least, the composite is confined to a single type of mineralization. The test must be performed for each type of major mineralization. The above test was performed for an undisclosed gold mine, at Mineral Stats. The author carefully performed the sampling aspect of the test himself to eliminate any operator training ambiguity. According to the analytical laboratory involved, the relative variance of the Analytical Error, including subsampling of the final analytical sample pulps, should not have exceeded 4×10    Several conclusions can be made: The reproducibility of 30-g fire assays from the laboratory was much worse than predicted, clearly showing that more errors than the Analytical Error were involved. Since the overall variances It is fair to say that the observed variances are mainly a sum of the variance of the Analytical Error, and of the variance of the Grouping and Segregation Error. The variance of the Fundamental Error should be negligible, as predicted later by the model given by Partial variances 16 splits is not enough to calculate a variance with good precision, and the variance of the Grouping and Segregation Error is usually a transient, quite erratic phenomenon, especially if a few gold particles are liberated. The difference between variances It is impossible, at least for many cases where the value of Because the fraction from which the 100 subsets were collected was made of a very large number of fragments, The value of Clearly, results from all described tests does not provide the necessary information to accurately calculate the integer Use the approximate, empirical Define a liberation curve, including the liberation size, using valuable information from mineral processing experiments performed to optimize the process. Define a liberation curve, including the liberation size, using necessary observations and tests from a logical, comprehensive, and complete mineralogical study, which should be performed as early as possible for the feasibility study of a new project.  Using A size fraction analysis was performed, the results of which are shown in In a case where unrecognized delayed comminution for gold takes place, To complicate things even further someone may wrongly assume that the gold delayed comminution cannot take place unless the liberation size is reached. In reality a substantial amount of gold may liberate long before the liberation size is reached. Therefore, it is of the utmost importance to investigate the nature of the coarsest particles in pulverized material in a Heterogeneity Test. A scanning electron microscope can perform such study on many polished sections prepared with the coarsest fraction of a pulverized sample. Various authors in the past made attempts to change the usual exponent The merit of their work is to address that there is often a problem if the classic  The focus should not be the exponent “2.5”, but the value that is selected for As some gold starts liberating, the Grouping and Segregation Error may become overwhelming and nearly impossible to minimize. Values for Adapting a value for With results listed in Both approaches, in this particular case, are in reasonably good agreement. The liberation size suggested by replicate samples has nothing to do with the liberation size, since in this ore there is absolutely no evidence of gold particles larger than 300 μm. Similar observations could be made in a major gold and copper deposit. The liberation size suggested by the recommended test is not realistic either, the reason is that Any change of slope as illustrated in The change of slope is amplified in the case of replicate sampling due to the confusion between the true variance of the Fundamental Error and the residual variances of sampling and analytical errors. Furthermore, in the case of replicate sampling, the precision of the calculated residual variances strongly interferes with the accurate quantification of the variance of the Fundamental Error, leading to difficulties to calculate  The empiricist is tempted to manipulate the integer The practitioner unaware of all P. Gy's Sampling Theory subtleties is tempted to reinvent the wheel when the problems he refers to have been well addressed and already solved in the past. Tests using duplicate samples, replicate samples, or interleaved samples are not recommended tests to quantify the variance of the Fundamental Error. However, if extraordinary precautions are taken, it can be done. For values of Tests using samples made of random fragments collected one by one, present many advantages, though they are not the panacea.  For material containing small fragments, such as blasthole material, reverse circulation drilling material, material delivered by a laboratory jaw crusher, the recommended test must be carefully tailored in order to select an appropriate value for For material containing fragments larger than 5 cm, perform the original test suggested by Dr. Pierre Gy, collecting a series of at least 50 or 100 random fragments from a conveyor belt. Replicate sampling, often referred to as the “sample tree experiment” Fragment size distribution analyses are necessary to address potential problems with Delimitation Errors, Extraction Errors, and Preparation Errors, along the entire sampling protocol. Delayed comminution problems must be well addressed to find out below what size Do not manipulate the integer The determination of the liberation model suggested by In any test, involving duplicates, replicates, or interleaved samples, never assume that all sampling errors other than the Fundamental Error have a variance that can be considered negligible, especially the Grouping and Segregation Error after the mineral of interest has been ground close to the liberation size. The original work of Dr. Pierre Gy, presented in more than 60 documents over the years, provides most of the necessary information to deal with many special cases concerning the calculation of the variance of the Fundamental Error. Many practitioners criticize the Sampling Theory long before they completely understand all the well-addressed subtleties of that magnificent tool.