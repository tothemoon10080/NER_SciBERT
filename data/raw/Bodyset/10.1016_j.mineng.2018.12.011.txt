Computer vision systems designed for flotation froth image analysis are well established in industry, where their ability to measure froth flow velocities and stability are used to control recovery. However, the use of froth image analysis to estimate the concentrations of mineral species in the froth phase is less well established and the reliability of these algorithms depends on the quality of the features that can be extracted from the froth images. Over less than a decade, convolutional neural networks have significantly pushed the boundaries with regard to image recognition in range of technical applications, notably cancer diagnosis, face recognition, remote sensing, as well as applications in the food industry. With the exception of the exploration geosciences, they are yet to make meaningful inroads in the mineral process industries. In this study, the use of three pretrained neural networks architectures to estimate froth grades from industrial image data, namely AlexNet, VGG16 and ResNet is considered. In its pretrained format, AlexNet outperformed previously proposed methods by a significant margin. This margin could be increased markedly via partial retraining of the VGG16 and ResNet34 networks.Froth flotation is widely used across a range of commodities and particle sizes to separate mineral and gangue species in an aerated pulp. Froth image cameras are available from a number of equipment suppliers and are used in the control of flotation cells by providing estimates of the flow velocity and stability of the froth. Although their ability to estimate the concentrations of mineral species in the froth phase has been reported, this functionality is not well established in industry, despite its obvious potential in the implementation of advanced process control systems on flotation plants. Estimation of the froth grades from image data is a challenging problem, as colour is not necessarily a reliable indicator of the presence of mineral species in the froth phase. Nonetheless, success has been reported with regard to estimating the ash content of coal ( Studies by In this study, this work is extended and it is shown that convolutional neural networks with deeper architectures than AlexNet can yield better results. Moreover, by partially retraining these networks, the reliability of identifying different states in the froth could be improved even further by a considerable margin. The net result of this is that markedly more reliable estimates of froth grades is possible. Convolutional neural networks (CNNs) belong to a class of deep, feed-forward artificial neural networks that have been successfully applied to image analysis in many different disciplines. They are biologically inspired variants of multilayer perceptrons that emulate the animal visual cortex, the most powerful visual processing system in existence. As indicated in The final fully connected layers of the convolutional neural network operate similarly to those of a multilayer perceptron with the preceding layer of features serving as predictors of the category or class to which the image belongs. The main advantage of CNNs over traditional fully connected deep neural networks is that they have comparatively fewer parameters to learn. Convolutional layers with small kernels are an effective means of extracting high level features that are fed to fully connected layers. Training of CNNs is accomplished by use of backpropagation and stochastic gradient descent ( As deep neural networks, CNNs have a large capacity to capture complex features from image data and over the last few years, these networks have emerged as state-of-the-art approaches to image recognition, often outperforming traditional approaches by a large margin ( However, ab initio construction and effective training of deep neural networks require massive amounts of data and high-end computational resources. One approach to alleviate this problem is to make use of a process called transfer learning. This is possible, courtesy of the public availability of a number of deep convolutional neural network architectures that have been trained on a large database of images of common everyday objects. These models can be used as is, with remarkable efficacy, or can be used as a starting point for further training, since they have already captured low-level features, such as lines, curves and shapes. Three such models are investigated in this study, namely AlexNet, VGG16 and ResNet34. These models have been pretrained on the ImageNet data base consisting of approximately 1.2 million images of 1000 common objects ( As indicated in the simplified diagram in This is the approach that was followed in this investigation. Alternatively, the 4096 features feeding into the output layer of the network can be extracted and used as predictors with an external model, such as was done by As shown in the simplified diagram in This gives it 13 convolutional layers, as opposed to AlexNet’s five. In addition, in VGG16 and VGG19, the large convolutional filters found in AlexNet are replaced with multiple smaller 3 × 3 kernel-sized filters. The stacks of smaller size filters increases the depth of the network, enabling it to learn more complex features (  For example, on the ImageNet dataset Keras ( In order to minimise the risk of overfitting, augmented images were generated by randomly rotating, shearing, shifting and horizontally flipping the original images. AlexNet was essentially used as a feature extractor, as described in Three approaches to using VGG16 were studied in this work. These will be referred to as VGG16a, VGG16b and VGG16c, as described below.    Stochastic gradient descent with restarts (SGDR) ( The case study has been considered previously by The 1280 × 720 pixel images were associated with four different operational regimes, as indicated in The flotation froth data set were obtained from an industrial plant in South Africa and is the same that was used by As indicated in the bottom panel of The image features extracted by each network can be visualised by mapping them to a two-dimensional score space by use of linear discriminant analysis. As mentioned previously, these features were the outputs of the hidden nodes feeding into the final fully connected (output) layers of the networks, i.e. FC As can be seen in As explained in  For comparative purposes, the performance of the deep learning architectures against previously proposed methods for feature extraction from froths are summarised in The GLCM approach was based on the use of 256 grey levels, as well as the extraction of features based on five pixel distances (1, 2, 3, 4, 5) and four angles (0°, 45°, 90° and 135°). Six texture properties, namely contrast, dissimilarity, homogeneity, ASM, energy and correlation were computed from each GLCM matrix, in total yielding 4 × 4 × 6 = 120 features for each image ( With the LBP approach, the rotation invariant uniform method was selected along with a radius of 1 and the number of neighbouring points equal to 8, to yield 20 features ( The GLCM and LBP features were used as predictors with a random forest model ( McNemar’s test ( With McNemar’s test, the following statistic Three null hypotheses were evaluated:    If the null hypothesis that the two classifiers being compared are the same, i.e. they have the same error rates ( The results of the diagnostics are summarised in Three types of approaches to froth image recognition have been considered in this investigation. GLCM-RF and LBP-RF use engineered froth features as predictor variables, AlexNet and VGG16a used learned features learned from a different domain and applied via transfer learning to the froth images. VGG16b, VGG16c and ResNet34 use learnt features as well, but features that have been learnt from both a different domain (ImageNet) and the froth images. It would have been interesting to also consider feature that were learned exclusively from the froth image data, but the available set of images is too small for this purpose. Nonetheless, it is clear that the learned features tended to yield better results than the engineered features, and also that the features learned at least partially from the froth image data were in turn better than the features obtained from transfer learning from the ImageNet data base. The accuracy with which images can be classified has a strong influence on the model when it is used as a coarse-grained estimator of the grades. This influence is demonstrated in  These are important considerations, as the bottleneck to obtaining labelled images can be surmounted to a large extent when modelling is treated as a classification, rather than a regression problem. First, it may be easier to associate froth images with a class (grade interval), than with a specific sample. This would also allow training of the networks by use of semi-supervised learning, to compensate for a lack of assay data or labels that can be associated with the images. As a more general point, it should be noted that the approach outlined in this paper has wide applicability in other areas of mineral processing, where pattern recognition in one form or another is important. For example, the approach could be extended to deal with signals of any dimensionality, e.g. time series in 1D (see for example As such, the application of convolutional neural networks need not be restricted to sensor data analytics, but could also find use model predictive control systems, where features extracted from the data can be used as predictors in the model, or as process diagnostics in statistical process monitoring systems. To summarise, in this investigation, the use of pretrained convolutional neural network architectures, AlexNet, VGG16 and ResNet34 for the development of flotation froth image sensors is explored. The following conclusions can be made from this study. Direct use of these architectures to extract features from the froth images and using these features as predictors to classify the froth structures resulted in considerable improvement over the use of algorithms previously proposed in the literature. In its pretrained form, the AlexNet and VGG16 architectures performed better than a random forest model using GLCM features to classify the froth images at a confidence level of more than 95%. Further significant improvement was possible by partial retraining of the higher layers of the networks, resulting in near perfect classification of froth states in an industrial platinum froth image data set. In this regard, the deepest of the convolutional neural networks, namely ResNet34, appeared to outperform an optimised VGG16 network (VGG16c) at a confidence level of close to 95%. Training of the convolutional neural network architectures is computationally intensive and it was shown that with minor modification of the VGG16 structure, training could be significantly expedited. Further work required to validate these results on different flotation systems is currently hampered by a lack of suitable data sets. As ‘big data’ tools, deep convolutional neural networks require massive amounts of data. While the collection of froth image data could be readily accomplished on industrial plants, labelling of the data required for training may be more challenging. The authors would like to acknowledge financial support for this work, made available by the Supplementary data to this article can be found online at The following are the Supplementary data to this article: