This paper presents a new approach using artificial neural networks (ANN) to predict the critical heat flux (CHF) for a steam–water mixture through pipes. A large number of experimental measurements are used for training and testing the developed network. The Levenberg–Marquardt algorithm was used to train the developed feed forward ANN. The training and validation are performed with good accuracy. The correlation coefficient obtained with unknown data applied to the network is 0.998 which is satisfactory and verifying the fidelity of the developed network. The present methodology proved to be much better than the traditional table and best-fit methods. Using the weights and biases obtained from the trained network, a new formulation is proposed for determination of the CHF Q
                     cr. Experimental results of Q
                     cr are compared with both the results obtained by the developed ANN based correlation and the results obtained by a best-fit correlation. Deviations between the results are found to be less than 5.5% and 30%, respectively. The developed ANN based correlation may make use of the dedicated ANN software unnecessary to use for each calculation time. As seen from the results obtained, the calculated Q
                     cr is obviously within acceptable uncertainties. This ANN based correlation can be employed with any programming language or spreadsheet program for estimating the CHF Q
                     cr. If the validity range changes, the ANN based correlation can be updated in terms of new sets of weights and biases using the same network architecture (same no. of hidden layers and no. of neurons).   %Correl. error Diameter of the tube (mm), desired output (target) Mass flow rate kg Number of neurons in hidden layer Heated length (mm) Number of input parameters Number of learning data Pressure (kPa) Critical heat flux (kW Temperature (°C) Weight Weight between the neurons j and i Vapor fraction (quality) at the outlet of the pipe Specific gravity of the liquid and saturated vapor, respectively The critical heat flux (CHF) is a limiting factor for most forced convective boiling processes. CHF refers to the heat transfer limit causing a sudden decrease in the heat transfer coefficient and possible catastrophic failure of the device in which evaporation or boiling is occurring. For a heat flux-controlled system, exceeding the CHF can lead to a sudden large increase in the wall temperature, which for most coolants, can lead to system failure. The capability to predict the CHF is therefore of vital importance to the safety of flow boiling process A considerable amount of information has been presented concerning the CHF for different fluids flowing through round tubes In general, the CHF prediction can be realized in two main different ways: collecting data into a multidimensional table (table method) or creating a best-fit correlation (best-fit method) as a function of the main parameters. The best-fit method based on assuming a correlation form consists of combination of non-dimensional numbers, which characterize some phenomenological processes, and in fitting some adjustment coefficients. The fitting process may be rather complex for fluids. The CHF look-up tables Modern computational capabilities and numerical optimization techniques would make the table and best-fit methods somewhat out of use. Recently, artificial neural network (ANN) (as one of artificial intelligence techniques) is widely accepted as a technology offering an alternative way to tackle complex and ill-defined problems. ANN technique has a number of advantages such as; fault tolerant in the sense that it is able to handle noisy and incomplete data. ANN can learn from examples, and deal with non-linear problems. Also, ANN has large degree of freedom, ease of use (no fluid properties are needed) ease of updating and accurate predictin at very high speed. ANN are systems of weight and biases vectors, whose component values are established through various machine-learning algorithms, which take as input a linear set of pattern inputs and produce as output a numerical pattern representing the actual output. ANNs mimic somewhat the learning process of a human brain. Instead of complex rules and mathematical routines, ANNs are able to learn key information patterns within a multi-information domain. ANNs differ from the traditional modeling approaches in that they are trained to learn solutions rather than being programmed to model a specific problem in the normal way ANN has been applied successfully in various fields of mathematics, medicine, economics, meteorology, psychology, neurology, and many others. ANNs have been used in many engineering applications such as in control systems, in classification, and in modeling complex process transformations The ANN methodology enables us to design useful nonlinear systems accepting large numbers of input, with the design based solely on instances of input–output relationships and has proved that it is a very powerful and efficient tool to analyze different heat transfer processes. Thus, ANN can be used as a predictor of CHF based on the available database without knowing their best-fit correlations due to ANN's black-box characteristic. However, although the ANNs can perform quite well for interpolation between patterns that have been used during the learning phase, they are poor in extrapolating. Thus, one has to strive to collect experimental data as much as possible in order to train the ANN in which all parameters that have effects on CHF will be considered within a wide parameter range. It is important to note that if the validity range changes, development of traditional correlations such as Eq. Neural networks operate much as a “black-box” model requiring no detailed information about the system. On the other hand, they learn the relationship between the input and the target. The network usually consists of an input layer, some hidden layers, and output layer. For a given set of inputs, ANNs are able to produce a corresponding set of outputs according to some mapping relationships. These relationships are encoded into the network structure during the training process (also called learning), and are dependant upon the parameters of the network, i.e. weights and biases which are iteratively adjusted in order to produce the nearest output to the desired target (experimental data) of the network Among the various kinds of ANNs that exist, the feed forward neural network has become the most popular in engineering applications Each neuron The architecture of a neural network gives the description of the suitable number of layers which the network has, the number of neurons in each layer, the transfer function used in each layer, and how the layers are connected to each other. Each input is multiplied by a connection weight. In the simplest case, the products and biases are simply summed, then transferred through a transfer function to generate a result and finally, the output is obtained. Networks with biases can represent relationships between input and outputs more easily than networks without biases The configuration of the ANN is set by selecting the number of hidden layers and the number of nodes in these hidden layers, since the number of nodes in the input and output layers is determined from physical variables. In fact, the capability of three-layer network to approximate any continuous function has been proved To determine the optimum network parameters, the learning rate (the rate at which the network learns) and momentum coefficient values are examined. The momentum coefficient is used to allow the network to avoid setting in local minima error (root-mean square error, MSE). Local minima in the MSE do not represent the best set of weight and bias factors and the global minimum does. Also, the neuron number in the hidden layer is tested between 2 and 12 and mean square error is calculated for each of them. After many trials optimum network parameters are found; the learning rate is 0.75 and momentum coefficient is 0.85 and the neuron number at hidden layer is 9. Therefore, the configuration 7–9–1 appeared to be the most optimal topology for this application. There are different learning algorithms. A popular algorithm is the back propagation (BP) algorithm The iteration process is ended at one of the following three conditions: (a) training error reaches an expected value such as 0.00001; (b) gradient reaches the minimal value; (c) number of iteration reaches a set value such as 3000. A transfer function generally consists of either linear or nonlinear algebraic equation Experimental data for critical heat flux ( An important stage of a neural network is the training step, in which an input is introduced to the network together with the desired target; the weights and biases are adjusted iteratively so that the network attempts to produce the desired output. Calculating the error between the output and the target performs this process. This error is fed back to the network with adjusting weights and biases according to least mean square error (MSE) criteria. The process is continued until the network output is close to the target. The weights and biases, after training, contain meaningful information, whereas before training, they are random and have no meaning. When a satisfactory level of performance is reached, the training stops, and the network use the weights and biases to make decision. A suitably trained and validated network should be able to predict realistic output even when the network is simulated with new inputs (test data). The decrease of the mean square error (MSE) during the training process of the selected topology is shown in After the training session, the network was simulated with the test data. The regression curve of the output variable ( Mathematical formulation can now be derived from the resulting weights, biases and the activation functions used in the ANN. As the regression coefficients obtained from both the training and testing of the ANNs were extremely good, it is believed that the results obtained would be accurate. Once optimum network architecture is found, the weights and biases are used to develop the ANN based correlation. The correlation estimates The values of hidden layer neurons are: Similarly, the weighted sum and biases of the output layers can be written as:  In the developed ANN based correlation, the coefficient of the input parameters are used to evaluate the summation function of neuron The capability to predict the CHF is of vital importance to the safety of flow boiling processes. Various authors have established different techniques and different relationships for the prediction of CHF. The quantitative relationship between the main variables, however, varies from one author to another. The CHF prediction can be realized either by the table method or by best-fit method. Modern computational capabilities and numerical optimization techniques have limited the above two methods. ANN alternative techniques are accepted way to tackle complex and ill-defined problems. ANNs are able to learn key information patterns within a multi-information domain. Therefore, it is used as a predictor of CHF based on the available database without knowing their best-fit correlations due to ANNs black-box characteristics. The developed ANN is applied to develop an ANN based correlation for estimating the CHF ( The use of the developed formula, which can be employed with any programming language or spreadsheet program for estimating