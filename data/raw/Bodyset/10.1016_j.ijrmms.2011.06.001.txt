Conventional methods for prediction of rock strength are based on using classical failure criteria. In this study, artificial neural networks were regarded as new tools for considering the strength of intact rock in a wide range of loading condition from uniaxial tension to triaxial compression. A comprehensive data set of the values of major and minor principal stresses at failure from 1638 laboratory tests on seven rock types was collected. For each rock type, data were randomly divided into two subsets, training and test sets. Neural networks were trained using training sets to predict the value of major principal stress at failure from uniaxial compressive stress and minor principal stress. Small architecture and regularization method were adopted to avoid over-fitting problems. The same training sets were used in determining the constants of two popular empirical failure criteria, namely Bieniawski–Yudhbir and Hoek–Brown. Then, the test sets were used to examine the accuracy and generalization of the models in predicting the strength in new situations. Comparison of the results of the neural network models with those of the empirical criteria showed that the former approach always lead to less root mean squared error and higher coefficient of determination. On average, for different rock types, using ANN models led to about 30% decrease in prediction error relative to best empirical models. These models also showed better flexibility in the prediction of major principal stress at failure in both brittle and ductile failure regimes.Strength of rock is one of the most important factors influencing the design of rock structures, and it has led to many years of research in the field of rock mechanics. Several empirical rock failure criteria have been developed by many researchers such as Fairhust In recent years, Artificial Neural Networks (ANNs) have been frequently used for function approximation in different field of science, including geotechnical engineering On the subject of rock strength, Meulenkamp and Grima In this study, ANNs were regarded as a basis for new generation of failure criteria to consider the strength of seven different rock types in a wide range of loading condition from uniaxial tension to triaxial compression. The networks were planned to predict the value of In this study, it tried to collect all of available and reliable rock strength data from worldwide sources The brittle failure condition proposed by Mogi ANNs may be defined as structures comprised of densely interconnected adaptive simple processing elements that are capable of performing massively parallel computations for data processing and knowledge representation Two or more neurons can be combined in a layer, and a particular network could contain one or more such layers. The layers of a multilayer network play different roles. A layer that produces the network outputs is called output layer. All other layers are called hidden layers In the learning process, the network is presented with a pair of training data including input values and corresponding target values. The network computes its own outputs using its initial weights and biases. Then, weights and biases are adjusted based on a comparison of the output values and the target values, until the network outputs match the targets The typical performance function used as an error index in the training phase is the Sum of Squared Errors ( Generalization is a very important aspect of ANN learning. Since it is a measure of how well the network interpolates to points not used during training, the ultimate objective of ANN learning is to produce a learner with low generalization error. Over-fitting of a training set occurs when the ANN memorizes the training patterns, and consequently loses the ability to generalize. ANNs that over-fit cannot predict correct output for data patterns not seen during training. Over-fitting problem is expected when the ANN architecture is too large, i.e. the network has too many hidden units and irrelevant input units There are two other methods for improving generalization during training the network Another method for improving generalization is called regularization. It is possible to improve generalization if the objective function is modified by introducing a new term that consists of the sum of squares of the network weights and biases When the data set is small and the network is training for function approximation, Bayesian regularization provides better generalization performance than early stopping. This is because Bayesian regularization does not require that a validation data set be separate from the training set. Hence more data can be used for training In this study, ANNs were used for the prediction of major principal stress at failure from uniaxial compressive strength and minor principal stress. FFNNs were adopted due to their appropriateness for pattern matching problems like strength prediction FFNNs can have one or more hidden layers. However, it has been proved that FFNNs with monotonically increasing differentiable functions can approximate any continuous function with one hidden layer, provided that the hidden layer has enough hidden neurons Optimization of network size is a very important task to prevent over-fitting. If several networks fit the training set equally well, then the simplest network (i.e. the network that has the smallest number of weights and biases) will, on average, gives the best generalization performance In this table, However, the most popular approach to find the optimal number of hidden neurons is by trial and error with one of the above rules as starting point Levenberg–Marquardt back-propagation algorithm combined with Bayesian regularization was used for training of networks because of fast training and high generalization In literature, it is proposed to use between 20 and 30% of available data for testing It was observed that the predicted values of A failure criterion is an algebraic expression of the stress condition under which a material fails. An empirical criterion may be adopted having no theoretical basis, selected only to meet practical requirements of accurate strength prediction and simplicity of use. Several empirical failure criteria have been proposed over the years in an attempt to estimate the strength of intact rock. However, they are usually accurate in a certain range of stresses and are not applicable for all rock types Empirical criteria proposed by Bieniawski and Yudhbir The Hoek–Brown (H–B) criterion is given by Approximate values of the constants, Training sets were used in development of predictive models based on ANNs and empirical failure criteria. The generalization of the models can be examined by comparison of their predictions with corresponding target values included in test data sets. In order to evaluate the accuracy of these models, two indices of root mean squared error (    Average The results show that the trained ANNs can predict the major principal stress at failure more accurately than empirical failure criteria. ANN models are especially more reliable for the cases with higher number of data in the utilized data set, e.g. sandstone and coal. In this study, ANNs were utilized as failure criteria to predict the value of Although the same information were used in development of the predictive models, ANN models for all rock types showed lower values of prediction error. The difference was especially considerable for quartzite and coal, where error of ANNs was about half of the failure criteria. On average, for different rock types, using ANN models led to about 30% decrease in prediction error relative to best empirical models. In addition, ANNs showed higher flexibility for prediction of strength in ductile failure. For coal, adding the ductile failure data to brittle failure data led to only 2 ANNs are powerful tools in predicting the strength of different rock types with high accuracy and flexibility. However, it is possible to improve their performance using more governing input parameters and more comprehensive data set. Extending the same study for rock mass can be the subject of future works. Furthermore, ANN-based failure criteria may be implemented in numerical codes to analyze the stability of different rock structures provided that the ANNs were trained using rock mass strength data. The authors would like to thank Evert Hoek for his helps and guidance in finding the required strength data set. Valuable comments of Candan Gokceoglu and Bulent Tiryaki on the earlier draft of the paper are also warmly acknowledged.