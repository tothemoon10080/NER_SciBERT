The framework of locally weighted learning (LWL) has established itself as a popular tool for developing nonlinear soft sensors in process industries. For LWL-based soft sensors, the key factor for achieving high performance is to construct accurate localized models. To this end, in this paper a nonlinear local model training algorithm called nonlinear Bayesian weighted regression (NBWR) is proposed. In the NBWR, the nonlinear features of process data are first extracted by the autoencoder; then, given a query sample a local dataset is selected on the feature space and a fully Bayesian regression model with differentiated sample weights is developed. The benefits of this approach, which include better consistency of correlation, stronger abilities to deal with process nonlinearities and uncertainties, overfitting and numerical issues, lead to superior performance. The NBWR is used for developing a soft sensor under the LWL framework, and a real-world industrial process is used to evaluate the performance of the NBWR-based soft sensor. The experimental results demonstrate that the proposed method outperforms several benchmarking soft sensing approaches.In process industries, there is a category of key process parameters playing an important role in product quality, such as the melt index, viscosity, catalyst deactivation, octane number, and concentration. These variables are referred to as primary variables and play an important role in many tasks, such as direct closed-loop control, safety monitoring, fault diagnosis, green production, operation optimization, and profit maximization To deal with the limitations associated with laboratory analyses and analyzers, A soft sensors have been developed. Soft sensor is essentially a mathematical model that uses explanatory variables (i.e., easy-to-measure process variables such as temperature, pressure, flow rate and liquid level) as the inputs and the estimations of the primary variables as the outputs. As the explanatory variables can usually be measured in real-time and soft sensors are realized by the computer software, ‘measuring’ the quality variables by soft sensors basically introduces no delay and has a much lower investment and maintenance cost. In general soft sensors can be classified into two categories, namely, the first principle model (FPM)-based type, which rely on the underlying physical and chemical mechanisms, and the data-driven type, which identify the mathematical models with the collected process data According to a recent survey and review of data-driven soft sensors The mixture of expert models and locally weighted learning (LWL) are two other ways to deal with nonlinearities. The former constructs localized models and combines them with different weights such that the limitation of a single model can be alleviated. For example, Yuan et al. employed the finite Gaussian mixture model (GMM) to develop nonlinear soft sensor for multiphase/multimode processes The LWL, also known as ‘just-in-time learning’, ‘lazy learning’, ‘instance-based learning’, ‘model-on-demand’, has three main features The first step in predicting the outputs of a query sample under the LWL framework is to select similar sample set according to a similarity metric that measures the relevance between two samples. Due to its simplicity, the Euclidean distance is the most commonly used similarity metric. In recent years, many improved distance metrics have been developed for similar sample selection, such as the weighted Euclidean distance After the similar sample set is determined, building an accurate local model is the key factor for high performance. The most popular methods for this work are the locally weighted regression (LWR)-based ones, in which the local regression model is trained with each similar sample endowed with a weight to differentiate its importance with respect to the query sample. In the past decades, a variety of LWR-based algorithms have been developed or employed for local model construction. The LWR-based algorithms can be generally divided into deterministic and probabilistic methods. In the deterministic category, the process variables are regarded as deterministic, and the loss functions are typically the explicit training error. Examples of the deterministic LWR algorithms include linear methods (such as the ordinary least squares Due to the contamination of measurement noise, industrial datasets are inherently stochastic Compared with the existing LWR-based soft sensingapproaches, the proposed method has advantages that can be summarized as follows. First, in the proposed method, the similarity is measured in the feature space extracted by the AE, which retains the consistency of the correlation among samples for similar sample selection and the correlation among samples for local model training. Moreover, empirically, the dimensionality of the extracted feature space is much less than the size of the dataset. In addition, for each query sample, the developed local model is nonlinear and Bayesian. Compared with the deterministic local models such as those built by the PLS and LSSVR, the developed local models are probabilistic and can provide additional prediction uncertainties, while compared with the probabilistic models such as the WGR and PPCA, which maximize the likelihood function, the developed models are fully Bayesian. The Bayesian models integrate out the model parameters and have been shown to be less prone to be overfitted than their maximum likelihood-based counterparts The remainder of this paper is structured as follows. In Section  The AE is a single hidden-layer unsupervised neural network consisting of one input layer, one hidden layer and one output layer, as illustrated in Given the In addition, by using linear decoding, the reconstruction The objective of the AE is to minimize the reconstruction error defined as The gradients of The AE is usually trained using the back-propagation (BP) algorithm, which updates the parameters (i.e., Using the weights In the NBWR, the query sample Then, the common Euclidean distance is used to calculate the similarity According to the similarity metric defined in Inspired by the results of the WGR An important distinction between the NBWR and the existing probabilistic local model training algorithms is that, in the NBWR, the model parameters As In the LWL framework, the historical samples used to train the local model are endowed with different importances. The samples that are located faraway from the query sample are less important, and vice versa, such that the process nonlinearities can be handled. Since the quantity Substituting In The above equation indicates that Again, by using the multiplication formula of probability and It is recognized from The true values of the primary variables corresponding to Note that the Student’s Using Subsequently, Based on linear Gaussian operations, the conditional distribution of Similarly, with the aid of the latent variable Therefore, based on In addition, the estimation covariance of The procedures for developing a soft sensor based on the NBWR under the LWL framework, including the off-line phase and on-line phase, are summarized as follows.          In this subsection, the properties of the NBWR are analyzed, and some theoretical advantages of the NBWG in contrast with the those of existing LWR-based soft sensing methods are discussed. These advantages, which are the basis of the better performance that can be expected from using the NBWG for soft sensor development, are detailed as follows:  According to From It can be found from In contrast with the uncertainties given by the WGR In this section, the performance of the proposed method is evaluated with an actual debutanizer column process. For comparison purpose, some related soft sensing approaches are selected as benchmarks, including the global PLS The debutanizer column process is extracted from a desulfuring and naphtha splitter plant and is schematically illustrated in  Note that for all the investigated methods, the validation dataset is used for selecting parameters, while the testing dataset is used to evaluate the generalization performance.  The parameters of the investigated soft sensing approaches are listed as follows.  PLS LSSVR VBGMM DeepELM WGR LWPLS LWLSSVR: a weighted LSSVR model NBWR: for the offline trained AE, The predictions of the butane content of the testing samples by various soft sensors are visually compared in      In the NBWR, the algorithmic parameters can be divided into two groups, i.e., the prior hyper-parameters ( In addition, our simulations show that the influences of   According to By considering the physical meaning of According to Fortunately, from Aiming at handling the limitations associated with the MLE-based LWR soft sensors, a nonlinear Bayesian local model called NBWR has been proposed. The NBWR is composed of two parts: (1) the nonlinear feature extraction based on the AE; (2) the Bayesian model construction on the feature space. The performance of the NBWR has been thoroughly evaluated, and has been compared with several related state-of-the-art methods based on an actual benchmarking process. The results have shown that the NBWR is superior to the benchmarking methods in terms of the predictive accuracy. In addition, the sensitivity test for the parameters of the NBWR has been done, and analyzed the influence of each parameter for understanding the NBWR, which shows that the parameters of the NBWR are not difficult to tune. Therefore, the potential application foreground of the proposed schemes has been demonstrated. However, it should be noted that the representation ability of the AE with a single hidden layer is limited and imperfect, which might be inadequate for processes with extremely strong and complicated nonlinearities. Under such circumstances, the prediction accuracy achieved by the proposed method would not be satisfied. A straightforward way of enhancing the representation ability of the AE is to use deeper networks (i.e., the stacked AE); nevertheless, the stacked AE is easily forced into overfitting. An alternative potential solution is to develop multiple AEs, each of which only needs to represent a small operating area, such that the requirement on the representation ability can be reduced and the use of deeper networks avoided. Therefore, developing a mixture of AEs and embedding it into the LWR framework is worthy of being investigated in the future. The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. This work was supported by The authors are grateful to Fortuna et al.