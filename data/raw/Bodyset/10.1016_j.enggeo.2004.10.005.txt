The present paper focuses on a rigorous statistical procedure referring to small-sampling theory leading to the determination of the number of specimens to test (sample size) in the laboratory for the determination of mechanical properties of rocks. From this theory, relationships between the number of specimens in a group, the coefficient of variation obtained after testing the specimens, the targeted precision index and confidence interval are given. Although this topic seems basic, the quick literature review presented shows that the situation regarding it is quite confused, and no standard and valid procedures for such an important subject can be found.
                  An algorithm which minimizes the sample size leading to the required precision index while respecting the target confidence interval is given. The effectiveness of the algorithm is demonstrated using a series of Monte Carlo simulations from which rock properties are generated. The most important conclusion drawn from these simulations is that, all things being equal, the smallest sample size varies for given rocks and test types, or in other words, it is impossible to determine a priori the sample size required to obtain a given precision index for a certain confidence interval. If the sample size is given a priori due mainly to the limited number of samples available, the engineer must evaluate the precision index for a given confidence interval, if the knowledge of both the true mean and standard deviation intervals is required.
                  The authors emphasize that this paper only deals with the way test data should be considered from a statistical point of view. Choosing what rock properties to test and how the values obtained are used in a design model are up to the rock engineer's judgment and experience.Nowadays, society's increasing needs require more and more natural resources, as well as new constructions involving excavations in rock. Consequently, the expertise from geologists, engineering geologists, civil, mining and petroleum engineers is required to design excavations effectively. Such designs often rely on laboratory tests on rock specimens prepared from samples gathered in the field, usually from cored drill holes. The usual tests performed include uniaxial compressive tests with or without strain measurements, triaxial compression tests, uniaxial tensile tests, direct shear tests on joints and several indirect tests, such as Brazilian or double point load tests, to name only a few. When dealing with laboratory tests, one will inevitably look for standard testing procedures. If a competent laboratory technician performs a series of identical tests on a given rock type, following scrupulously the best standard published for that test, he or she will be confronted with the fact that the results vary from one test to the other, sometimes showing an important scatter in results although the tests were performed in the best possible way. Such scatter in laboratory test results has been dealt with in several ways along the years. Some simply reject results that are too far from the average (so-called outliers). Others consider laboratory test results as random variables and have suggested various means to consider them (e.g., see One is often tempted to increase the sample size to counteract the effect of scatter. Increasing the sample size may decrease the scatter, but the asymptote to which it will eventually converge may still be quite large. On the other hand, given the high cost of sample collection and specimen testing, it is beneficial to perform only the minimum number of tests required to attain the required accuracy for the safety of the project. Moreover, money is not the only constraint, as stated by Specimens used for a given laboratory test should look quite similar to the naked eye. The rock microstructure, consisting among others in grain size, grain distribution and bonding, pores and microcracks and other defects, will have a direct impact on the mechanisms leading to deformation, slip and failure, and they contribute markedly to the observed scatter in test results. As was shown by The authors believe that rejecting a test result must be linked to the observation of the fragments of the specimen after failure in those cases where the tests are destructive. The apparent similarities observed with the naked eye between the specimens should bring one to reject the results of a test having produced fragments that differ significantly from the ones produced in the group. For nondestructive tests, the selection is performed a priori, and once a specimen is accepted in the group, the results it gives should be accepted unless a flaw in the test procedure can be identified. Following this introduction, one question arises when preparing a laboratory test program which is defined as an ensemble of tests performed on groups of specimens. How many tests of a given type should be performed on a given rock? The objective of the paper is to answer rigorously this question, assuming the rock property the engineer is testing is right for his design. The proposed procedure is based on what is called the exact-sampling theory or small-sampling theory in most statistics books (e.g., see Sampling theory is essentially the study of the various relationships existing between a population and samples drawn from the population. It allows estimation of unknown population quantities, such as population mean, variance and so on. These quantities are usually called population parameters, and their estimation is made from knowledge of corresponding sample quantities, such as sample mean, variance etc. The study of unknown population parameters by use of samples drawn from it, together with indications of the accuracy of such inferences using probability theory, is called statistical inference. The classical statistical inference involves normal law probabilities. Traditionally, the determination of confidence limits for a population mean requires the knowledge of the population standard deviation. But this standard deviation is usually unknown, and it is the sample standard deviation which is used in the calculation. It has been proven that this substitution leads generally to an acceptable approximation when the number of observations is greater than 30 ( The arithmetic sample mean is denoted by According to the small-sampling theory, the interval into which a population arithmetic mean lies is defined as follows One can also estimate, within specific limits of confidence for the population, variance in terms of sample variance. This interval is defined as follows To be able to read the confidence coefficients from the Student On the other hand, reading confidence coefficients from the Student For example, for a 95% confidence interval which is most often selected, Eq. The estimation of confidence intervals inspired from the small sample theory which is briefly summarized in the preceding paragraphs involves that the following hypotheses are satisfied. Sampling procedure should be such that all population elements have the same probability of being selected. Sampling is done from an infinite population of elements. The sample elements are independent. The values of the character measured on sample elements are normally distributed throughout the population. The starting point in site investigation is to identify zones or design sectors where it is believed that the rock mass will show a homogeneous mechanical behaviour with respect to the property being measured. Consequently, test results from a series of specimens prepared from a given sampled zone will represent adequately the characteristics of the zone's population. It has long been recognized that when sampling an ore body to determine the grades, it is extremely difficult to have a sampling strategy that will result in having equal probabilities of collecting field samples representing the population (ore body) characteristics since access to these samples is limited ( The authors are well aware that rock mechanical properties often show the characteristics of regionalized random variables ( To avoid the limitation on sample size, Many authors have shown that the distribution of test results on rock can be well represented by a normal law, but Although the subject of this paper has also been considered using extreme values statistics ( The scatter observed in test results is not only related to rocks. Materials produced in the metallurgic industry ( The authors are also well aware that the uncertainty on the knowledge of mechanical properties of rock are not the only source of uncertainty in rock engineering. Other uncertainties must be considered, such as those linked to the in situ stress state ( Assume The precision index, From a practical standpoint, it is advantageous to use the precision index to define the true mean interval. Combining Eqs. This equation shows that as Eq. To better evaluate the meaning of the precision index, the lower bound of the mean confidence interval can be subtracted from the upper bound and divided by 2 leading to the maximum absolute error, Considering the definition of relative error, Eq.  The authors agree with this recommendation for routine engineering in mines if the sought confidence interval is 95%. For mining works which have a longer life span than temporary mining openings, such as shafts or for civil engineering applications, it is suggested to insure that As can be seen in The left hand terms of Eqs. Eq. The same expression could be obtained by considering the right hand terms of Eqs. Eq. The data in Solving Eq. If statistical inference is to be performed, such as finding the probability of failure or nonfailure of laboratory specimens with a given confidence interval, the true variance interval is required along with the true mean interval. Eq.  The confidence parameters appearing in Eqs. The data in The authors have mentioned in the introduction several reasons for optimizing the sample size. What is meant by optimal sample size is the smallest number of specimens in a group which insures the required precision index for a given confidence interval. Since, on one hand, the sample size is a function of the observed coefficient of variation and the latter is unknown a priori and, on the other hand, the sample size is a function of the coefficient of confidence which is also unknown a priori, one must proceed by iterations. This algorithm requires that the number of samples available for specimen preparation is sufficient. To avoid testing more specimens then required, the first coefficient of variation should be assumed to test no more than four specimens within the first iteration.  Three simulation sets were performed to test the validity of the proposed optimization algorithm and to show that attaining a given precision index ensures the true mean and standard deviation are both within the range defined by the precision index and sample size with a chosen confidence interval of 95%. These simulations were done using the Monte Carlo technique. The data given by this technique follow a Gaussian distribution with a mean and standard deviation equal to that of the population. Each data set is comprised of 10 simulations, which are then used with the optimization algorithm, using the random data as test results whenever required in the various steps.  The conclusions that can be drawn from For a given rock type, the minimal sample size in a group varies from one case to the other even if the required precision index is the same. For the 10 simulations of the Malpasset (France) gneiss, this minimal number ranges from 5 to 13 to insure a precision index equal or lower than 1.50 in all cases, as shown by the The true mean of the three rock types is well within the range defined from the observed mean (Eq. The true standard deviation of the three rock types is well within the range defined from the observed standard deviation (Eq. The objectives sought with the simulations are thus attained. To show the influence of the confidence interval considered when searching the minimum number of specimens to be tested when a given precision index has been chosen, various confidence intervals ranging from 75% to 99% have been successively targeted while performing simulation N4. It can be seen from The chosen precision index with simulation N4 was 1.35. The a posteriori calculated precision indices (  The a posteriori calculated precision indices To present precision statements for the simulation results reported in Defining the repeatability limit within laboratory, The reproducibility limit within a laboraoty,  In performing the calculations leading to the repeatability and reproducibility limits for the simulations, all the simulated test results were considered; that is, it was assumed that the consistency statistics (see for instance ASTM Standard Practice E 691) at the 0.5% significance level of each simulation was less than their critical values. Consequently, the limit values reported in the table cannot be greater. On the other hand, having in mind that the rock properties can be considered as regionalized random variables, as stated in In order for the reader to know to what testing procedure each standard refers to, The E122-00 standard suggests, among other things, to estimate the sample size using the following equation, Following these definitions, the true mean interval may be written as, While standard E122-00 recommends low probabilities and having Comparing the values in To illustrate the consequence of using the ASTM standard, the authors give The following comments can be made regarding the minimal sample size obtained with various ASTM standards. Standard D2664-95a, dealing with triaxial testing of rock and which refers to standard E122-00, recommends nonetheless performing a minimum of three tests for each confining stress or at least one test for nine different confining stresses. Standard D2936-95(2001), which defines how direct tensile tests should be run and which refers to standard E122-00, specifies that the sample size may depend on the availability of samples, but it is preferable to perform at least 10 tests. Standards D2938-95, D4406-93(1998), D4543-01 and D5607-02 all refer to standard E122-00 but add no information regarding the minimal sample size to test. Standards D2845-00, D3148-02, D4341-93(1998), D4405-93(1998), D4525-90(2001), D4644-87(1998) and D3148-02 do not refer to standard E122-00 and give no information regarding the minimal sample size in the groups to test. Standard D3967-95a(2001), which relates to the Brazilian test and does not refer to standard E-122-00, specifies that a test group should contain a minimum of 10 specimens except when the coefficient of variation is smaller than 5%. Standards D4535-85(2000) and D5335-99 do not refer to standard E-122-00 but specify that the number of test results should be statistically sufficient to obtain the required precision. Standard D5873-00 on the Schmidt hammer rebound index does not refer to standard E122-00 and suggests that 10 tests be performed per specimen from which an average should be calculated. Results that depart of a certain value from the mean should be discarded. Standard D5731-95 dealing with the point load test also does not refer to standard E122-00 but mentions that a minimum of 10 tests should be performed and that the two highest and two lowest values be discarded before calculating an average. The standard also mentions that, if less than 10 specimens are tested, only the highest and lowest values should be discarded before averaging the remaining results. Standard D4611-86(2000) referring to the specific heat of rock and soil does not refer to standard E122-00 but suggests that, if heterogeneity is considered a problem, various specimens should be tested. The standard suggested by the International Rock Mechanics Bureau (IRMB) for the uniaxial compression test gives a table defining the sample size required to attain a precision index of 1.50. The equation leading to the values presented in If Eq.  Such a table is surprising since  According to It should be noted that some of Yamaguchi's results show a deviation of less than 20% between the true and measured means with sample sizes of less than 10 specimens, which demonstrates that this objective can sometimes be attained with less than 10 specimens while maintaining a confidence interval of 95%. The International Society for Rock Mechanics (ISRM) has proposed testing procedures for various laboratory tests. For reasons already exposed, the authors cannot agree with the sample sizes in As mentioned earlier, experimental errors alone cannot explain the scatter observed on laboratory test results on specimen groups. This will be demonstrated by referring to the most frequently performed laboratory test, the uniaxial compression test along with its most frequently used reference in North America, ASTM standard D2938-95. As demonstrated by According to standard D2938-95, rock cores should be used to prepare specimens and must be of NQ or NX size. The nominal diameter for NQ and NX cores is 47.6 and 54.0 mm, respectively. The acceptable tolerance on the specimen diameter variation is 0.50 mm along its length. Assuming the dimensions are measured with a 0.025-mm accuracy which is not uncommon, the maximum absolute error on the diameter is In the worst case, the diameter measurement is made where the specimen is the widest, and the stress leading to failure occurs where the specimen's diameter is the smallest. Assuming the average diameter of NQ and NX cores, the relative error The uniaxial compressive strength is expressed as, Using the simulation N1 in Section 3.2.6B, the coefficient of variation is 20.69%, and the sample size is 11. From Eqs. One must then conclude that the contribution of experimental errors linked to specimen dimensions within the limits specified by ASTM standard D4543 on the scatter of test results is not very significant. Gross or systematic errors are not considered here. The same demonstration could be made with any other laboratory test with any other standard; the conclusions would be the same. As mentioned in With a confidence interval of 95%, Eq. Consequently, it is convenient to have the observed characteristics of elements taken from a population follow a normal distribution. For a given confidence interval, the required sample size will be much lower even if, for rock testing, the small-sampling theory is used. This paper shows the importance of using a rigorous approach when dealing with the minimal sample size to use for a given rock and given test to attain a target precision index leading to the estimation of confidence limits on the true mean of the measured parameter. It also shown how such an index can be calculated when the sample size is given or imposed a priori due to the limited availability of specimens. The validity of an algorithm optimizing the sample size in a group has been demonstrated using simulations. These simulations have also shown specifically that, for given rock and test types, the minimal sample size varies from one case to the other although the same precision index is sought. Consequently, assuming a priori a sample size as some authors or standards suggest, is unrealistic although the authors admit that the availability of rock samples is often a constraint. In such a case, the engineer should calculate the precision index which will allow him to estimate the errors on the average value and standard deviation he will work with. The simulation results have shown that the observed relative errors on the true mean are, in all cases, lower than the maximal relative error linked to the precision index, making this parameter a conservative (safe) tool for estimating the true mean interval (19 times out of 20). Finally, the authors emphasize the fact that the procedures presented in this paper only deal with minimizing the sample size required to obtain a certain precision index. Whether the precision index, testing procedures, test selection, sampling locations, specimen preparation are adequate is up to the engineer's judgment. One should also have means of knowing if the assumption of a normal distribution for the population being sampled is justified before using equations based on this assumption. Moreover, how the true mean intervals for tests performed at the laboratory scale will be used in conjunction with rock mass property extrapolation models is not covered in this paper, and it is also up to the engineer's judgment to use the proper approach. The authors gratefully acknowledge the financial support of the National Science and Engineering Research Council of Canada (Grant OGP0003412) for supporting part of this research. The authors also thank H.J. Pincus for the helpful suggestions he made on the original manuscript.  The user then proceeds with ExcelÂ© solver (under the Tools tab, not installed by default). The following parameters ( The example shown in Using the algorithm proposed in Section 3.2.6A, the minimal sample size is calculated for the uniaxial tests performed on the Sudbury (Canada) norite which will insure a minimal precision index of 1.35 with a confidence interval of 95%. The data used in this example come from simulation N1 in Section 3.2.6B. Solution procedure: The remaining part of the example is given in the form of table in Looking at the data in Using the data in 