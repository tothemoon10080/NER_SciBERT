The early detection and root cause identification of abnormal events in industrial processes is important, to allow for timely corrective actions, ensuring continued economic operation. This paper investigates the application of statistical fault detection methods, in conjunction with process topology data-driven techniques for root cause analysis, to a simulated milling circuit. Two faults (faulty particle size analyser and rapid mill liner wear) were simulated, and the statistical monitoring techniques tested. Fault detection proved accurate, and variables closely associated with the faults were identified by the root cause analysis. The need to further formalise the selection of data for process topology generation for root cause analysis was highlighted. The milling circuit simulation and fault data has been made available as a resource for future research. Economic performance factors were developed to quantify the impact of the faults and motivate for fault detection and diagnosis.The challenge of detecting and diagnosing faults in increasingly complex industrial processes (such as the minerals industry) has received significant attention in the literature, with the focus being on data-based methods ( Principal Component Analysis (PCA) and related methods (including nonlinear and dynamic versions of PCA) are commonly used for fault detection in the process industry ( Fault diagnosis is cited as being possible by means of causality methods, which attempt to extract causal relationships between variables in the form of process topologies ( Despite the accepted economic benefits of process control in general ( Whether detecting and diagnosing faults or assessing economic performance, any proposed method must be demonstrated or evaluated on a data set. While real operating data provides the most realistic test of any method, the “ground truth” is often missing: for example, the actual root cause of a fault may not be known. Simulated data is used in many studies, as diverse conditions can be simulated without the risk of safety or financial impact. However, the simulations generating this data should be as realistic as possible, in order to provide the level of complexity and challenge required to test any proposed method, and demonstrate real-world applicability. This paper describes the application of data-based fault detection and diagnosis techniques to a validated dynamic model of a run-of-mine milling circuit ( The proposed approach is suggested in general for more robust assessment of the actual benefit of abnormal event detection and root cause analysis in industrial processes. The dynamic simulation and simulated data are available online to promote further analysis and comparative studies. The paper is structured as follows: Section A dynamic model of a run-of-mine mill circuit has been developed to demonstrate the potential economic impact of fault detection and diagnosis. The mill circuit model and its control system is briefly described here, as well as the nature of input excitation (in the form of disturbances) to the model, the generation of normal operating conditions data and fault data. The model, which can be run in MATLAB and Simulink, has been made available as supplementary material for future research. For further details, see the Supplementary Material section of this paper. A dynamic model (rather than industrial data) provides a well-defined data set to test the monitoring methods described below; the selected dynamic model is based on actual operations, however, and so it provides a level of complexity that ensures that the monitoring approach is rigorously tested. The run-of-mine grinding mill circuit model presented by The variable abbreviations used in The mill circuit model was built and tested in MATLAB R2014a, R2016a and R2017a and Simulink, using the ODE45 numerical integration method. A control system for the circuit, consisting of single loop PI controllers with input filters and output saturation (see Control loop pairings were determined based on previous investigations into this system ( The three control loops which were implemented were: The sump volume (SVOL) is controlled by manipulating the cyclone feed flow rate (CFF) which manages the throughput to the hydrocyclone. The mill charge (JT) is controlled by manipulating the mill feed solids (MFS) which manages the overall throughput for the entire circuit as well as the electricity consumption of the mill (P The particle size estimate (PSE) is defined as the percentage of fines present in the output flow from the hydrocyclone. The PSE is controlled by manipulating the sump feed water (SFW) which indirectly manages classification in the hydrocyclone by adjusting the cyclone feed density (CFD). The eight variables listed in Two key disturbances must be rejected by the control system under normal operating conditions (NOC): feed ore size distribution variation (defined as the fraction of rocks in the feed ore, α These disturbances were modelled as random walks ( The expected disturbance variable gradients and disturbance variable starting points were based on inspection of survey data in ( The motivation for this disturbance modelling choice is twofold: firstly, random walks represent non-deterministic input excitation (deterministic input excitation might produce unwanted autocorrelation artefacts). Secondly, real-world disturbance changes would not be completely time-independent: random walks enforce a certain non-independence of consecutive values. Disturbance variation is required to recreate realistic NOC data, as well as ensuring sufficient excitation of the control system such that the expected process variable interactions can be captured. All sensor noise was assumed to be normally distributed, with standard deviation of 1% of the measured value. The inferential sensors (JT and PSE) were modelled as having a measurement delay of 1.5 min to account for input processing. Furthermore, the control system was made more robust to noise by adding first order filters with 1 min time constants to the control loop inputs. Disturbance variation and sensor noise were implemented for both normal operating and fault conditions. Initial start-up of the mill circuit model involves simulation without disturbance variation or sensor noise for a simulated period of 50 h in order to reach initial steady-state. The initial start-up conditions are discarded and not considered during process monitoring. Normal operating conditions were simulated for a total of 104 days of operation: 90 days were used as NOC training data, and 14 days for NOC test data. Process measurements are recorded every 30 s. Fault data were simulated for 30 days for the investigation of two different faults: a faulty particle size analyser on the product stream, and rapid wear of the mill liner. These two faults are chosen in order to provide data for both sudden and gradual faults, which must be detected and diagnosed by any process monitoring approach. The particle size analyser sensor fault can be attributed to a faulty/dirty sensor due to dust or slurry, or simply general instrument drift. This causes the sensor to produce a bias in measurement. It is assumed that the bias would be negative: larger particles are easier to detect than smaller particles, and so the sensor is more likely to under-detect the fraction of smaller particles present, resulting in a lower PSE measurement (representing the percentage of fines in the hydrocyclone overflow). The fault was simulated as a 5% constant negative bias on the PSE reading. The mill liner fault is a result of accelerated wear and tear to the liner, which acts as an interface between the rotating mill shell and the charge tumbling inside the mill. The liner transfers energy from the shell to the charge, and increased wear reduces the efficiency of this energy transfer, requiring more power for the same particle breakage rate, reducing the efficiency and throughput of the mill ( The fault is simulated by placing a bias on the calculated mill power draw. This bias is implemented only on the power draw where it is used to calculate mill breakage, and not on the mill power sensor. This is because the fault does not reduce the actual mill power draw, but does reduce the efficiency of the transfer of power to the charge. The fault is simulated as a linear decrease in the efficiency of power transfer from mill shell to charge, from 100% at the start of the fault to 85% after 30 days. This represents abnormally rapid wear of the mill liner, possibly due to faulty material or installation. Although monitoring systems are available specifically for mill liner wear, this abnormal wear would not be detected during operation by these systems, which require mill shutdown and internal inspections. A process monitoring approach should detect this abnormal wear (and other faults, including unknown faults) online, from process measurements (although other measurements can be included, such as vibration monitors or motor current, where available). The significance of abnormal events is rarely quantified in terms of economic impact in process monitoring literature. To capture the economic impact of control and fault detection, The milling circuit simulated in this work has been the subject of a number of studies of economic impact, most notably in comparing the economic performance of two different controllers ( The economic performance functions developed by The particle size (measured and simulated as the particle size estimate, PSE) is identified by In Eq. Since one of the simulated faults is a bias in the measurement of particle size, it is important to distinguish between the The relationship between the actual (or simulated) particle size estimate (PSE) and valuable metal recovery is shown in The instantaneous value of mineral recovered can be calculated from the throughput, recovery, ore grade and mineral price (   The instantaneous electricity cost (in US$/h) is calculated as the mill power draw (P The economic performance factor (EPF, in US$/h) of the simulated run of mine milling circuit is defined as the difference between income due to mineral recovery (a function of throughput and recovery) and the cost of electricity to power the mill (a function of the transfer of power from the mill to the mill charge, the feed ore hardness and throughput): As discussed above, there are other factors which would have an impact on the overall profitability of such an operation, and these should be developed for further implementations of this method. Although specific methods for process monitoring are described below, the proposed approach to fault detection and diagnosis is general, and can be readily applied with other methods. Feature extraction by principal component analysis (PCA) is used as the basis for process monitoring in this work (rather than more complex nonlinear or dynamic variants of PCA, or other feature extraction methods) because it is well described in the literature ( Given a data set, represented by the matrix The columns of The data can be reconstructed in the original measurement space from the scores and principal components. The reconstructed data, Two monitoring diagnostics are derived from the PCA model: the modified Hotelling’s T A fault is considered to be detected by the monitoring technique when the monitoring diagnostic exceeds the control limit. The modified Hotelling’s T where The squared prediction error for sample where New data is projected into the model (after being normalised and centred) using Eqs. Once an alarm has been triggered due to a violation of a diagnostic threshold, the contribution of each of the measured variables to the diagnostic can be determined. There are a number of contribution methods, including complete, partial and reconstruction-based contributions ( The contribution For this study, a threshold for the contributions for each variable is calculated from the 99th percentile of the contributions from the NOC training data ( Due to the highly interconnected nature of processes, faults may propagate through connected paths in the process and fault symptoms may be seemingly unrelated to the root cause of the fault. A process topology provides information about both connectivity and causality which can be exploited to determine probable propagation paths from the fault symptoms. A process topology can be derived from fundamental knowledge of the process ( Causality methods can be computationally expensive, particularly for systems with large numbers of variables, or with many observations. A reduced set of variables is frequently selected to represent the system, based on process knowledge or monitoring results ( Granger causality is used in this study to develop process topologies, because of its computational efficiency (particularly compared to cross-correlation and transfer entropy methods) and intuitive implementation ( A question which is not commonly addressed in the literature is the selection of data for the construction of process topologies. The simplest approach, and that which appears to be taken in the literature, is to make use of all available data. This approach requires no prior knowledge of the process, has no hyperparameters to specify, and does not lose any of the information which the causal method may extract from the data. However, in the authors’ experience, when working with both simulated and operating data, this approach has been unsuccessful. For example, in the current work, application of Granger causality to all of the normal operating conditions (NOC) data produced process topologies in which every variable appeared to have a causal link with every other variable. This result is neither useful nor sensible, and so two other proposals are presented here. These proposed methods are based on the application of Granger causality to windows of data from NOC. An obvious drawback is that this requires the specification of window width, which in turn requires knowledge of the dynamics of the process of interest. Here, the window width is selected based on a multiple of an order of magnitude estimate of a representative residence time from the milling circuit. An order of magnitude estimate is used to reduce the requirement for expert system knowledge; in this case, the estimate was 30 min, a reasonable value for a large industrial operation (for comparison, the simulated mill has a steady state residence time of approximately 15 min). The multiple of the residence time to determine the window width was 100, which ensured that the windows were each large enough to include sufficient variability in the data for the Granger causality application. The effect of these assumptions is further discussed in the results. The first proposed method applies Granger causality to every possible consecutive (but non-overlapping) window within the NOC data. The significance of each causal connection is averaged over all of the windows, and used to construct the process topology. This approach is attractive as it makes use of all of the NOC data, but at a reduced computational cost, and produces fewer spurious connections (as will be shown in the results). The second proposal is to apply Granger causality to a single window of data which ends at the time of fault detection. This method is attractive as it has a very small computational cost, and considers a portion of data similar to the faulty data, potentially improving fault diagnosis. Once a fault is detected, the key variables (from the contribution method) are identified, and the causal variables determined from the process topology by tracing backwards (in terms of causality). One of the limitations of data-based root cause analysis is apparent when considering the final step. The nodes in a topology map represent measured variables in the process, but faults are not always directly associated with a specific sensor measurement. For example, pump impeller wear is not measured directly, but may have an impact on measured variables such as pressure or flow. Therefore the root cause analysis can, at best, point to a variable that is associated with the root cause of the fault. The results of the simulation of the run of mine milling circuit are shown below for a period of 134 days: 90 days of normal operating conditions (NOC) data, to train the statistical monitoring model; 14 days of NOC data to test the performance of the monitoring method; and 30 days of fault data, for each of the two faults (particle size estimate fault, and mill liner fault). The data to generate the initial steady state of the model is not shown. The process inputs and outputs for the particle size estimate (PSE) fault are shown in The main source of variation in the NOC periods of data is due to the incorporation of random walks in the feed ore size distribution variation (defined as the fraction of rocks in the feed ore, α Note that the data in The economic performance factors for each of the simulated cases are shown in  The economic performance of the simulated milling circuit is not abnormally low following the PSE fault (when compared to the NOC data), and monitoring of the plant based only on economic performance would not necessarily identify the performance shown in  The decreasing performance as a result of the mill liner wear would become apparent from monitoring economic performance as those shown in The statistical monitoring model was trained on the normal operating conditions data, making use of 6 retained principal components, which explained >98% of the variance in the data, as shown in the scree plot in The results of statistical monitoring of the simulated milling circuit are shown below, for each of the simulated faults. The control charts for each of the monitoring statistics (modified Hotelling’s T For both monitoring statistics, the false alarm rate (determined from the NOC test data) is low, reflecting successful training of the model on the NOC training data. The missing alarm rate (determined from the fault test data) is particularly high for the modified Hotelling’s T In all cases, the detection delay reflects very rapid detection of the faulty condition.  The control charts for the two monitoring statistics are shown in The poorer performance of the statistics in terms of missed alarms (compared with the PSE fault) is a result of the nature of the fault: a gradual change in the mill liner condition is difficult to detect, and the slow occurrence means the control system maintains control of the milling circuit, resulting in the poor performance of the T Due to the incipient nature of this fault, the detection delay is longer than for the PSE fault; simultaneous monitoring does not detect the fault for more than two months, for example. However, the detection delays for the individual monitoring statistics are significantly shorter than would be possible if only the economic performance (shown in  As shown in The relative contributions to the SPE statistic at the time of detection for the PSE fault are shown in  As mentioned in the Methods section, although the application of Granger causality appears to be simple, requiring the user to specify only the significance level for retained connections and the maximum time lag, the authors’ experience has shown that this is not the case. In particular, generating the process topology using all available NOC data resulted in an over-connected network, in which every variable appeared to have a causal relationship with every other variable. For this reason, two alternative approaches were proposed here: to define a window size (in terms of a representative process lag or residence time for the process), and then generate the process topology from consecutive windows of data from the NOC data, and to generate the topology from a single window of data which ends at the time of fault detection. The order of magnitude estimate for the representative process lag was selected as 30 min for this study, and the window size was specified as 100 times this process lag value. The results of the topology generation were found to be relatively insensitive to the choices of these values, suggesting that either approach may be suitable. The process topology generated for consecutive windows in the NOC data is shown in Both of the process topologies reflect the control loop links between the particle size estimate (PSE) and sump feed water (SFW), between the sump volume (SVOL) and the cyclone feed flow rate (CFF), and between the mill feed solids (MFS) and the mill charge (JT). However, other connections are less intuitive: for example, the mill power (P The variability of the causal connections between process variables was investigated in further detail (as described in the The results of the root cause analysis for the PSE fault are shown in The analysis suggests that the root causes of this fault are the sump feed water (SFW), sump volume (SVOL) and particle size estimate (PSE). Reducing the number of variables would enable plant support personnel to more closely study the operation of the hydrocyclone; the control loop link between the particle size and sump feed water (both root causes) may assist the identification of the particle size sensor as the real root cause. The results of the root cause analysis for the mill liner fault are shown in The analysis identifies the mill power (P This paper described a statistical monitoring approach based on feature extraction (by principal component analysis) and fault detection (with statistical thresholds), followed by fault diagnosis using contribution methods and data-based process topologies (using Granger causality). The monitoring approach was illustrated using standard techniques, but can be easily extended to more complex methods. A simulation of the run of mine milling circuit described by Two fault conditions were simulated: a faulty particle size analyser on the product stream (PSE fault) and rapid wear of the mill liner (mill liner fault). The mill circuit simulation and simulated fault data have been made available for further research, such as testing other fault detection and diagnosis methods, or investigating the economic impact of fault detection in more detail. The statistical monitoring method detected the sudden PSE fault almost instantaneously, and the contribution and process topology analysis suggested that the root causes of the fault were the sump feed water (SFW), sump volume (SVOL) and particle size estimate (PSE). Reducing the number of variables of interest to these three would allow plant support personnel to more rapidly identify the actual root cause. The PSE fault caused a decrease in economic performance for the milling circuit, which could be avoided or drastically reduced with the implementation of statistical monitoring methods as described here. The statistical monitoring method took slightly longer to detect the mill liner fault, due to the incipient nature of the fault. This detection is, however, significantly faster than could have been achieved by monitoring only the economic performance of the circuit, for example. The contribution and process topology analysis identified the mill power (P The results of the process topology generation and root cause analyses have shown that Granger causality has the potential to identify variables associated with the cause of faults in complex systems, such as the milling circuit simulated in this study. The sensitivity of the method to the data used to generate process topologies was highlighted in this work, suggesting a need to further formalise the method’s application, particularly to large datasets. Two approaches for the selection of data for topology generation were proposed, making use of simple assumptions about the process, in order to avoid the need for expert knowledge. The simulation of the milling circuit, as well as the data used in this paper, have been made available for further use. The code can be downloaded from The following acknowledgements are made:  AngloAmerican Platinum, for research funding of Brian Lindner and John McCoy. The authors would also like to acknowledge the valuable comments of the reviewers of this article.  When the prediction of This pairwise approach to Granger causality has been shown to predict spurious causal links, and a multivariate extension of Granger causality proposed (  Although the method is based on the fitting of linear autoregressive models to data, it is anticipated that a nonlinear process under effective control will remain in an approximately linear regime. The method is thus applicable to normal operating conditions data for a process under control. As the process deviates from normal conditions, the resulting nonlinearity may result in approximation errors when constructing process topologies, and so fault data is not used for this purpose in this paper. The model order, where Time series generated by processes will include some stochasticity, which means that nonzero values for Granger causality will be calculated even when there is no connection between the variables. Hypothesis tests to determine the statistical significance of the values obtained need to be employed. For Granger causality this hypothesis test can take the form of an F-statistical test ( N represents the sample size of the time series,  In order to investigate the variability of the process topologies produced by the Granger causality method, the significance of the causal connections between process variables was plotted for each of the windows in the normal operating conditions (NOC) data, which was used to construct the process topology shown in  However, the method does not always detect expected connections, such as between the mill feed solids (MFS) and mill power (P Similarly, the method detects unexpected causal connections between process variables. For example, as shown in These results highlight the sensitivity of Granger causality to the portion of data used to construct the process topology: not only are expected connections not always (or even frequently) identified, unexpected and counterintuitive connections can be identified.