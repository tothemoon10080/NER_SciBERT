Laser scanner is a powerful tool which helps in the control of as-built construction projects. The automatic registration of the acquired point clouds without the use of artificial targets is a relevant subject in current investigation. This work focuses on extracting descriptive keypoints from geometric point descriptors, in such a way that keypoints are suitable to perform 4 Points Congruent Sets coarse registration without artificial targets. These keypoints are obtained via 3D Difference of Gaussians over geometric scalar values of the points resulting in characteristic salient features. The registration procedure reduced the RMSE around 2cm during coarse registration comparing against state of the art algorithms. These RMSE values allow the subsequence use of fine registration via ICP completing the automation of the registration process. Geometric keypoints are demonstrated to be a suitable way to obtain automatic point cloud registration and open the way to future developments.In recent years, Building Information Models (BIM) stand as the optimal solution for storing and managing building life-cycle information, including not only geometry, but also semantics and relationships with other constructive elements defined by the Architecture, Engineering and Construction (AEC) industry In most of the survey processes, although there are mapping systems which reconstruct 3D point clouds from 2D laser scans based on a continuous 3D positioning estimation The aim of this work is to obtain an automatic coarse registration without the use of artificial targets, able to perform fine registration with standard fine registration algorithms such as the Iterative Closest Point (ICP) algorithm The rest of the document is organised as follows: The use of point clouds as source data for 3D model generation, surveying, and structure analysis is one of the most extended techniques in the current years. The increase in popularity of point clouds is, to a significant extent, due to the new generations of scanning devices with reduced cost, which are now more compact and easy to handle. Unfortunately, the huge amount of data generated with these devices is difficult to process. Additionally, in order to obtain a complete model, an object or scene needs to be scanned from different positions, as mentioned before. This work tries to tackle both problems, the amount of data, and the aligning of the acquired information. A good introduction about the point cloud and shape registration can be found in the works by Tam et al. Coarse registration is a critical and complicated procedure when the requirements of being automatic and without targets are added. The procedure for the registration without the use of artificial markers, usually follows the same steps Regarding the point descriptors and feature extraction, some relevant work can be found in the works Meanwhile, in the area of keypoint detection, the work of Rusu and Cousins As for the coarse registration procedure, Aiger et al. Another useful approach using keypoints is the one explored in The method presented in this work includes the use of different techniques, which combined allow to spread to new possibilities over the alignment problematic. The methodology exploits the capability of the 3D DoG keypoint detector over coloured point clouds. Here, instead of using the return intensity of the LiDAR data as done in The process of point cloud registration without artificial targets implies the necessity of obtaining natural reference points among the collected data. Usually, these points are computed from the geometric information provided from the surrounding neighbourhood of each particular point. These descriptors not only work by defining the type of point that is characterised, but also, they help giving an interpretation of the scene, define objects, etc. As mentioned in The geometrical features for each point depend on the size of the neighbourhood, where the radius used to cover the neighbouring points should be large enough to describe the local geometry. Small radii might tend to result in neighbourhoods which are not appropriate to cover the local 3D shape, while large radii might have a smoothing effect losing details and mistaking the neighbourhood into another context (i.e. a sphere where using a large radius mashes-up with a plane resulting in a planar surface). Thus, the algorithm works in a two-step approach. First, the dimensionality features are proposed for a given spherical neighbourhood, and then, the features are computed for growing sizes, trying to minimise the entropy function. The search radius used in the implementation varies between 3 The descriptors are computed from the eigenvalues and eigenvectors of the covariance matrix obtained using the well-known principal component analysis (PCA) algorithm  Once this procedure is obtained for a point, searching the optimal radius is essential to generate the best possible descriptor from the point cloud. For each of the above mentioned neighbourhood sizes, the Shannon entropy shows how ordered the points are in each eigenvector direction inside its ellipsoid. Since the entropy comes from the eigenvalues The change of curvature, or simply curvature  Finally, the authors decided to use and analyse the planarity, curvature and eigenentropy descriptors in the following work, supporting the idea by the possible use of these point descriptors in different uses, for example, the study of the convergence ratios for the ICP algorithm Point descriptors give important information about the point clouds, but unfortunately, they are not sufficient to perform a registration without prior coarse alignment of the data. In this sense, the work performed by Theiler et al. in Now, assuming each point descriptor can be stored as a scalar number in a different field, the point cloud can be easily coloured by each of them. In this sense, each available point cloud will have a different skin or texture depending on the used point descriptor. The decision of colourising the point clouds with these descriptors came from the assumption that if the Difference of Gaussians is able to detect changes over the intensities, it should be able to do the same for another kind of colour information. As mentioned in The extraction of keypoints through the Difference of Gaussian method not only satisfies the necessity of detecting relevant points or parts of the scene, subsampling an important amount of the original data, but also guaranties that those keypoints are robust against noise. This fact gains more relevance when comparing the keypoints obtained by applying only a threshold in the descriptors values used in In the LiDAR return intensities there are several keypoints detected around the ceiling, just on top of the scan position, and not enough points around the corners and the borders of the ceiling and the walls. Alternatively, the entropy keypoints are well represented in those areas, and cover a more evenly distributed amount of points. In this current work, the thresholds to detect the keypoints were set iteratively, reaching around one percent of the original number of points in the point cloud. The third st ep in the proposed methodology is to perform the coarse registration, which relies on the 4-Point Congruent Set algorithm as described in The automatic registration process can be summarised as follows: first, a random base of four co-planar points, which are not close to each other, is generated from the model point cloud. From this base, the geometric relationship between the four points and their intersection is stored. Also the relationships between the normal vectors are considered to reduce the possibilities during the search of the correspondence base in the source data. The second step is to find a second base from the point cloud to be registered. Instead of randomising the search, only the pairs of points that satisfy the geometric and normal vectors relationships are considered. Thus, all the point pairs are grouped allowing to search only for pairs that are co-planar satisfying the geometric and normal vectors relationship. They also have to include an intersecting point fulfilling all the established relationships. Once all the base candidates are stored, it is time to verify which base reduces the registration error. For each candidate, the resulting transformation matrix obtained from both bases and the root mean square error (RMSE) between the resulting alignment are computed. Checking the RMSE, only the minimum error is marked as a matching candidate, thus, the transformation matrix is saved as a coarse registration candidate. The final transformation is the one that minimises the global RMSE between both point clouds, taking into account the estimated overlapping. One important thing to remark is that, as explained in Selecting the base of four coplanar points is a random process, so the nature of the algorithm is random. This means that the experiments need to be repeated several times to obtain a final stable indicator of accuracy. The first one is the success rate. One attempt is considered a success using: For the The final step in the whole process is to perform the fine registration. The state of the art technique is the Iterative Closest Point (ICP), which is able to perform a good quality alignment using the point-to-point approach. The following section details the used datasets, as also the experiments carried out in order to demonstrate the performance of the proposed method. A subsection including a quality assessment of the registration results follows to analyse in more detail the experimentation. Additionally, a comparison using the already published results and datasets by Theiler et al. The method proposed in this study is tested and analysed in four different case studies: a classroom, an L shaped laboratory, and the pillars foundation of a building. All the scenes belong to the School of Mining Engineering at the University of Vigo and were scanned using a Faro Focus3D X 330 LiDAR scanner. The performed work is centred in the interior of buildings. Only the pillars dataset takes place in the exterior, being its ground full of vegetation and an irregular slope. In order to be able to capture the whole area, each case study is scanned twice from different positions. Also, the scanner is placed such as the different point clouds contain some occlusions and shadows. This procedure leads to a scenario, where the final dataset consists of six point clouds of around 10-21 millions points each. The six scenes can be seen in In order to reduce computation complexity, the amount of points per point cloud is subsampled via an octree filter ( The experiments were carried out on the three datasets using the eigenentropy, planarity and curvature feature descriptors, setting After 50 trials in each dataset and each kind of keypoints, the mean RMSE and the standard deviation for the coarse and fine registration were recorded. Since the purpose of a coarse registration is to prepare the data for the fine registration, not only the coarse registration values obtained by the proposed methodology are tested in this section, but also the results obtained in the fine registration. Fine registration in this case was carried out with the ICP algorithm. One can expect the standard deviation values of the fine registration be the lower as possible, meaning that the whole process reaches stable results of alignment. Fine registration comparison with other methods found in the literature, like ICP and the different modifications of the algorithm, is not performed during this work, mainly because the fine registration is out of scope in this case. The main intention of this work is to obtain a coarse registration method which is able to serve as input for the fine registration. All the experiments were implemented in Matlab, except the keypoint extraction, which was implemented in C++ with the help of the Point Cloud Library The first analysed dataset is the Classroom. This dataset was intended to be the control dataset, thus, results are expected to be accurate. The findings on this dataset can be seen in In case of the laboratory dataset, the results in The pillars dataset presents special complexity. Watching the success rate at By now, all the datasets and keypoints registration were analysed. But, since some discrepancies between the coarse and fine alignment were encountered in the tables, the authors propose an additional test to verify the quality of the registration. The distance between the registered points from the source point cloud, which belongs to planar surfaces, and the planes primitives fitted to the surface of the model point cloud is computed. This measurement is repeated over three different planes in the model and is intended to give a more representative registration value than the whole mean error. Eqs. ( In   Even though the experiments were carried out comparing the results using the proposed methodology and the one used by Theiler et al. The experiments were performed exchanging the keypoints from the LiDAR return intensities with the ones detected using the proposed methodology. Results obtained from the eigenentropy and curvature descriptors keypoints show a However, the results obtained by the planarity based keypoints are not as satisfactory as the others. Looking at the results from the previous sections, the ones obtained here are in accordance, certifying these keypoints as not suitable for the task required in this work. Although some cases are satisfactory, in the overall cases the success rate is not good enough, and both the angular and the translation error are not as accurate as required, leading to a final bad coarse alignment, and in consequence a bad fine one. After the performance of all experiments, some facts should be remarked. The methodology performed using keypoint alleviates the 4PCS registration algorithm. Among all the tests, the keypoints in the indoor scenes were the ones that resulted in a better performance as was the intention of the proposed method. Regarding the keypoints, the ones obtained from the eigenentropy and the curvature showed to be more than suitable to perform the registration, even though sometimes the success rate is not enough to be fully automatic. However, when comparing the results in a multi-scan position scene, the results are much better than the previous ones in terms of these success rates. Additionally, in general terms, the RMSE obtained using these keypoints is lower than those in the state of the art ones. Only planarity is not good enough to justify its inclusion. To summarise, obtaining keypoints from the geometric descriptors proved to have more significant results than the previously reported. Even though the LiDAR return intensities can be meaningful in terms of point cloud description, its keypoints can be improved using different geometric point descriptors as shown in this section. In addition, the keypoints around the scanner position obtained with the LiDAR return intensities are noisy and persistent as viewed in Although the standard accuracy measurement is the RMSE, sometimes its value could be misleading, as demonstrated by In this paper a new use for the point descriptors was set, tested and evaluated. The geometric descriptors are suitable to apply colour and/or texture to the point cloud, obtaining a way to be geometrically descriptive. In this way, it can be able to apply keypoints detectors state of the art techniques, obtaining robust and more descriptive keypoints, conversely, its LiDAR return intensities counterparts have noise problems. These new keypoints can be used for other different works, mainly because they are computed from geometric descriptors, reaching to keypoints which contain relevant information of the point cloud by themselves. The keypoint detector algorithms used in this work are proved to be robust and well known in the scientific community. Their further use to detect salient features from coloured point cloud can be exploited in further works for not only automatic point clouds registration, but also for other open interest subject, e.g. object recognition, descriptor and keypoint matching, etc. These obtained keypoints should be more robust than the ones obtained by similar methods, and can be useful for the mentioned additional purposes. Of course there is room for further improvement and new research, like introducing a descriptor value to the keypoints in the 3D Difference of Gaussians, and turning to a final version of 3D SIFT. The automatic registration of point clouds using keypoints instead of the whole dataset (K-4PCS) has been tested, according to the scope of this work, using mostly indoor scenes. In most cases, the inclusion of these new keypoints can outperform the Harris and LiDAR return intensities ones, while in the worst case scenario, it can obtain similar results. The proposed method proved to obtain better coarse registration results than the ones compared in this work. The automatic alignment with the use of keypoints detection as natural targets is demonstrated to be suitable in scenarios where the geometry is not regular, and a certain amount of overlapping can be managed. The overlapped area should be around 60% at least, in order to guarantee a success rate, but the method could work with less, as far as it has some distinctive geometry. Further work is required to improve the need of less overlapping zones, and solve the geometric symmetry problem. This work also includes a more complete measurement procedure to evaluate the point cloud registration results. It is intended to serve as a complement of the RMSE in the cases that it proved not to be accurate enough for the registration purposes. A more extensive analysis of the resulting point cloud is needed to check the distance between the original data on several surfaces. Reducing the computation over the majority of the overlapping area is also critical to prevent the erroneous RMSE that can mislead the final registration values. Authors want to give thanks to the