This article presents a suite of numerical methods contained within a Matlab toolbox for constructing complete particle-size distributions from diverse particle-size data. These centre around the application of a constrained cubic-spline interpolation to logit-transformed cumulative percentage frequency data. This approach allows for the robust prediction of frequency values for a set of common particle-size categories. The scheme also calculates realistic, smoothly tapering tails for open-ended distributions using a non-linear extrapolation algorithm. An inversion of established graphic measures to calculate graphic cumulative percentiles is also presented. The robustness of the interpolation–extrapolation model is assessed using particle-size data from 4885 sediment samples from The Netherlands. The influence of the number, size and position of particle-size categories on the accuracy of modeled particle-size distributions was investigated by running a series of simulations using the empirical data set. Goodness-of-fit statistics between modeled distributions and input data are calculated by measuring the Euclidean distance between log-ratio transformed particle-size distributions. Technique accuracy, estimated as the mean goodness-of-fit between repeat sample measurements, was used to identify optimum model parameters. Simulations demonstrate that the data can be accurately characterized by 22 equal-width particle-size categories and 63 equiprobable particle-size categories. Optimal interpolation parameters are highly dependent on the density and position of particle-size categories in the original data set and on the overall level of technique accuracy.Particle-size data are of interest to a large body of theoretical and applied research. Traditionally championed by the broad field of earth sciences ( Practices in civil engineering, applied geology and soil science have used a range of mathematical models to derive continuous particle-size distributions from sparse or proxy data ( In spite of issues associated with sparse data, i.e. that they fail to entirely capture the distribution shape, autocorrelation in particle-size distributions indicates that distributions could be characterized by relatively few data points. Data reduction is an important process for both data storage and processing, particularly in the context of complex multi-dimensional models. Data reduction in this manner provides a more accurate means of describing a particle-size distribution, without resorting to the use of summary statistics like distribution moments ( Robustness of fit assessments of parametric and empirical distribution models have to date been unsatisfactory. Over a century ago This paper presents a series of numerical methods for integrating particle-size data from a range of different sources. Integration is an essential step for the robust analysis of particle-size data. This paper does not try to characterize particle-size distributions by parametric model fitting, rather by re-sampling the data to a set of uniform particle-size categories. Integration allows later statistical analyses to be performed with confidence and for the calibration of particle-size data to be attempted more rigorously. The integration procedures include (i) the construction of particle-size distributions from sparse particle-size data; (ii) resolution of order-relation conflicts in multiple samples; (iii) interpolation of particle-size distributions into regular particle-size categories and (iv) extrapolation of distribution tails. The paper also presents an approach to estimate the optimum number of particle size categories for distributions in a data set. The optimum number of discretized categories is calculated on the basis of the accuracy of the analysis technique used to measure the particle-size distribution and is an essential step in preparing the data for spatial interpolation. This procedure aims to avoid unnecessary computational costs during both the data homogenization process and subsequent three-dimensional interpolation. Integration of particle-size data does not remove bias between samples caused by sample analysis using different analytical techniques. Inter-instrumental calibration is dealt with by the The methods presented in Application of the methods presented in This section provides a description of the numerical methods used by the Particle-Size Toolbox module Let a particle-size frequency distribution Particle size units in the toolbox are given in the phi ( The principal objectives of applying interpolation algorithms to particle-size data are to predict percentage frequency values for unknown particle-size categories or to calculate the particle-sizes corresponding with indicator percentiles (e.g. In addition to using a constrained cubic-spline interpolation, solutions developed to tackle the inherent non-linearity of particle-size distributions take inspiration from the observations of This considerably simplifies modeling the distribution since To apply a binary Owing to the practical limitations of collecting statistically representative samples of large particles ( The solution to the problem of unconstrained distributions adopted here builds on the assumption of a log-hyperbolic distribution. The upper and lower tails of a discretized logit-transformed frequency distribution The length of both ‘tails’ is calculated by comparing For the upper end of the distribution the particle-size categories The probability functions for the upper and lower ends of the distribution are based on a series of linear regression equations applied to logit-transformed cumulative frequency values Once the upper and lower tails of a distribution have been modeled, a regularly discretized estimate for Particle-size frequency distributions contain a great deal of auto-correlated and hence redundant data. The number of particle-size categories can therefore be efficiently reduced with minimal loss of data. A conventional approach using the percentiles of a distribution is applied here to effectively reduce the number of particle-size categories needed to describe a complete particle-size distribution. An equiprobable particle-size distribution is modeled by identifying the upper limits of particle-size categories corresponding to equally spaced cumulative frequency values, i.e. [10th, 20th, …, 90th, 100th]. The function Estimation of The solution space for graphic measures of skewness and kurtosis is presented in A set of simulations were run to investigate the effect of the number of particle-size categories on the accuracy of particle-size frequency distributions modeled using Overall data accuracy was estimated by calculating the median The optimum number of categories for both techniques was parameterized by comparing In cases where more than one data source are available for a single sample, issues of integrating non-monotonically increasing cumulative frequency data may arise. Rank-order problems also tend to occur when dealing with older digitized paper records or numerical data stored as strings. An  The following section illustrates the application of the numerical techniques described in The characteristics of the data set are summarized by the first four moments of the distribution, shown in  The results of the optimization simulation run for 4885 samples are presented in Modeled Bias in the inverse The precision of the inverse   The interpolation/extrapolation scheme described in Eqs. The results of the optimization simulations presented in Comparing the results of the two simulations show that equal-width particle-size categories are more effective at capturing data variability than equiprobable particle-size categories. This is surprising, in that Optimization simulations were also run with subsets of the data, ranging in number from just 100 to 1000 sub-samples, all of which were considerably more noisy than those generated by the complete data set. This suggests that optimal interpolation parameters are highly sensitive to the nature of the data set, and so cannot be considered representative of particle-size data in general. Furthermore, these findings imply that the introduction of particle-size data measured using another technique will markedly alter the optimum interpolation parameters. Firstly, multiple values of technique accuracy will need to be considered; the threshold or benchmark value would be provided by the least accurate technique. Secondly, running the simulations using data with differing particle-size categories will yield a mixed result signal. Ultimately, mixing particle-size data measured by laser-diffraction methods with another less accurate technique, will result in the reduction of the number of particle-size classes required to accurately characterize the data. A manual for using the numerical techniques presented in this paper is available online at The website provides links to examples of the different data formats that the toolbox is designed to work with. These files are freely available and can be downloaded in a range of commonly used formats. It is also possible to generate example data files from within the toolbox itself via the function A PDF copy of the website can be downloaded from the website for offline reading. Specific help on individual functions is provided natively within Matlab, accessed by entering The authors would like to thank D. Maljers, J. Staffleu, R. Harting and M. van der Meulen at TNO for providing access to the The calculation of the derivatives and co-efficients of a constrained cubic spline are given below for an The first order derivative The second derivatives of the third degree polynomial are then given as The first four moments of a grain-size distribution are commonly approximated by the graphic measures of The initial problem consists of four equations in seven unknown percentiles. Inspection of Eqs. Substitution of Eq. To provide an inverse solution for the above estimates, i.e. to derive estimates of the 5th to 95th cumulative percentiles from known graphic measures, the inter-percentile ranges are first solved. Substitution of Eq. Substitution of Eq. In the symmetrical case Note that the particle-size distribution symbols in the symmetrical case are given as The solution in terms of Substitution of Eq. The value of Substitution of Eqs. Range constraints on the solution given in Eqs. Evaluation of Eqs. Eq. Evaluation of Eqs. Substitution of Eqs. Eq. Order-relation problems of reconstructed percentiles will occur at the minimum value of graphic kurtosis, because Eq. In the limiting case Order-relation problems analogous to those given in Eqs. Another limiting case of Eq. Valid solutions to Eqs. In addition, there is a constrained subspace of solutions for highly skewed distributions, in which feasibility is determined by Eq. The solution space is shown in a Rhind diagram in A solution for resolving tied ranks is presented for use with the Inman–Conover monotonic regression method applied in Let if if