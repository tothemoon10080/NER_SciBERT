Multi-layer perceptron artificial neural networks are used extensively in hydrological and water resources modelling. However, a significant limitation with their application is that it is difficult to determine the optimal model structure. General regression neural networks (GRNNs) overcome this limitation, as their model structure is fixed. However, there has been limited investigation into the best way to estimate the parameters of GRNNs within water resources applications. In order to address this shortcoming, the performance of nine different estimation methods for the GRNN smoothing parameter is assessed in terms of accuracy and computational efficiency for a number of synthetic and measured data sets with distinct properties. Of these methods, five are based on bandwidth estimators used in kernel density estimation, and four are based on single and multivariable calibration strategies. In total, 5674 GRNN models are developed and preliminary guidelines for the selection of GRNN parameter estimation methods are provided and tested.GRNNs Xuyuan Li, Postgraduate Student, the University of Adelaide, School of Civil, Environmental & Mining Engineering, Adelaide, SA 5005, Australia +61 8 8313 1575 +61 8 8303 4359  64-bit AMD64, 64-bit Intel 64 or 32-bit ×86 processor-based workstation or server with one or more single core or multi-core microprocessors; all versions of Visual Studio 2012, 2010 and 2008 are supported except Visual Studio Express; 256 MB RAM PGI Visual Fortran 2003 or later version English 4.74 MB Free to download for research purposes from the following website: Over the last two decades, artificial neural networks (ANNs) have been used extensively in the field of hydrological and water resources modelling, and their popularity is still increasing (    Given the factors described above, it is generally not possible to isolate the impact of model structure on the predictive performance of MLPs, making it difficult to know which model structure should be used. In addition, the trial-and-error process generally used to determine the optimal structure of MLPs is computationally expensive, as it necessitates the development of a potentially large number of models. Although there are other alternative ANN based approaches, including Radial Basis Functions (RBFs) ( However, a potential issue with the application of GRNNs to hydrological and water resources problems is that there has been limited work on determining which smoothing parameter estimation methods should be adopted. As GRNNs are essentially a Nadaraya-Watson kernel regression method ( Among the extensive literature on smoothing parameter (or kernel bandwidth) estimation in other areas of research, such as mathematics and statistics, there are a number of different approaches to obtaining optimal estimates of kernel density, which are based on assumptions about the form of the PDF and different fitness function types (i.e. the objective function on which the estimator is based). Consequently, their relative merits for determining the optimal values of the smoothing parameters for water resources GRNN models are likely to vary from case study to case study, depending on the distribution of the data and the modelling objective function used. However, the relationship between the performance of GRNNs with smoothing parameters obtained using different kernel density estimation methods and the properties of the water resources data used to develop them has not been considered previously, making it difficult to know which methods to use for particular case studies. Therefore, the objectives of the current study are: (i) to compare the performance, in terms of both predictive accuracy and computational cost, of GRNN models for which smoothing parameters have been estimated using a range of methods, as well as that of a benchmark MLP model, for case studies with data that have varying degrees of normality, linearity and different modelling objectives (e.g. matching average or extreme events); and (ii) to develop and test empirical guidelines for the selection of the most appropriate methods for GRNN smoothing parameter estimation based on the properties of the available data (i.e. degree of normality and non-linearity) and the modelling objective. The remainder of this paper is organised as follows. A brief introduction to GRNNs is provided in Section According to Let: With respect the GRNN formulation, the expression in Eq. In Within this study, a slightly generalised version of the GRNN estimator in Eq. The approach to the systematic assessment of the performance of GRNNs with different bandwidth estimators is illustrated in As can be seen from Procurement of the synthetic data involved the generation of input data from distributions with differing degrees of normality, and the subsequent generation of the corresponding output data using synthetic models with different degrees of non-linearity. Data were generated from seven distinct distributions, including normal (NORM), log-normal (LOGN), exponential (EXP), gamma (GAMMA), Pearson type III (PT3), log-Pearson type III (LOGPT3), and extreme value type I (EVT1) (see The synthetic models used to produce the output data included a linear exogenous auto-regressive time series model (EAR4), a threshold exogenous auto-regressive time series model (TEAR10), and a nonlinear input–output function (NL) (see The first two synthetic models [Eqs. In order to further test the impact of the degree of normality and non-linearity of the data on the predictive performance and computational efficiency of the different GRNN parameter estimation methods investigated, as well as the performance of the empirical guidelines for the selection of the most appropriate methods for GRNN smoothing parameter estimation developed based on the results from the synthetic data, two case studies with data with different degrees of normality and non-linearity were selected. The first case study was concerned with forecasting salinity in the River Murray in South Australia one, five and 14 days in advance and the second with the prediction of runoff in the Kentucky River basin in the USA one day in advance. The data division procedure used for both real case studies was identical to the one used for the synthetic case studies (see Section The salinity case has been studied extensively in the context of ANN modelling (e.g. Analysis of the input data shows that the salinity based inputs are approximately normally distributed (average The rainfall-runoff problem from the Kentucky River basin has also been extensively studied in the ANN literature (e.g. Analysis of the input and output data shows that the distributions of lagged effective rainfall and flow are extremely non-Gaussian (averaged The parameters for all of the GRNN models for the synthetic tests and real case studies were estimated using nine methods. Of these methods, five are adopted from the literature on kernel bandwidth selection for kernel density estimation, and four are based on single and multivariable calibration optimisation strategies. The methods adopted from the kernel density estimation literature are: the Gaussian reference rule (GRR); biased cross validation (BCV); 2-stage direct plug-in (DPI); a combination of BCV and DPI (BCVDPI); smoothed cross validation (SCV). The methods based on calibration optimisation strategies are as follows: single variable calibration with squared error as the objective function (SVCS); single variable calibration with mean absolute error as the objective function (SVCA); multi-variable calibration with squared error as the objective function (MVCS); and multi-variable calibration with mean absolute error as the objective function (MVCA) ( The GRR based smoothing parameter estimator is the most commonly used estimator. It is based on minimising the asymptotic mean integrated squared error (AMISE) under the integrability assumption of an unknown probability function As with the GRR, the BCV ( As illustrated in The motivating idea behind the DPI ( The BCVDPI estimator is a combination of the BCV and 2-stage DPI, and is achieved by replacing the estimated term Although the BCVDPI has no closed form (it requires the solution of an optimisation problem), it inherits the positive attributes of a reduced dependence on the Gaussian assumption in comparison to the DPI. The optimal smoothing parameter by minimising AIMSE The fitness function and assumptions of the BCVDPI based approach are identical to those of the 2-stage DPI approach. The main difference between these two approaches is that the former uses GSS based optimisation due to the biased cross-validation procedure, while the latter does not. The concept behind SCV is very similar to that underpinning the DPI approach, except that SCV attempts to minimise the exact MISE, rather than the AMISE [Eq. By replacing Although the assumptions with regard to normality, linearity, and error basis of the SCV based method are very similar to those of the 2-stage DPI based approach ( The most commonly applied trial and error approaches to bandwidth estimation can be classified as single variable calibration (SVC) and multi-variable calibration (MVC). The SVC estimator assumes that a common smoothing parameter is applicable to all input vectors, which increases computational efficiency compared with the MVC estimator, for which smoothing parameter estimates have to be obtained for each input vector, but at the cost of potential reductions in modelling accuracy and flexibility ( In order to assess the performance of the different GRNN models in absolute terms, standard MLPs were developed as benchmarks using the systematic approach outlined in As mentioned in the Introduction and shown in As discussed in Although predictive accuracy was assessed using all of the six performance metrics mentioned above, only the performance based on the averaged IoAd and modified IoAd (MIoAd) is presented in the body of the paper, while the performance based on the other metrics can be found in the The adopted MIoAd is very similar to Eq. The reason for detailing the sensitivity of the performance criteria to the average trends and extreme events is so that an assessment of the impact of the error basis of the fitness functions used by the different smoothing parameter estimators on the performance of the GRNN models with different modelling objectives can be made. Computational efficiency was measured by computational time (CT) (measured by a dual processor 2.6 GHz Intel Machine), which was based on the average CPU clock speed (in seconds), as shown in The test regime was implemented in accordance with The predictive accuracy for the validation data and computational efficiency of all GRNN models for the synthetic data are summarised in Overall, the results indicate that the predictive performance of the GRNN models reduces as the degree of non-Gaussianity in the data increases, especially when the GRR, BCV, DPI, BCDPI and SCV methods were used for smoothing parameter estimation. This suggests that the DPI (or BCVDPI) and SCV methods are not consistently effective in improving the predictive performance of GRNN models for non-Gaussian data compared with using the GRR, despite their reduced reliance on the normality assumption and their increased computational cost. In fact, in many instances, use of these parameter estimation methods resulted in a decrease in predictive performance compared with that obtained using the GRR, particularly for the more extreme distributions (i.e. LOGPT3, EXP, LOGN in In contrast, use of the SVCS/SVCA and MVCS/MVCA methods was generally successful in terms of improving the predictive performance of the GRNN models for data with high degrees of non-normality compared with the models for which the GRR was used for smoothing parameter estimation. In fact, when the SVCS/SVCA and MVCS/MVCA methods are used, there is very little degradation in predictive performance with an increase in the non-normality of the data. This is most likely because these smoothing parameter estimation techniques do not rely on any Gaussian assumptions. This makes use of the SVCS/SVCA approaches a particularly attractive option for highly non-Gaussian data, on account of their much smaller computational cost compared with the MVCS/MVCA methods. While the trends described above apply to all three synthetic data sets, they manifest themselves more strongly for the non-linear (NL) case. This suggests that the combination of non-linear and non-Gaussian data has the potential to result in a marked degradation in the predictive performance of GRNNs, unless the SVCS/SVCA or MVCS/MVCA methods are used. It should also be noted that for the NL case, there was a noticeable improvement in predictive performance when the MVCS/MVCA approach was used instead of the SVCS/SVCA method. However, this improvement was achieved at a significantly increased computational cost. In the vast majority of cases, the predictive performance of the MLP models was similar to that of the GRNN models for which the SVCS/SVCA and MVCS/MVCA methods were used for smoothing parameter estimation, although the MLPs performed slightly better than the best-performing GRNNs in some instances. In addition, for Gaussian or nearly Gaussian data, the predictive performance of the GRNNs for which the GRR was used for smoothing parameter estimation was very similar to that of the MLPs. Consequently, the results suggest that if a bandwidth estimation technique is used that is appropriate for the distribution of the data, the predictive performance of GRNNs is very similar to that of MLPs. In addition, this can generally be achieved at a much reduced computational cost, unless the MVCS/MVCA bandwidth estimation technique is used. Furthermore, use of GRNNs eliminates the uncertainty associated with the selection of an appropriate MLP model geometry. Based on the findings of the 5670 computational experiments with the synthetically generated data, a set of preliminary empirical guidelines has been developed for selecting the most appropriate smoothing parameter estimation technique based on the degree of normality and degree of non-linearity of the data, as well as the modelling objective ( Based on    The results for the two real case studies are given in By considering the properties of the data for the salinity case study ( By considering the properties of the data for the rainfall-runoff case study ( As shown in Artificial neural networks (ANNs) have been used extensively for hydrological and water resources modelling over the last two decades. In the vast majority of studies, multi-layer perceptrons (MLPs) have been used as the ANN model architecture. However, obtaining the optimal structure of such models is not an easy task. By using general regression neural networks (GRNNs) as the ANN model architecture, this problem can be overcome, as GRNNs have a fixed model structure. However, there has been limited investigation into the best way to estimate the parameters of GRNNs. In order to address this shortcoming, the performance of nine different GRNN parameter estimation methods was assessed in terms of accuracy and computational efficiency for data with distributions of varying degrees of normality and non-linearity on both synthetic and measured data. In addition, the impact of the objective function on model performance was assessed. In total, 5674 GRNN models were developed as part of the computational experiments conducted. As a way of benchmarking, the predictive performance and computational efficiency of the GRNN models was also compared with that of MLP models. The main results from the synthetic case studies show that: The predictive performance of GRNNs developed using the GRR, BCV, DPI, BCVDPI, and SCV based methods was generally influenced by the distribution of the input/output data because of their dependence on the Gaussian assumption (assuming the underlying density follows a normal distribution). Compared to the GRNNs developed using the GRR, use of the DPI, BCVDPI, and SCV based methods did not effectively improve predictive performance, despite their decreased dependence on the Gaussian assumption and increased computational cost. The predictive accuracy of GRNNs developed using the SVCA/SVCS and MVCA/MVCS based methods was relatively insensitive to the distribution of the input/output data because of their independence of the Gaussian assumption. There is a distinct trade-off between predictive accuracy and computational efficiency for the methods investigated, with a reduction in computational efficiency for the methods that are least affected by the Gaussian assumption (i.e. SVCA/SVCS and MVCA/MVCS) by several orders of magnitude. If an appropriate smoothing parameter estimation technique is used, the predictive performance of the GRNN models is very similar to that of the MLPANN models, although slightly worse in some instances. However, the computational cost of developing the GRNN models is generally significantly less. In addition, there is no uncertainty in relation to the selection of the most appropriate model structure. Based on the general observations of the relationship between the performance of the different GRNN parameter estimation methods and the properties of the data and modelling objectives, preliminary empirical guidelines for selecting the GRNN parameter estimation method that represents good trade-offs between predictive accuracy and computational efficiency were developed. The validity of the guidelines was tested and confirmed for two case studies with real data, including the forecasting of salinity in the River Murray in South Australia and a rainfall-runoff study in the Kentucky River basin in the USA. While the results of this study provide useful insights and guidance on the selection of appropriate parameter estimation methods for GRNNs, further research into the possibility of improving the predictive performance of some of the methods that rely on the Gaussian assumption to some degree is warranted, as these methods are much more computationally efficient than the methods that are found to perform well with extremely non-Gaussian data in this study. In particular, the stage number used in the DPI, BCVDPI, and SCV methods may not be sufficient to describe extreme distributions with data accumulated at the boundary and a long tail. The boundary issue ( This research was aided by the suggestions and the original code of GRNN from Dr. Rob May and Dr. Greer Humphrey. 