Many models exist for describing the experimental results of batch adsorption which are used in research to study equilibrium, kinetics, and mechanisms of adsorption. In the process of statistically analyzing the experimental data, the adsorption literature contains errors that render the results unreliable. These errors include incorrect application of theoretical models and also incorrect application of statistical analysis. Some errors are so abundant in the adsorption literature that they have actually gained credibility and mistakenly taken for granted that these are sound scientific practices. This article highlights some common errors in adsorption data analysis that are frequently found in the literature and provides suggestions for more sound practices.In the course of data analysis, statistical methods are applied to fit experimental data to models and to assess statistical inferences. There is an abundance of software for statistical calculations which come as stand-alone commercial programs, as part of commercial spreadsheets or as shareware and freeware. However, the availability of good software does not ensure a correct statistical analysis. Prerequisites for the correct use of software are a familiarity with the basics of statistics; a knowledge of the assumptions and limitations of each statistical technique; and the ability to choose the appropriate method of analysis. Uncritical use of statistical software may lead to applying the techniques incorrectly, or even using statistical methods in cases where they are not appropriate. In the field of batch adsorption research, certain errors in data analysis keep showing up over and over again. They show up in top ranking journals and are so abundant in the adsorption literature that they have actually gained credibility. New comers to adsorption research may take it for granted that these are sound scientific practices and spread the errors even more. The objective of this article is to highlight some of these errors and to provide suggestions for more sound practices. For clarity, a few specific examples are taken as prototypes from the literature. In the choice of these examples, articles were chosen to represent several journals and authors from different countries. The misuse of linearization is probably the most common error in data analysis. It originated many decades ago when computers were not yet available and it has not lost its popularity today. There are problems associated with trying to linearize an inherently nonlinear equation by use of various transformations. The main issue when transforming data to achieve a linear equation is knowledge of the error-structure of the data and how this structure is affected by transformation. When the errors are additive on the dependent variable ( Typical examples are adsorption isotherms and adsorption kinetic models. These equations are nonlinear, i.e. the observed response (dependent variable) does not depend linearly on the independent variable. The transformed (linearized) response function is used for the quantitative evaluation of the parameters by linear regression. For example, the nonlinear form of the well-known These linearized forms are used extensively in adsorption literature. The structure of experimental error is transformed along with the data (in some cases leading to loss of homo-skedasticity), and a basic assumption of the least squares method (i.e. that the independent variable has only a negligible error) is sometimes violated. Moreover, the statistical tests used to check the goodness of fit will often not detect that the parameters are biased.  A common practice in research is to fit the experimental data to several models, then perform some kind of test to compare and decide which model fits the data better. Based on the choice of the “best model”, conclusions about the intricate mechanism of the system are often available. The most popular tool for model comparison is the coefficient of determination, In spite of the apparent simplicity of interpreting    The first two issues with This is especially common in adsorption studies when it comes to estimating thermodynamic parameters and it is also found in other cases such as isotherm and diffusion calculations ( The estimated slope is highly uncertain because zero is within its 95% confidence interval, and consequently, there is no evidence that the slope is different from zero. Therefore, the apparent variation of ln The previous analysis does not prove that ln For a fixed sample size, increasing the number of regression parameters leads to a decrease in the degrees of freedom, and almost universally decreases It is customary in batch adsorption studies to fit the equilibrium uptake data to several isotherms, then to use Akaike's Information Criterion (  This comparison method is illustrated using isotherm data from a recent study ( The results of nonlinear regression, published in the study, are presented in Webber's pore-diffusion model ( It can be seen from Eq. It follows from the previous discussion that it would be a good practice to examine pore-diffusion plots and decide how many linear segments exist. When a group of points are identified as belonging to a linear segment, linear regression can then be applied to these points and the corresponding After equilibrium is reached For the purpose of this illustration,  Another common practice is to detect and acknowledge segments, then automatically dismiss the first segment(s) as a period where film-diffusion is controlling the rate of adsorption ( Here the published study ( By analyzing the data in In 1947 Boyd et al. published their legacy series of papers, where they presented theoretical models for ion-exchange that simulate equilibrium ( If diffusion inside the pores is the rate limiting step, the following equation was derived ( From Eq. In order to apply this model to experimental data, the right-hand sides of Eqs. The following distorted equation of Boyd's pore-diffusion model is found in many recent publications: This is graphically illustrated in Statistical analysis and hypothesis testing are universally accepted as The misuse of linearization (linear transformation) is probably the most common error in batch adsorption literature. In the past, researchers needed to transform their data into a form suitable for simple linear regression, but in the present age computers and software are easily available to do this instead. In order to justify a transformation two conditions should be met: The error-structure of the experimental data is known to violate some assumptions of the least squares method. A specific transformation is expected to change the error-structure to better satisfy these assumptions. If these conditions are not met, then there is no point in linearizing the data.  Webber's pore-diffusion model is often abused in batch adsorption studies. This is mainly manifested in the disregard of segments or mismanagement of segmented data. It is recommended that pore-diffusion plots are examined carefully and segments, if present, identified numerically by PLR. It would also be beneficial to have as many kinetic data points as possible if Webber's model is a candidate for data analysis. This would ensure having a reasonable number of points in each segment and thus obtaining statistically significant estimates of the diffusion parameters. A distorted version of Boyd's pore-diffusion model is widely spread in the literature. Using this distorted model leads to wrong estimates of