Rock bursts constitute serious hazards in underground mining and excavating. Up to now, numerous researches in the form of empirical, experimental, analytical, intelligent and numerical methods with their own specific scope, characteristics, strengths and weaknesses, have been conducted for rock burst prediction. The weaknesses and limitations of the mentioned prediction methods, especially the intelligent studies, indicate the need for continuing the researches in this field. In this research, a rock burst database, consisting of 188 datasets, was considered. Each dataset corresponds to a series of predictor variables and one of defined classes for the dependent variable “rock burst intensity”. To design classification models, describing important characteristics of datasets and predicting future trends, a data preprocessing procedure was conducted. The procedure consisted of a statistical analysis strategy, a metaheuristic technique for feature (variable) subset selection and some feature extraction techniques. The statistical analysis led to conclude that by considering the available datasets, some predictor variables have statistically insignificant contributions for rock burst prediction. By contrast, the other predictor variables have considerable ordinal contributions. These statistical inferences were completely in accordance with the results of the feature subset selection technique. Besides, the application of this technique revealed specific combinations of significant predictor variables having the highest priorities for modelling the dependent variable. The application of feature extraction techniques to construct derived components from initial datasets did not lead to representative results. Therefore, a high rank combination of significant predictor variables can be adopted to design and develop new classification models based on the considered datasets.Ratio of the uniaxial compressive strength of rock to the maximum principal stress Ratio of the maximum tangential stress to the uniaxial compressive strength of rock Ratio of the uniaxial compressive strength of rock to the maximum in-situ stress Ratio of the tensile strength of rock to the maximum in-situ stress Ratio of the uniaxial compressive strength of rock to the maximum principal in-situ stress Ratio of the maximum in-situ stress to the uniaxial compressive strength of rock Ratio of the maximum tangential stress to the uniaxial compressive strength of rock Ratio of the uniaxial compressive to the tensile strength of rock Elastic energy index Rock mass intact coefficient Classification and laboratory test method on bursting liability which includes determining the following factors: Uniaxial compressive strength of rock Elastic energy index Bursting energy Dynamic failure duration Rock burst phenomenon, usually causing injury to workers, damage to equipment and even substantial economic losses and delays, is one of the common dynamic instability modes in underground mining and excavating in hard, brittle and relatively unfractured surrounding rock strata ( Rock burst is an extremely complex phenomenon influenced by multiple factors. How to obtain comprehensive characteristics of rock bursts during the nucleation and evolution processes remains an unresolved problem ( According to Rock bursts occur in the unloading process of excavation and their characteristics are closely related to the deformation and failure characteristics of the rock. Most of them involve tensile or composite tensile-shear failure ( Rock bursts in shallow depth (overburden thickness) occur with low frequency. Their frequency and severity seem to increase with depth. However, depth is not the only factor that can contribute to rock burst. Bursts have been reported in excavations under only 300 m. By contrast, some underground operations have been excavated at depth greater than 1500 m without bursts. This indicates that site-specific conditions other than depth are also important factors ( Rock burst have three different stages including the inactive, active and destructive. In the inactive stage, there are few events of accumulated stress releasing. In the destructive stage, in addition to the rock collapse, many medium sized and minor rock bursts are often triggered by one large scale rock burst. For a period, the whole affected area is very active. So, the active stage is the state between the inactive and the destructive stages (Wu et al., 2002). Rock bursts usually happen with a few hours of the excavation, but in some cases they can occur long after the excavation. The maximum principle stress controls the position of energy accumulation after the excavation and consequently the rock burst. The strain energy can again accumulate despite the fact that previous rock bursts had released some of the near-surface energy in the strata as a consequence of high geo-stresses ( There are still great challenges to better predict and control of the phenomenon in the field of mining, geo-mechanics and strata control. The rock burst hazard prognosis influences the choice of suitable excavation method (conventional or mechanized), cross section form and especially excavation support ( The overall purpose of this research is to recognize predictor variables or components having significant contributions to classify different classes or categories of dependent variable of a database by using different statistical and data mining techniques, in order to predict rock burst occurrence and intensity potential during initial stages of underground mining and excavating projects. This comprehensive analysis of the considered datasets, frequently used in the previous researches, reveals their different characteristics and their effectiveness in discriminating the different classes of the dependent variable, as well. Considering the coal burst or outburst phenomenon is out of the scope of the research. Rock burst common prediction methods can generally be classified as empirical, experimental, analytical, intelligent (including data mining techniques) and numerical. However, none of these methods is totally complete and valid and they have their own advantages and disadvantages. In the empirical methods, having been widely employed, different assessment indexes or indicators are considered ( In the field of experimental rock burst prediction, there are some distinct conducted experiments. However it should be kept in mind that rock burst as a stress induced rock failure process is a phenomenon of confining stress decrease and energy release. It could not be simulated and explained by the mechanical characteristics of rock during triaxial compressive loading. Rock burst has been studied by conducting brittle failure tests in compression with low stiffness machines. Some researchers attempted to classify rock burst potential with complete stress-strain curves of rock material obtained from compression tests, but the curves indeed reflect the combined characteristics of testing machine, loading rate and rock material. Therefore, it is not an intrinsic property of rock material and should not be used to explain rock burst failure mechanisms. Laboratory experiments should be conducted to simulate stress decrease and the resulting rock failure process ( There are several theories such as strength, stiffness, energy, inclusion, mutation, rigidity, defect, energy disturbance, burst liability, instability, catastrophe, bifurcation, dissipative structures and chaos to study the deformation and stability of mechanical system in rock and mechanism of rock bursts ( Up to now, many of developed prediction methods have been based on the application of the intelligent techniques including rule-based and data-driven studies. In these studies, often with qualitative outputs, some stress and strength related components or new defined indicators (based on the former) are considered as the inputs. However, training and performance of the models greatly depend on considered datasets, data preprocessing procedure and training parameters. In the case of rule-based models, training also depends on considered rules (often some empirical criteria). The most cited applications of intelligent techniques are reported in Due to the complexity of rock bursts, serious limitations in modelling the transition from continuous to discontinuous behavior and development of numerical programs based on small displacement rule, it is very difficult to use numerical methods to realistically model the dynamic behavior that takes place during the build-up and occurrence of rock bursts. For this reason, most numerical simulation techniques focus on static methods of estimating rock burst risks, analyzing rock mass failure and optimizing preventative measures. Although the static method cannot reflect the dynamic characteristics of a rock burst, it can still reveal the progressive evolution of failures through the surrounding rock mass. So, it is also an important way to qualitatively interpret the macro mechanism of a rock burst ( In spite of numerous rock burst reports around the world, the number of described cases with available or reported values for different representative factors or predictor variables is quite limited. The under-review database consists of 188 distinct case-histories (datasets) of rock burst events occurred in underground mines and excavations around the world. It has been extracted through the related studies and includes 3 datasets from        Besides, each dataset corresponds to one of four classes or categories of “none (not-occurred), weak, moderate and strong intensity” as the values of the dependent variable “rock burst intensity”. The general characteristics of different rock burst intensities are reported in The collected datasets have the common characteristics and features of most rock bursts and have substantial information fields reflecting: overall stress condition and stress anisotropy in a point deformation, failure and strain energy storage characteristics of rocks However, they do not contain any detail description about the geological, geo-mechanical and technological conditions, the associated seismic events or any other information field corresponding to an affecting factor on rock burst phenomenon. On the other hand, it is a fact that the geological, geo-mechanical and technological conditions cannot be quantized easily into tangible predictor variables. Due to this limitation of the available datasets, they cannot be separated into specific categories. All the mentioned data-driven studies also suffer from this limitation. Among the predictor variables, maximum tangential stress and stress ratio are those which have been obtained through different methods (determining based on in-situ measurements or estimating based on the developed analytical solutions or numerical models). Obviously, different methods will result in different answers. Nevertheless, only the alternatives (of all possible measures for the mentioned methods) should be chosen (based on the specific geo-mechanical and geological conditions of projects) that estimate reasonable and reliable answers not having considerable differences with the actual values. In contrast, the other predictor variables have been estimated based on unique procedures. This point which has existed in all previous data-driven researches, is one of the intrinsic characteristics of the rock burst database. The collected datasets have numerous missing values that makes their simultaneous application hard and often impossible. Different variable arrangements with their corresponding maximum available datasets, are presented in The considered database is comprehensively introduced and graphically depicted in Appendix-Section A. Classification, as a unique field in data mining, is the process of finding a model or function that describes and distinguishes data classes or concepts, for the purpose of being able to use the model to predict the class of datasets whose class label is unknown. Data preprocessing techniques are applied to the data to help improve the accuracy, efficiency and scalability of the classification process. There are a number of data preprocessing techniques which can substantially improve the overall quality of mined patterns and be categorized as data cleaning (to identify noises and outliers and to correct inconsistencies), data integration (to merges data from multiple sources), data transformation and data reduction (including numerosity and dimensionality reduction). These techniques are not mutually exclusive and may work together. Classification process may need to be preceded by a relevance analysis which attempts to identify predictor variables that do not contribute to the process. These predictor variables can then be excluded ( The application of statistical techniques in any research, requiring data collection and analysis, is vital. Producing descriptive characteristics and extracting inferential information can be noted as the most important purposes of using the statistical techniques. Outlier detection and substitution with reasonable values are essential before database analysis. There are different methods and sub-approaches for outlier detection. These methods can generally be classified as univariates and multivariates. Each of these methods and sub-approaches has its own assumption and limitation and thus may bring different results in comparison to the others ( Statistical methods and techniques are based on various basic assumptions. One of the common assumptions which should be examined during analyzing a database, is the normality condition. When this assumption is violated, inference and interpretation may not be reliable or valid ( Now, the question is whether the differences between the means or the distribution functions of the predictor variables in different classes are statistically significant or not? To answer, the acceptance or rejection of mean-equality and distribution function-equality hypotheses are evaluated using the statistical tests for 95% confidence level. Selecting the type of the statistical tests, including parametric and nonparametric, depends on the nature and characteristics of samples and inferential aspects. If samples follow a normal distribution or their frequency is so great that they can be considered as normally distributed (according to the central limit theorem), parametric tests can be used. Otherwise, nonparametric tests are preferred. Most of parametric tests have nonparametric counterparts. Although parametric tests generally have higher accuracies than the nonparametric tests, the later have their own specific and distinguishing features. They do not require any assumption about data distribution and are useful for small sample or ordinal data problems ( Since there is at least one class, not having normality condition, for all the predictor variables, the nonparametric test “Kruskal-Wallis” is chosen to compare their means. The results of the test are reported in By applying Jonckheere-Terpstra test for comparing distribution functions of the predictor variables ( According to two-sample Kolmogorov-Smirnov test results, all of distribution function-equality hypotheses are rejected for the predictor variables “maximum tangential stress and stress ratio” and by contrast all of them are accepted for the predictor variable “uniaxial compressive strength of rock”. In the case of the predictor variable “tensile strength of rock”, 4 of 6 comparisons correspond to the acceptance of distribution function-equality hypothesis. Only 1 of 6 comparisons is accepted for the predictor variable “elastic energy index”. Wald-Wolfowitz run test results (for two possible values of the statistic) are generally in accordance with the previous test results. However, there are some differences. Among them, the items “not rejecting all of distribution function-equality hypotheses for the predictor variables maximum tangential stress and stress ratio” and “not accepting all of them for the predictor variable uniaxial compressive strength of rock” can be noted. Correlation analysis is a statistical tool for determining the type and intensity of relation between two arbitrary variables. Correlation coefficient is one of the commonly used criteria for interaction analysis. The coefficient reflects the relation’s type (including positive, not-related and negative) and its intensity in the range of [-1, 1]. If there is not any statistically significant relation between variables, the coefficient will be assigned “zero” value. There are two different options for determining the correlation coefficient between numerical or numerical-ordinal variables. For variables following a normal distribution or “numerous sample” problems, Pearson correlation coefficient is used. Otherwise, another coefficient, presented by Spearman, is preferred. Spearman correlation coefficient is designed based on rank of data (not their original values) and has less prerequisites than Pearson coefficient. The significance of correlation coefficient, determined through a related statistical test, has an important role for making a decision whether the obtained coefficient is by chance or there is actually a relation between variables. The null hypothesis of the test is that there is a statistically significant correlation between variables ( According to the brief outcomes reported in Since the effects of other predictor variables are not excluded during the coefficient calculation process, they may impress the results. Thus a solution must be considered. Partial correlation coefficient is usually used for the task in which the effect of one variable can be excluded (controlled) by the technique. Due to the known relations among “maximum tangential stress, uniaxial compressive strength and stress ratio” or “uniaxial compressive strength, tensile strength and brittleness ratio”, all possible pairwise relations with controlling the effects of impressing predictor variables are studied. As well as, since the predictor variable “tensile strength of rock” has a remarkable positive relation with the predictor variable “uniaxial compressive strength”, the relations of “tensile strength of rock and elastic energy index” and “tensile strength of rock and intensity” are checked by controlling the effect of the aforementioned predictor variable. The results are reported in After passing the steps, the following statistical inferences can be inferred: Due to the equality of group means and distribution functions of the predictor variables “overburden thickness” and “brittleness ratio” and the statistically insignificant correlations between these variables and the dependent variable, it is concluded that these variables with available datasets will have insignificant contributions to rock burst prediction. Similarly, due to the equality of group means and distribution functions in several pairwise comparisons of the predictor variable “tensile strength of rock” and not having a statistically significant correlation with the dependent variable, it is concluded that this variable will have an insignificant contribution to rock burst prediction, too. On the other hand based on this procedure, the predictor variables “maximum tangential stress” and “stress ratio” will have a remarkable contribution. Although, these variables have a high correlation to each other and “not forming a multi-collinearity situation” rule should be considered in their simultaneous application. Since some of the group means and distribution functions of the predictor variable “elastic energy index” are statistically equal, this variable will play a less important role than two previous variables. With the same attitude, since several pairwise equality hypotheses for the predictor variable “compressive strength of rock” have been accepted, this variable will play the dimmest role of all significant variables. These inferences are totally in accordance with the results of two types of tests to examine the significance of individual predictor variables in regression analysis for qualitative dependent variables, including: The likelihood ratio test that evaluates the overall relationship between a predictor variable and the dependent variable. The Wald test that evaluates whether a predictor variable is statistically significant in differentiating different classes of the dependent variable or not. In this section, the application of a feature or variable subset selection approach, incorporated the second version of Non-dominated Sorting Genetic Algorithm (NSGA-II) and feed forward Multi-Layer Perceptron (MLP) artificial neural networks as the common classifiers, for detecting significant predictor variables are presented. NSGA-II, presented by The results of solving the feature subset selection problem for different predictor variable arrangements and their related available datasets, with the parameters expressed in In this research, factor analysis and nonlinear principal component analysis approach using auto-associative neural networks are conducted to extract predictor components, rather than original predictor variables, with the aim of resulting in prediction models with higher accuracy. Factor analysis is a statistical method for reflecting infra-structural relations among variables, recognizing latent principal factors or components and reducing dimension in which original variables are placed in the factor or component structure. A factor or component is formed by a linear combination of some original variables. Number of factors is less than or equal to number of original variables. Contribution of factors to express data variation decreases in an ascending order and effective variables are those placed in primary factor structures. Factor analysis procedure includes following steps ( Evaluation of data suitability for factor analysis: In this respect, two main issues of “sample size and intensity of relations among variables” should be considered. For the first issue, it is recommended that the ratio of sample number to variable number should be equal to or greater than 20 or according to some references, should be equal to or greater than 10. For the second issue, there are two statistical indexes including Kaiser-Meyer-Olkin (KMO) measure of sampling adequacy and Bartlett's test of Sphericity. Value of KMO index is in the range of [0, 1] and is compared with 0.6 as the minimum acceptable value for factor analysis conducting. In Bartlett test, being known or in other words, identity of correlation matrix is checked. The null hypothesis is that the correlation matrix is an identity one. In the case of an identity correlation matrix, variables will not have significant relations together and therefore new factors cannot be defined. Factor extraction: This step includes determining minimum number of factors or components by which correlations between variables can be represented in the best way. There are different but related extraction methods resulting in correlated or non-correlated solutions. Researcher should determine number of factors describing relations among variables in the best way. There are different methods to make a decision for adequate number of factors. Rotation and interpretation of extracted factors or components: Extracted factors should be rotated to maximize the relationship among variables and factors. Factor rotation will not change solutions but the pattern will be presented in a manner that is easier to interpret. The results of applying factor analysis procedure with principal component analysis method for factor extraction, Kaiser criterion for determination of adequate factor number and Varimax method for rotation are reported in  Despite abundant researches and due to their weaknesses and limitations, there is still a need for development of proper methods for rock burst prediction. Many classification and prediction models have certain presumptions about the characteristics of datasets. Employing these models without considering different aspects of datasets may result in misleading outputs. This matter shows the importance of data preprocessing procedures, including statistical and data mining-based steps, in data-driven researches. The expressed statistical inferences have a perfect adaption with the results of significance tests of predictor variables in regression analysis and feature subset selection procedure. It was demonstrated that all predictor variables are not necessarily effective in modelling the dependent variable. The simplicity of obtaining or determining based on standard procedures is not a guaranty or precise criterion for a predictor variable to be effective in a data-driven research. On the other hand, the considered linear and nonlinear feature extraction techniques did not lead to representative components to develop classification models. Thus, instead of using all the original predictor variables, the significant variables can be used to design and develop new classification models without being concerned about the prediction accuracy. Since, the combination of the predictor variables “stress ratio” and “elastic energy index” is constantly a high-ranked answer in every predictor variable arrangement and its related available datasets, it can be adopted as a reasonable choice of prediction models’ considered inputs. The characteristics and limitations of the collected datasets make the inferences and conclusions about the contributions or significances of the predictor variables. The obtained results are only based on and indefeasible for the present database. If new numerous datasets are collected and added to the database, the research results may be changed. It is emphasized that the predictor variables “overburden thickness, tensile strength of rock and brittleness ratio” are not universally ineffective but they have insignificant contributions based on the collected datasets. The described procedure and consequent applications can be generalized to new collected databases in the future, to determine whether the inferences remain constant or not. The collected datasets, values of the predictor variables in different classes and some important scatter diagrams between them are depicted in The values of extracted components for different normalized predictor variable arrangements (in the rage of [−1, 1]), maximum number of corresponding datasets and desired number of extracted components are presented in