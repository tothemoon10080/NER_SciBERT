Obtaining accurate information on rock mass discontinuities for deformation analysis and the evaluation of rock mass stability is important. Obtaining measurements for high and steep zones with the traditional compass method is difficult. Photogrammetry, three-dimensional (3D) laser scanning and other remote sensing methods have gradually become mainstream methods. In this study, a method that is based on a 3D point cloud is proposed to semi-automatically extract rock mass structural plane information. The original data are pre-treated prior to segmentation by removing outlier points. The next step is to segment the point cloud into different point subsets. Various parameters, such as the normal, dip/direction and dip, can be calculated for each point subset after obtaining the equation of the best fit plane for the relevant point subset. A cluster analysis (a point subset that satisfies some conditions and thus forms a cluster) is performed based on the normal vectors by introducing the firefly algorithm (FA) and the fuzzy c-means (FCM) algorithm. Finally, clusters that belong to the same discontinuity sets are merged and coloured for visualization purposes. A prototype system is developed based on this method to extract the points of the rock discontinuity from a 3D point cloud. A comparison with existing software shows that this method is feasible. This method can provide a reference for rock mechanics, 3D geological modelling and other related fields.A rock mass usually contains "planes of weakness". These planes of weakness occur at all scales and have a statistical distribution of spacing and orientation ( Remote sensing techniques can be used to acquire three-dimensional (3D) information from the terrain with high accuracy and high spatial resolution ( The remainder of this study is organized as follows. In recent decades, many scholars have studied non-contact measuring methods, such as close-range photogrammetry, laser scanning measurements, and the fusion of these two methods ( We can manually or semi-automatically extract information on discontinuities according to 3D geological models that are based on point clouds or that directly handle 3D point cloud data ( In substance, the extraction of discontinuity sets based on a 3D point cloud is a point cloud classification problem, namely, to distinguish points that belong to different discontinuities. The classical classification method, which is known as the FCM algorithm, is simple and relatively rapid ( In this study, a method that combines the FA and FCM algorithms and is based on point cloud classification is proposed to semi-automatically extract the joint points from extensive 3D point cloud data. The optimal number (number of discontinuity sets) is determined by the clustering parameters. The extraction process of rock mass discontinuity sets is designed as follows: ( Original data pre-processing. Data partitioning: the imported data are segmented into point subsets according to the octree method or a fixed size cube. Factor calculation: the orientations of the best fit plane of the subsets are computed by the LS method or PCA. A stereographic projection is applied during the analysis of the orientation data using Dips (available on Cluster analysis: the FA is used to obtain the initial cluster centres, and the FCM algorithm is used to calculate the best classification result. Merging and displaying of the results: clusters that belong to the same discontinuity are merged and displayed in the same colour in the 3D frame. Three cases were used in this study: three field point clouds with different numbers of points and different numbers of discontinuity sets. Case study 1 was intended to provide a comparison between this method and the DSE software. The data from case study 2 were used for the parameter sensitivity analysis. The data from case study 3 were used to test the efficiency of the proposed method. (1) Case study 1. The data from case study 1 ( (2) Case study 2. The laser scanning data from case study 2 were obtained from (3) Case study 3. The laser scanning data from case study 3 were obtained from The density of a 3D point cloud enables us to consider point subsets that meet the coplanarity conditions as a whole, which can improve the efficiency of point cloud processing. The advantage of point cloud segmentation is that the original point cloud can be directly analysed without surface reconstruction ( The noise points in the cube both influence the orientation of the fitting plane and may lead to judgement errors regarding whether a cube is available. Therefore, data pre-processing was performed before the data partitioning to remove outlier points, such as points of vegetation, dust and insects. These points reduced the accuracy of the point extraction when determining the discontinuity and increased the execution time. Thus, these noise points had to be removed before the discontinuity extraction. These isolated outliers could be automatically removed with software (CloudCompare and Geomagic). However, the number of these points was relatively small, and the characteristics of these points were unclear ( If the original point cloud is uniformly distributed, the 3D point cloud can be divided into equally sized cubes to avoid great differences in the number of points in each subset. Data partitioning is actually the gridding of a point cloud. A cube of fixed size ( The cube size was decided by the density of the point cloud and the roughness of the rock mass. Point clouds that were obtained by different laser scanners with different minimum angle steps or different angles of incidence for the laser beam ( Segmenting a point cloud with a fixed cube is simple and convenient, but the size of the cube must be set in advance. The octree approach was used to segment the point cloud in this work to improve the segmentation and management of points. The minimum bounding box of a point cloud was considered the “root node” of the octree, which was then segmented into 8 equally sized sub-cubes. Sub-nodes that met the constraint conditions were not split further. Otherwise, the corresponding sub-cubes continued to be divided into 8 equally sized sub-cubes until the entire space cube met the constraint conditions. Two parameters were set during this step: the minimum number ( The LS can be used to calculate the fitting plane equation of point subsets ( PCA is based on dimensional reduction, namely, transforming multiple indicators into a small number of the most important indicators. Therefore, this method is very efficient and suitable for the calculation of a large amount of point cloud data ( The normal vector of the fitting plane After the orientation data were obtained, the pole density contour map ( Different discontinuities have different directions, so the cluster analysis method is based on the normal vector. A pole in a stereographic projection refers to the dip direction and dip angle (also called the orientation) of a cluster of points in the 3D space within a cube. Here, we clustered these poles mathematically while actually clustering these clusters of points. The classical clustering algorithm FCM is a local optimization algorithm, and the initial centres and number of discontinuity sets are specified by the user, which results in a lack of objectivity. If the initial centres are not reasonable, a satisfactory result cannot be obtained. The FA has global convergence, and the convergence speed is fast ( Therefore, the FCM algorithm is considered the optimal algorithm for the cluster analysis of directional data from rock mass discontinuities ( The dataset was The update of the centres is The principle of the FA is as follows. Each firefly represents a solution to the problem, namely, a group of cluster centres ( In nature, the brightest firefly will attract fireflies with less brightness. Based on this algorithm, the optimal solution of the problem can be obtained via iteration. The firefly The firefly attraction The distance between the fireflies is set as the sum of the distances between the corresponding centres: When using the FA in the classification of clusters, the first step is to initialize the parameters, namely, the number of fireflies Firefly Algorithm First, the initial position of the fireflies The final optimal solution results in the best centres. The membership matrix can be calculated according to formula (6). Then, the cluster analysis and merging of clusters in the same group are performed. The optimal feature number is automatically decided by an introduced cluster validity function. The clustering validity evaluation method provided the evaluation results of the clustering results in the form of clustering parameters based on an evaluation of the density and dispersion degree of the clustering results ( Based on this workflow, a prototype system was developed based on the QT framework, and three experiments were performed on a ThinkPad laptop (1.7_GHz(R) Intel Core i5-4210U, 8 This method involved the deletion of point outliers (vegetation points, isolated points, and noise points) and an analysis of the influence of the aforementioned process.  Riquelme ( Sensitivity tests were conducted in this study, including the determination of suitable parameters to obtain better results. The data from case study 2 were used to perform a size sensitivity analysis experiment. Different cube sizes, which influenced the results ( Coplanar detection was performed to ensure that the points in the subset belonged to one plane. Clusters that did not meet the coplanar conditions may have contained boundary points and vertices. The Case study 3 (more than two million points) was introduced to further verify whether this method still had high efficiency for data with a large number of points. The results showed that the processing of case study 3 took a total of 1 A new method for extracting joint points from 3D point clouds was proposed in this study, and a prototype system was developed to conduct the experiments. Data with different number of points were processed with different methods. The results of case study 1, which used three different methods (the proposed methods and DSE), were compared in In this method, the FA with global optimality was used for the rock mass discontinuity extraction process based on the 3D point cloud. Meanwhile, not all points had to be calculated, which avoided redundant computations. This method was only based on raw point clouds without any complex triangulation and the establishment of a 3D model of the geological body. The quality of the results when using different methods (the proposed methods and DSE) was also compared in Considering the limits of point cloud segmentation, some deficiencies had to be handled: (1) points near the boundary could not be accurately classified because the cube at the boundaries contained at least two discontinuities,; and (2) accurate boundary lines could not be obtained. Addressing these problems will be the focus of the authors' future work. We acknowledge and thank the Editor-in-Chief Professor Gregoire Mariethoz and the three reviewers, namely, Professor Siefko Slob, Professor Adrián Riquelme, and an anonymous reviewer, for their thoughtful and constructive comments on this manuscipt. The laser scanner raw data from case study 1 were privately provided by Siefko Slob, and the data for case study 2 were obtained from his personal website at Research Gate ( Supplementary data associated with this article can be found in the online version at 