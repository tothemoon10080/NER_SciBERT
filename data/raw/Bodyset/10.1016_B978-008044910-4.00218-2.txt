Quantitative economic geography (the use of mathematics to conceptualize economic geography and advance propositions about the nature of the observable spatial economy) emerged in economic geography through research on location theory and spatial interaction during the 1960s. Alongside theory construction, methods of spatial statistical analysis were developed to evaluate the empirical predictions and fit of such theories. This approach was reinvigorated by economists during the 1990s, developing a perspective that has been dubbed ‘the new geographical economics’. Notwithstanding associations within this literature, and beyond, of quantitative reasoning with neoclassical economic geography and logical empiricism, a different kind of quantitative economic geography also emerged in the 1990s: regional political economy. While both approaches use mathematical reasoning to develop their theories, regional political economy is distinctive in its association with Marxian political economy; its conclusion that the capitalist space economy is not self-regulating but exhibits persistent out-of-equilibrium dynamics; its treatment of the spatiality of political economic processes as endogenous rather than exogenous to those processes; and its rejection of logical empiricism in favor of sociospatial dialectics. Quantitative economic geography is, thus, much more diverse than is generally presumed.Quantitative economic geography has, at various times, taken one or more of three forms. First, dating back to the commercial geography of the nineteenth century, is the collection and cataloging of numerical statistics about the geography of economic activities and communications costs. Second, dating back to the ‘quantitative revolution’ in Anglo-American human geography, is the use of statistical methods to explore, and test hypotheses advanced, concerning, spatial relations between economic and other related variables (utilizing quantitative as well as qualitative data). Third, also dating back to the ‘quantitative revolution’, is the use of mathematics as a language to advance theoretical propositions about the spatial organization of economic activity, and the economic evolution of landscapes. Much of the attention that quantitative economic geography receives in the scholarly literature is devoted to how and whether the economy can adequately be captured through the collection and statistical analysis of economic and other related data, and about the relative merits of quantitative and qualitative empirical research methodologies. Neither of the first two forms raises issues specific to economic geography, however, notwithstanding that quantitative data and methods are of particular relevance in economic geography, due to the nature of economic concepts and information. We thus focus here on the use of mathematics to conceptualize economic geography and advance propositions about the nature of the observable spatial economy. With very few exceptions, mathematical economic geography has concerned itself with analyzing the spatial dynamics of capitalism, notwithstanding the coevolution of a variety of other economic systems (e.g., socialist, subsistence, slavery, feudal, and community economies) at various times, and in all kinds of places. The use of mathematics to theorize economic geography can be traced back to continental European economists, particularly Alfred Weber (1868–1958), Tord Palander (1902–72), Johann von Thünen (1783–1850), and August Lösch (1906–45), as well as the German geographer Walter Christaller (1893–1969) and the American political scientist Harold Hotelling (1895–1973): ‘location and spatial interaction theory’. Within geography, an initial flourishing of quantitative economic geography occurred, starting in the late 1950s, with the initiative of US based geographers Edward Ullman (1912–76), William Garrison (1924–), and Brian Berry (1934–); British geographer Peter Haggett (1933–); and Swedish geographer Torsten Hägerstrand (1916–2004), the quantitative revolution began with economic geography. In the early 1990s, this approach was reinvigorated within economics as a result of new mathematical models pioneered by the American economist Paul Krugman (1953–): Under the aegis of the quantitative revolution, and drawing on the preexisting scholarship noted above, economic geographers sought to develop mathematical theorems to describe the spatial organization of a market economy. The bulk of this research, under the label of ‘location theory’, sought to determine the optimal (i.e., profit maximizing or cost minimizing) point location for individual capitalist enterprises, within the continuous space of a market economy. Industrial location theory sought to identify the point where aggregate transportation costs, for both assembling inputs and marketing the commodity produced, are minimized. Central place and retail location theory sought to identify the best locations for individual retailers, taking into account competition from similar firms and the attractions of locating within retail clusters (central places). In both cases, the analysis concentrated on transportation costs, for producers and consumers, as the prime determinant of spatial variation in overall production costs, and therefore total profits. Spatial variation in other costs, such as land, labor, capital, and taxes, and the effects of agglomeration economies (savings accruing to co-location with other economic activities) were typically added as secondary considerations. Capitalists and consumers were conceptualized as engaged in self-interested, fully informed, rational choice. Space was conceived of as a uniform plane, and location theorists sought to understand why economic activities would emerge at some places rather than others on this plane. This research was also extended to consider public goods offered by the state, such as parks, education, and emergency and medical facilities. Complex location allocation and public facility location models were developed to determine the point locations that either maximized coverage of a spatially distributed population, or maximized accessibility, or minimized inequities in access. A second body of scholarship, pioneered by William Alonso (1933–99), examined land-use patterns: agricultural or urban activities that occupy extensive spatial territories or land-use zones, rather than point locations. Rational capitalists were assumed to choose, for the land they own or rent, that activity that maximizes profits. By the same token, residents of a certain kind would choose the location that is so desirable that they are willing to pay more for that location than anyone else. These choices were driven by the land market: competition for land means that each location is sold or rented to the highest bidder, who outbids others by using that land in a profit-maximizing (or utility-maximizing) way. Thus, wheat is grown in regions where it is the most profitable crop, and low-income households occupy those parts of the city where they can outbid all other users of land. (Little attention was paid to other space-intensive activities, such as coalfields, fishing, or minerals extraction.) A third body of research, pioneered by John Q. Stewart (1894–1972), William Warntz (1922–88), and Alan Wilson (1939–), examined spatial interaction theory and the economics of transportation. One subset of this research sought to determine cost-minimizing transportation flows: which modes of transportation would be cheapest over which distances, and which routes through a complex transportation network will minimize time or cost. A second subset, more descriptive than normative in its approach, sought to predict how much spatial interaction (migration, commodity flows, and capital flows) would occur between places given prevailing transportation and communications technologies. Gravity models and entropy-maximizing models were commonly used as tools for this purpose: seeking to predict the most likely patterns of flows, taking into account the characteristics of origins and destinations (and nearby destinations), the costs of interaction, and any known constraints such as information on total inflows and outflows, and capacity constraints on links. Subsequently, many attempts have been made to demonstrate that the empirically robust empirical predictions of such descriptive models can be grounded in theoretical models of rational choice in the presence of stochastic utility functions. These attempts to provide a rational economic foundation to gravity models are, however, controversial. A fourth body of research, pioneered by Yorgos Papageorgiou (1943–) and Emilio Casetti (1928–), sought to bring all of these considerations together to simultaneously determine the spatial organization of an entire local economy (often conceptualized as a city): commodity production, consumption, agricultural, residential and commercial land-use patterns, and transportation. The approach taken was drawn from neoclassical economics, to which space was added as an extra consideration. Assuming perfect competition and full information, every economic actor seeks to maximize his economic welfare, with the market determining production levels, consumption, and location. Like neoclassical economics, this scholarship made very strong assumptions about behavior (rationality), methodological individualism (microfoundations), and market structures (perfect competition), adding assumptions about preexisting spatial structures (an isotropic plane). Importantly, this research showed that the minor change of including even isotropic space into neoclassical economic theory calls into question the foundational principle of that theory: that a competitive market economy minimizes capitalists’ profits and maximizes consumers’ welfare. Alternative comprehensive approaches were developed by Leslie Curry (1915–2009) and Michael Webber, who sought to determine the most likely spatial organization of activities, land uses, migration, trade, and labor markets without presuming rational, fully informed choice. Like models of spatial interaction, this approach replaced very strong assumptions about rational choice making with minimalist (even random) assumptions about behavior, showing that predictable spatial patterns nevertheless emerge. Similarly, Alan Wilson and his colleagues sought to extend their systems-based spatial interaction methodology to comprehensive models of the local economy. These models explicitly incorporate the types of nonlinear interdependencies and structure-changing behavior that are characteristic of chaotic and complex dynamics: ‘complex spatial systems’. Typically, scholars following these approaches were more skeptical of the idea that the world must be understood through a set of mathematical theorems, and were willing to experiment with alternative approaches to analyzing the properties of their models through computational experimentation, most notably examining the empirical implications of their theorizations using Monte Carlo simulation. In the early 1990s, Paul Krugman catalyzed a renaissance of location theory in the spirit of neoclassical economics, the ‘new geographical economics’. The impetus for this was a new set of mathematical techniques introduced into mainstream economics by the US based economists Avinash Dixit and Joseph Stiglitz to model monopolistic competition using standard microeconomic tools (rational choice). Krugman’s innovation was to apply these, successively, to international trade and the emergence of industrial clusters. Grounded in this highly simplified model of monopolistic competition, the individual rational choice foundations of neoclassical economics, and the assumptions of friction of distance and undifferentiated space inherited from earlier location theories, the new geographical economists sought to extend Krugman’s initial insights to account for a set of stylized facts about the spatial configuration of specialization and trade, agglomeration, and regional economic growth. In order to gain some purchase on the behavior of these types of spatial economic systems, conventional proof-theorem mathematics was replaced by computational experiments, but always within the methodological bounds set by the methodological individualism of rational choice theory. Alongside these developments of mathematical spatial economic theory, economic geographers such as Luc Anselin (1953–), Daniel Griffith (1951), Robert Haining (1949–), and Bernard Fingleton (1949–) were active in developing methodologies that would enable such theories to be tested, in good positivist fashion, against empirical observation. Beginning in the late 1960s, enormous progress was made in measuring the confounding effects of spatial pattern on inferential statistics (measuring spatial autocorrelation and determining its effects on statistical inference), in developing methods of inferential spatial statistics that address these problems, and in incorporating these into a methodological program of spatial econometrics. More recently, both spatial interdependencies and spatial heterogeneity were conceptualized as resulting from the nature of the economic process being modeled, in particular, those hypothesized by the new geographical economics, rather than as some ‘nuisance’ parameter to be controlled to ensure unbiased, efficient, and/or consistent statistical inference. Increasingly, these approaches sought to match the desire of the mathematical theorists to derive foundational theorems about the economy, with definitive hypothesis tests. The shape taken by this first school of quantitative human geography, as for all intellectual endeavors, was strongly influenced by the time and place within which it emerged. Post-1945 North America and Europe was a period when social science sought to gain prestige by emulating the natural sciences; when the natural sciences saw themselves as providing a powerful value-free account of nature by adopting logical empiricism (positivism) as its philosophy; when neoclassical economics was the discipline closest in approach to the natural sciences; and when there was strong belief in the power and ability of quantitative social science to improve society through social engineering. Under these circumstances, it seemed perfectly natural for quantitative economic geography to adopt the twin discursive frames of logical empiricism and neoclassical economics. Both positivism and the capitalist market economy came under increasing criticism, however, in the politically turbulent years of 1968–73. Even enthusiasts of quantitative economic geography, such as David Harvey (1935–) and Allen Scott (1940–), became disenfranchised from the twin ideas that positivism would enable the engineering of a brave new society, and that markets were the key to this. As a consequence, a new school of radical economic geography emerged that was severely critical of neoclassical economics (a critique that was already immanent, given the shortcomings of this theory identified once space was included into neoclassical theory). Radical geographers were equally critical of what was termed the spatial fetishism of this first school of quantitative geography (the assumptions of an isotropic plane, and of space as a variable exogenous to the economy), and its use of mathematical reasoning and quantitative methods. As a result, quantitative economic geography was taken to be equivalent to neoclassical and logical positivist economic geography, and was rejected by most radical geographers as empiricist and bourgeois. Nevertheless, in the 1980s, Allen Scott, Gordon Clark (1950–), Eric Sheppard, Panos Liossatos, Trevor Barnes, and Michael Webber catalyzed a mathematical economic geography in the spirit of Marxian political economy and post-Keynesian economics, influenced by the work of the Italian economist Piero Sraffa (1898–1983), the Japanese economist Michio Morishima (1923–2004), and the American economist John Roemer (1948–). This body of research, which developed into what has become known as ‘regional political economy’, has extended parallel modeling in economics to account for the flow of commodities, capital, and technical knowledge between regions. It has examined the relevance of a labor theory of value in a capitalist space economy, and has sought to move away from the equilibrium models popular in economics. A persistent conclusion has been that a capitalist space economy is unlikely ever to be in equilibrium, and that its spatiality is a destabilizing force. Research has thus been undertaken into the disequilibrium dynamics of a capitalist space economy. In the process, it has been shown how the introduction of geographical space – particularly the transportation sector and transportation infrastructure – calls into question some of the theoretical principles of both mainstream economics and mainstream Marxist theory. While rejecting the desire of economists to ground aggregate models of the economy within microfoundations, research has sought to examine the spatial behavior of capitalists: the adoption of new technologies, and the pricing of commodities in spatially dispersed markets. Empirical work has examined growth dynamics at the national and international scale, the adoption and imitation of new technologies within and across regions (establishing, for example, that persistent differences in technological mix and the trajectory of technical change exist between regions), the evolution of post-Fordist industrial districts, and spatial pricing patterns within urban areas. Methods have included equilibrium and disequilibrium modeling, evolutionary economic models, and spatial statistics. They also increasingly include the use of computational and simulation modeling, instead of seeking to simplify the economy to the point where it becomes tractable for the generation of general mathematical results. This has demonstrated that the commonly received view that quantitative methods are necessarily positivist or neoclassical is, in fact, erroneous. The study of connections between this research and the interdisciplinary field of complexity theory has uncovered parallels between this kind of mathematical economic geography, dialectical analysis, and certain kinds of Deleuzian theory ( These very different conclusions about how a capitalist space economy works, notwithstanding the use of the same kind of mathematical theoretical reasoning, reflect a very different set of assumptions. Location theory sought to explain the space economy through the rational choices of self-interested individuals, took geographic space to be exogenous to the economy and determinant of economic outcomes, and presumed that the economy is tendentially at or near equilibrium. While space undermined perfect competition, the operating principle was that these imperfections and externalities could be identified and corrected through state intervention and social engineering. By contrast, within regional political economy different kinds of economic actors are assumed to occupy different class positions within the economic system (defined by the factors of production they own, their position in the hierarchy of economic decision making, and their relative wealth), differentially conditioning the possibilities available to them as individuals. Thus social structures exist which condition action, making methodological individualism an inadequate conceptualization of human behavior. In addition, it is assumed that differences exist between individual actors occupying similar class positions in terms of relative location, resources, preferences, technologies, and so forth, and that actors possess only limited information about the current and future economic landscape. Space is not exogenous, because accessibility, transportation technologies, and infrastructures co-evolve with the space economy. It can then be deduced that equilibrium is rarely to be expected, and that a capitalist space economy is conflict ridden and characterized by sociospatial inequality and uneven development.   These are characterized by a large number of spatially interdependent and heterogeneous elements, where the interdependence between these elements is characterized by nonlinear dependence. A method used to derive the most probable state of a spatial interaction system, given information on total inflows and total outflows and capacity constraints. An analog with Newtonian mechanics in which the interaction between two places varies directly with the size of those places and inversely with the distance between them. The view that society is best explained by reducing it to the (usually rational) beliefs and actions of the individuals who compose it. A simulation exercise designed to explore how a system behaves by running repeated experiments in which the initial conditions of the system and rule-based outcomes are drawn at random from a known probability distribution. The view that humans make choices that maximize their satisfaction (utility) given the limited set of resources at their disposal. Utility functions expressing individuals’ preferences, in which parameter values vary stochastically across an otherwise uniform population according to a known probability distribution.