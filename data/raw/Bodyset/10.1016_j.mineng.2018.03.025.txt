Mining operations record a large amount of data from multiple sources (such as block model and online processing data) which is neither effectively nor systematically used to understand and improve operational performance. This paper proposes a generic semi-automatable data analytics method, the Integrated Analysis Method (IAM), that addresses the disconnection between disparate datasets. IAM enables evidence-based understanding of rock and machine parameters, laying the foundation for a potentially more sophisticated way to model and predict mining processes to deliver financial value. IAM systematically combines and analyses both rock characteristics and operational data to isolate the impact of the variability in rock characteristics and operational settings on key performances. Insights extracted from IAM allow one to narrow down key operating conditions, specific to a particular plant, that are correlated to, for example, significant differences in daily throughput while processing batches of ore with similar metallurgical characteristics. Such insights can be used for multiple purposes, for instance, to learn optimal processing recipes for a given set of rock properties. We applied IAM to a combined data set recorded at a Chilean ore deposit and evaluated our findings with domain experts.Increasing processing costs and declining ore body grades have called for the global mining industry to focus on improving productivity and energy efficiency in order to stay competitive and to meet the increasing demand for resources ( While these state-of-the-art techniques can, and should, be incorporated into practice, their outcomes can be further improved by making use of currently under-exploited knowledge buried within many sources of historical data collected in today’s minerals processing plants. In particular, the Fortunately, we can attempt to learn this information by analysing historical data, from which we can extract patterns of various operating strategies and quantify their impacts on rock processing performance. Through the application of data analysis techniques, one can learn better operating strategies to maximise outcomes in light of various factors, such as energy, throughput, The main contribution of this paper is a generic semi-automatable data analytics method, called the Integrated Analysis Method (IAM) that can be used to isolate the impact of rock characteristics A key benefit of IAM is its ability to learn better operating strategies, Furthermore, IAM supports a better integration between scheduling and control ( We acknowledge that the application of data analytics for operational supports in the mining industry has been demonstrated before. For example, as early as the 1970s, there have been attempts to apply machine learning techniques to gain insights into the impact of operational settings on plant performances ( This paper is organised as follows. Section The process of minerals extraction involves several stages, including blasting, comminution, and flotation ( KPIs are influenced by several factors, such as geo-metallurgical properties and operational settings. The operational settings and rock properties both influence KPIs, but in order to study them, their influences on KPIs need to be analysed separately. To separate the influence of these factors, we introduce the Integrated Analysis Method (IAM), a methodology that aims to analyse the influence of these factors on KPIs. For instance, in Section In the following sections, we will use the terms X and Y for variables related to rock characteristics and operational settings respectively. IAM is designed as a pluggable framework whereby a wide range of analysis techniques can be included and applied in the analysis chain as long as the data sets and the chosen analysis techniques satisfy certain constraints (gradually elaborated throughout this section). As a consequence, IAM is agnostic to underlying domain-specific variations, such as the types of plants or mills. Furthermore, IAM is flexible to the KPI used: any KPI can be used as long as its corresponding values are available in the data set being analysed.   Similarly, A Finally, a set of configuration parameters is captured as a We first discuss the five high-level steps of IAM (as shown in As a first step, from the input data While both X and Y factors may strongly impact KPIs within each Next, we merge the Thirdly, the Fourthly, the distributions of the identified Y variables (the operational settings/parameters) between Finally, the distributions of the Y variables identified in the previous step are visualised to communicate the results of the analysis to users. The first stage of IAM (identification of KPI Secondly, assuming each data point represents a good quality reading of the KPI (due to, for example, reliable data capture), the KPI values are clustered directly using a known clustering technique, such as Alternatively, if the data points are suspected to be noisy for instance due to low-level granularity or environmental interferences, a single reading at that particular point in time will not give a true reflection of the KPI achieved. Instead, we need to look at Currently, our IAM framework only considers a single KPI variable. Nevertheless, IAM can be extended to handle multiple KPI variables. In this case, the technique to identify Thirdly, the identified In IAM, the combination of techniques applied to extract KPI The second stage of IAM is to isolate the influence of X variables from Y variables (see Thirdly, statistical differences in the distributions of the values of each X variable across the In IAM, the combination of techniques to extract and validate The next step establishes the mapping between In this merged data, we denote the collection of data points from one Within IAM, the number of During the third step of IAM, each Depending on the richness and relevance of the Y variables in the data set, as an optional second step, one may enrich the Y variables by applying feature extraction, for instance, using a frequent pattern mining algorithm ( For reliable results, a data set can be split into a training set and a test set where the former is used to learn the Y variables that may explain the KPI, while the latter is used to validate that the identified Y variables can explain the KPI values in the test set. The Y variables that characterise each Similarly, the exact supervised machine learning technique to be applied can also be parameterised by the Alternatively, one could use classification method on the In the final step of IAM, the identified Y variables are compared across the The statistical test can be parameterised by the From the previous statistical testing, we can thus isolate the independent variables that are statistically different. We then visualise these isolated variables through a number of techniques, such as parallel coordinates and/or box-and-whisker graphs to show visually the different range of values that these variables take across different Factors to consider in choosing a visualisation tool are the number of Y variables identified from the previous comparative analysis and the number of data points involved in the analysis. For a relatively small number of Y variables, and/or for a reasonable number of data points to visualise, using parallel coordinates may be effective as it can help one to see variations in the ‘trends’ between the values of Y variables across different In IAM, the visualisation technique to be used can be pre-configured by setting the The goal of analysing the data sets taken from the comminution processes of a Cu porphyry deposit in Chile is to understand the impact of different operational settings (as captured by various operational and machine settings of the plant) on a certain KPI while processing materials with similar rock characteristics. The KPI being analysed in this instance is production throughput (TPD). A data set related to the short-term plan and process sensors readings from the comminution plant were provided. This comminution process involved the operations of one SAG mill and three ball mills. The data set combines data from separate information sources, including data about the short-term mining plan (which includes the estimated rock properties that would be processed each day, such as the estimated BWi and SPI values), the daily summary of the comminution plant operations (such as energy used, total operating hours for each mill, total tonnes of balls being reloaded to each mill, and bearing pressure of the mills), and the daily summary of reconciliated flotation plant outputs (such as distributions of the particle size of materials being fed to the rougher, recovered minerals from rougher, first cleaner, second cleaner, as well as the overall tonnes of minerals recovered). The data set covered approximately 5 years of operation (July 2010–January 2016, 2041 data points). We refer to this combined data set as the The data set has some data quality issues, including incorrectly-recorded values and widespread missing values. Variables that contained many incorrectly-recorded values, for instance, negative percentage values for the particle size distribution of ore feed, were removed. Furthermore, data points in which values for the KPI (TPD) being analysed were missing were also removed. Data points where the values for rock properties (BWi and SPI) are obviously incorrect (for example, 0 or negative values) were also removed. In the 5.5-year period covered in the daily data set, a change was introduced in the comminution plant whereby a fourth ball mill was installed in 2015. The data analysis conducted focused on the period before this change. Furthermore, because the analysis compares operational settings to TPD, a degree of ‘similar processing capacity’ is needed as a baseline. In our analysis, data points used are restricted to those where all mills (the SAG mill and the three ball mills) were operating at close to full capacity ( In total, the data set contains 1645 data points for the period before the introduction of the fourth ball mill. After filtering, 786 data points remained. Finally, for the Advances in One of the KPIs to be analysed that the stakeholders are interested in is the throughput of materials being processed daily (tonnes per day – TPD). The IAM configuration parameters set for this analysis are provided in As described in Section The CPA technique used is the Change Point Model (CPM) technique (  To learn optimal operational settings, we need to ensure that we are comparing KPI Many clustering techniques are available; in this case study, we applied the simple k-means clustering technique ( At this stage, each data point in the data is labelled with both the KPI In an ideal situation where a A summary of the identified As each rock cluster has more-or-less similar rock characteristics, the existence of multiple The first step in characterising the two high and low KPI Recorded process-related variables in our daily data include daily kilowatt-hour used by each mill, the bearing pressure for the mills, the tonnes of balls being reloaded to each ball mill, the tonnes of crushed pebble generated by the plant, and P80. While these variables may not be the actual operational settings themselves, they are reflections of operational settings, and can thus be used as proxies. This does not reduce the relevance of our approach, as regression analysis and the subsequent comparative analysis can be conducted on actual operating parameters, once such information is available. In this case study, we applied the stepwise regression analysis package ( The relatively low R-squared values in our stepwise regression analysis indicate that the variation in the TPD could not be fully explained by the variables in the data set. A more powerful regression algorithm, such as random forest ( We applied the Mann-Whitney-Wilcox test ( For the purpose of visualising the differences in these variables, we used a parallel coordinates graph, with normalised values, as shown in From the statistical tests and visual clues, we conclude that the distributions of the values of these 6 variables are indeed distinct. From our earlier regression analysis, we have also established that these variables are statistically significant in terms of explaining the trends of TPD. Therefore, we can be reasonably confident that the values seen for the high KPI The IAM method proposed in this paper focuses on methods for data analysis. While IAM is flexible in the sense that it supports the extraction of insights about the impact of any chosen rock variables (the X variables) and operational settings (the Y variables) on any KPI of interest, data used as input to IAM should contain enough information of reasonable quality for IAM to deliver quality results (garbage-in-garbage-out). For example, when we assess the interplay between metallurgical rock characteristics, operational settings, and throughput, the ability to understand how different rock characteristics respond differently to operational settings is critical to optimising processing plants. Therefore, the linkage between characteristics of each batch of rocks being processed, the processing parameters used to process those batches, and the resulting throughput for each batch are crucial to extracting correct insights. While it has traditionally been difficult for operators to know exactly what types of rock are being processed at any given point in time, recent advances in, and adoption of, ore tracking technology (such as SmartTag™) Obtaining accurate information about rock characteristics poses another challenge. The nature of rock characteristics data (which is a combination of lab-tested data and interpolated data) calls for IAM to cater for possible uncertainties in rock characteristics. Consequently, the clustering of rock characteristics may inadvertently create an artificial separation between groups of rock that is not meaningful. To address these issues, IAM could be extended with other statistical measurements to inform users about uncertainties in the data sets, such as a non-parametric confidence interval for the values of rock properties indicating the lower and upper boundary of rock hardness measures per cluster. Alternatively, advanced clustering techniques, such as fuzzy clustering ( Finally, IAM only defines the sequence of analysis steps needed to extract the ‘optimal’ operational strategies. Data analysts who apply IAM have the freedom to choose the most appropriate statistical or machine learning algorithm, based on the nature of the data. For example, to perform the clustering of rock characteristics, users can choose more advanced clustering algorithms, such as DBScan ( We have further demonstrated the Other work involves the improvement of the types of analysis algorithms that can be used in IAM to incorporate those that deal with inherent uncertainties in the data, especially in clustering of rock characteristics. We also envisage the use of more advanced feature extraction techniques (for example, frequent pattern mining techniques ( Other research has been conducted in looking at how one could improve the process of mineral extraction. Analysing plant operational data to gain insights about a plant’s performances has been around for some time. Within the monitoring and control systems domain, such as In the field of resource extraction, recorded sensor data has been used to design or optimise plants. For instance, in Genetic algorithm uses a repeated procedure of random crossover, mutation and selection to construct a model of the plant’s operations based on the input data. Genetic algorithms were also used in Another way to optimise operations is to build one or more models of (parts of) the plant and simulate these models using various processing parameters. For instance, Discrete Element Simulation (DES) can be used to simulate the interaction between rock particles to aid the Computer Aided Design (CAD) of SAG mills ( Such machine-specific simulation models can be used to optimise single machines, however as all steps in resource processing plant might influence each other, simulations should take groups of machines into account ( The approaches described above are model-driven and tend to be ‘generic’ to any machines. On the other hand, IAM is data-driven, thus allowing a certain degree of customisation (as data used for analysis comes from the particular machines being used in the plant). More importantly, IAM takes rock properties into account. Traditionally, models used in a simulation are calibrated using data extracted from expensive surveys. Such an approach is expensive as mill surveys involve the halting of the plant for a substantial amount of time. Furthermore, the information gathered from mill surveys only captures the state of the plant at one particular point in time (the time when the survey was taken). Longer term variability is not captured in this data. Using IAM, these simulations can be calibrated to improve the accuracy of the simulation models and consequently optimise operational settings, possibly extended with an error propagation analysis. That is, IAM could be used to validate the comparisons between models and to refine models using real-life on-line data from existing equipment, similar to IAM can use data from various sources, as shown by our analysis in Section In this paper, we have presented IAM, a general data analysis method that can be used to isolate the impact of rock properties and operational settings on mineral processing KPI (such as throughput). Key data set requirements, as well as the corresponding configuration parameters, that IAM needs have been generalised in the form of a class diagram. Furthermore, we have also provided some guidelines on factors to consider in the setting of the parameters as well as in the choice of various analysis methods that IAM requires. The IAM method proposed in this paper has been evaluated using a data set from a comminution plant operation related to a Cu porphyry deposit in Chile. In this evaluation, we showed how one could extract optimal operating strategies to achieve optimal throughput for rocks with certain characteristics. The results of our analysis have been discussed with domain experts to validate their correctness. Equally important, we have discussed some of the challenges in applying IAM, especially the lack of a more accurate way to link rock characteristics data (for each batch of rocks being processed) and the corresponding processing parameters/operational settings applied. Nevertheless, recent advances in ore tracking technology make it possible that such information will be obtainable in the near future. This work was supported by the Cooperative Research Centre for Optimising Resource Extraction 2 (CRC ORE 2), project P4-001.