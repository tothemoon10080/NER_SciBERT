Process monitoring and fault diagnosis have been studied widely in recent years, and the number of industrial applications with encouraging results has grown rapidly. In the case of complex processes a computer-aided monitoring enhances operators possibilities to run the process economically. In this paper, a fault diagnosis system will be described and some application results from the Outokumpu Harjavalta smelter will be discussed. The system monitors process states using neural networks (Kohonen self-organizing maps, SOMs) in conjunction with heuristic rules, which are also used to detect equipment malfunctions.The aim of fault diagnosis systems is to detect process failures at an early stage. The failures can be due to equipment malfunctions or process disturbances. Of these two, process disturbances, where the operating state has drifted outside the acceptable operating area, are usually more difficult to detect. This is due to the fact that acceptable operating area is seldom clearly defined. Detection of process disturbances is important since it reduces the occurrence of production that does not meet the quality criteria. The increase in the quality of the products contributes to a greater economic profitability of the process. Fault diagnosis has gained growing interest among researchers during recent years. A wide range of applications are reviewed, e.g. in According to The first approach in data processing is classification, in which the multi-dimensional symptom vectors are considered and the direction and distance to a reference vector of the nominal state are determined. This is done, for instance, by geometrical or probabilistic methods by artificial neural networks or by clustering ( An excellent method for classification, an unsupervised neural network algorithm called self-organizing map (SOM), developed by Teuvo The aim of this study was to develop a fault diagnosis system using Kohonen SOMs in conjunction with heuristics rules. The system ( Outokumpu flash smelting is a pyrometallurgical process for smelting metal sulphide concentrates. The Outokumpu flash smelting process consists of a flash furnace, waste-heat boiler and electrostatic precipitator. A flash smelter usually also includes the following auxiliary units: feed mixture preparation and drying, converters, slag treatment system, SO In flash smelting the fine, dried copper sulphide concentrate and silica flux with air, preheated oxygen enriched air or pure oxygen blast and recycled flue dust are fed through a concentrate burner into the flash furnace reaction shaft. In the reaction shaft the suspension of gas, solid concentrate particles and solid flux particles, are formed and reactions like the one described below take place: The matte and slag are tapped out through the holes located at the side or at the end walls of the settler. The waste gases generated at the process are ducted through the uptake shaft into waste-heat boiler and electrostatic precipitator. The sensible heat of the furnace off-gas can be recovered in a waste-heat boiler that is connected directly to the furnace uptake shaft. The waste-heat boiler has two consecutive parts, the radiation section and convection section. On the bottom of the sections there are also dust-collecting boxes for collecting the flue dust. The dust-collecting boxes will receive about half of the flue dust coming into the waste-heat boiler. The off-gas and the remainder of the dust flows to the electrostatic precipitator. In the electrostatic precipitator the dust particles are charged in a high-voltage electrical field, caught on a charged plate or wire and finally collected by neutralizing the charge and shaking the wire and plates. Outokumpu flash smelting furnace is presented in The SOM is a neural network algorithm developed by Professor Teuvo Kohonen that forms a two-dimensional presentation from multi-dimensional data. The topology of the data is kept in the presentation such that data vectors, which closely resemble one another, are located next to each other on the map. Another important characteristic of the SOM is generalization of the information, which enables the classification of data vectors not used in the training of the SOM. The SOMs are applied to classify large amounts of data. They can be used to form a neural network model of an unknown system based only on the data received from the system. In contrast to traditional methods, such as principal component analysis, the Kohonen model can also be created from highly deviating, non-linear data. Before the SOMs are trained, values of each variable in the data should be normalized to have zero mean and variance of one. This procedure ensures that every variable has equal importance in training the SOM. The following formula is used for the normalization: Training a map is an iterative process in which a best matching unit (BMU) must first be found for each data vector. Each data vector must therefore be compared with each neuron on the map in order to find the BMU. A neuron on the map that most closely resembles the current vector is selected as its BMU and the weight factor of the neuron and its neighbouring neurons are adjusted according to the following formula: The SOM can be interpreted by labelling its neurons according to classified measurement vectors. Neurons are labelled after the most probable process state, which can be calculated using the following formula: This gives the map a clear physical interpretation. However, the weakness of this method is that a neuron normally receives hits from measurement vectors representing both normal and undesired states. Therefore, a neuron cannot be explicitly labelled to represent either a normal or undesired state. If the SOM is used to detect only one disturbance, neurons can be labelled as disturbance neurons even if the probability for disturbance is less than 50%. The sensitivity of the SOM can be adjusted by using different probability levels when labelling the neurons. If neurons are labelled as disturbance neurons even with a low probability of the disturbance, the SOM will detect disturbances occurring with a high probability, but the number of false alarms will also be high. The probability level that should be used depends on the application. The state of the process can be monitored by drawing a pointer that displays the neuron corresponding to the latest measurement vector. It is often also advantageous to monitor how the state of the process has evolved during the last measurements, and therefore a suitable length trajectory of the latest neurons representing the latest operational states can be drawn on the map. The online toolbox presented in this paper monitors process states using Kohonen SOMs in conjunction with heuristic rules. The system also enables states of measurements and mathematical methods, based on limit value checking, to be used in heuristic rules. The system consists of the following modules: process interface, application, databases and user interfaces. The structure of the toolbox is shown in The data from process measurements and laboratory and maintenance databases are transferred through the process interface to the toolbox. The toolbox reads data directly through the network from an SQL-based relational database or from a text file. After pre-processing, the data are transferred to controllers that distribute the data to measurement, formula and SOM objects. Based on the new measurement data the objects determine their own state. If the state changes, the inference machine is informed accordingly. At the moment there are five state levels available: LOLO, LO, NORMAL, HI and HIHI. Based on the state changes of measurements and SOM objects, the inference machine updates all those rules where a state has been changed. If all conditions of a rule are evaluated as true, the operator is informed accordingly. The software model of the equipment consists of input variables, output states and rules. Measurements, formulas, SOMs and other equipment can be defined as input variables. Possible output variables are the state of the equipment or state of the process defined for the equipment. All the measurement data and the rules that have evaluated as true are stored, together with their symptoms and timestamps, in SQL databases for future analysis. The toolbox has several different implemented analysis methods. For example the system can calculate the most typical rules that have been evaluated true in a given time interval. For the use of some specific analysis methods not implemented in the system, the data can easily be exported to other applications through an ODBC interface. The data stored in the database can also be used for off-line simulations. This is useful during the configuration period, when new rules and SOMs, are tested. The toolbox consists of two different user interfaces. One is developed for the administrator and the other for the operator. The operational user interface offers all the information required for on-line monitoring of processes. Through this window it is possible to monitor the current state of a process and even to predict the future trend. The process monitoring user interface consists of four main blocks: maps, trends, active faults and history.  As SOMs may contain several different types of fault, only the component space of the most probable fault is presented to the operator. This keeps the operator view simple and clear. It is of course possible to examine all the other component spaces of different faults individually or all at once.    The operational window is presented in The administrator side, that has all the required components for training of the maps, making of the rules and other general configuration tools, can be made transparent for the operators. As long as it is configured properly, the operator only has to monitor the process without concerning about transfer of data or other modifications. The administrator side has five important blocks: measurements, formulas, SOM training, equipments and trends.     In addition, the administrator side also contains a useful database organizer that can be used to prepare data for training of the maps. The system has an open architecture, which enables easy integration with other applications. It has been developed using a platform independent object oriented programming language Java. All the process information like measurements, SOMs and rules are independent from the system so the toolbox application does not need recoding if taken in use in a different process. The most important part of a rule-based fault diagnosis system is the rules that are applied. With well-functioning rules a very effective system can be built while, on the other hand, a system cannot predict phenomena correctly if its rules are false or feeble. The rules used in the implemented system are IF–THEN rules. In the IF part, objects compared with their limit values can be measurements, values computed from measurements or the probability of phenomena according to the SOMs. Logical operators AND, OR and NOT can be used in the comparison. The THEN part triggers a warning message for the operator, and possibly sets values for other user defined variables, which in turn can be used in the IF part of other rules. In the system, the rules are always connected to a specific piece of equipment and can be formed using only variables that are known for that equipment. This prevents the insertion of illogical rules that may be the reason why the diagnostic system shows unexpected behaviour. Rules that are based on equipment also make it possible to know which rules are affected if certain changes are made in the process equipment. An example of the rules used in the system is given below. It can be read “if the gas blower vibrates and sooting is not detected, then there are dust aggregations in the gas blower”. IF Gas_blower_SOM_vibration= The nature of the phenomena monitored by means of SOMs differs, some of them being closely linked with process control and process disturbances, while the rest monitor the states of the process. For the real-time detection of different phenomena, the SOMs are trained using data that can be received real-time. One exception to this is the map trained using data received from analysis of the feed. The analysis results can be read on-line, but there exists a significant delay between the actual process state and the analysis. This also applies to maps representing the states of the matte and slag, where some of the data are received real-time, while some are based on the analysis of the above two components. These SOMs can be used on-line, the BMU being chosen only on the basis of the available measurements. Thus the SOMs can even operate without all the components of the data vector used in the training. The phenomena associated with process control are presented in The most important phenomenon that affects process control is the quality of the feed material. The overall quality of the feed mixture is influenced by the quality and amount of concentrate and by the amount of recycled slag. In the Harjavalta smelting plant, the quality of the feed material is monitored on the basis of laboratory analyses made, on the average, 5–6 times per day. The composition of the feed material is analysed for its arsenic, lead, zinc, copper, nickel, iron, sulphur, silicate and calcium contents. The main aim is to train an SOM using information about different feed compositions, and to determine the correct values of the variables used in control for each neuron. The operator can then use the values of the BMU as set points for the control variables.  The overall state of the process was monitored in order to detect undesired process states because a deviation from the desired state cannot always be considered to be a direct process disturbance. From the economic point of view, it is just as important to detect a decrease in the quality of the product as to detect an equipment failure, since both lead to a reduction in productivity and profitability. Differentiating undesired process states from actual disturbances does not generally create sudden emergencies, and thus it is acceptable to detect a phenomenon even with a slight delay. The monitored process states were viscosity of the slag and the matte, temperature of the waste-heat boiler, and the formation of dust aggregations inside the boiler or the gooseneck. Detection of the formation of dust aggregations is described in detail as an example.  To detect dust aggregations, a principal component analysis was first performed in order to reduce the number of training variables. The 19 variables that were direct process measurements, and the eight variables calculated from the process measurements listed in  The following actual process disturbances were searched for: flooding of the feed material, aggregation of feed material in the concentrate burner, and malfunctions of the fields of the electrostatic precipitator and gas blower. Detection of the formation of concentrate aggregations in the concentrate burner is described in detail as an example.   After the maps had been trained, their classification abilities were evaluated using data that were not used in training the SOMs. These data consisted of regularly separated, short periods of actual data. The amount of data used for the evaluation was approximately half the size of the data used in the training. The SOMs were subjected to three tests. In the first test, situations in which the data vector hit a neuron representing the same state as the data vector were classified as hits. In the second test, a hit represented a situation in which the data vector hits a neuron where the most probable state is the state of the data vector. In test number three, a hit represented the situation where a data vector's BMU is a neuron that represents the same state as the data vector, or the neuron considers its state as the most probable one. Test number two usually gives better results than number one, but it also causes more false alarms. The third test gives a better result than tests one or two when two or more classification types, i.e. disturbances, occur concurrently. The feed material SOM was evaluated with data from the middle part of the time period when the data were collected. Classification of the theoretical oxygen enrichment coefficient was tested by dividing the data into different categories on the basis of the value of the coefficient. The classification and amounts of learning and testing data are presented in  An SOM trained with the five latent roots of the principal component model of the variables presented in  An SOM trained with the variables presented earlier was used to detect the formation of concentrate aggregations in the concentrate burner (  Since summer 2001, the fault diagnosis system has been in test use in the Outokumpus Harjavalta copper smelter. In contrast to the previous study, the focus was on detecting only two types of disturbance; the formation of concentrate aggregations in the concentrate burner, and the formation of dust aggregations in the waste-heat boiler. There were two testing periods in the smelter during last year. During summer 2001, a research assistant carried out his summer training at the smelter, and in November a researcher spent 1 month performing on-line testing of the system. They observed the behaviour of the process, and also recorded more accurate data on the process disturbances. This information was used, together with process measurement data, to form the training data for the SOMs. The purpose of the on-line testing was to evaluate the behaviour of the system in actual situations, and to set the proper probability level for the maps. Off-line analysis of the concentrate burner SOM showed that, when the probability limit used in labelling the neurons is set to 23, it is able to detect the concentrate aggregations ( During a period of 1 month, all the actual disturbances detected in the process were noted, and then compared with the notifications of the monitoring system. A process disturbance was considered detected by the system if, at some point during the occurrence of the disturbance, the system gave a notification of it. This made it easier to compare the result with the actual efficiency observed by the operator. The detection of concentrate aggregations in the concentrate burner is presented as an example. The development of concentrate aggregations in the concentrate burner could be noted by examining the temperature measurements of the reaction shaft. The temperature on one side of the shaft rose every time concentrate had started to gather in the burner. Disturbances in the burner were noted using these measurements, and then compared with the notifications of the monitoring system. The maps were trained with six temperature differences across the reaction shaft and the feed. During the testing period, two different maps were used to detect the concentrate aggregations. Both were trained with the same training variables, one according to the normal procedure and the other one using a trend of five measurements for each variable. The trend measurements were handled as normal measurements in the training, except that their importance in selecting the BMU was weighted such that the oldest measurements had the least importance. As disturbances that continue for a longer period of time cause more production losses, the percentages were weighted with the duration of the disturbance. The percentage is calculated by dividing the total length of the detected disturbances with the total length of all the disturbances. The results are presented in However, about one-third of the time the system still incorrectly detects a disturbance. When the maps were retrained including a new training variable, the energy balance of the shaft cooling water, the trend map was able to reduce the number of incorrect notifications to one quarter of all the notifications, but it could not detect disturbances with the same efficiency. These results are, however, acceptable because over one half of the actual process disturbances were detected. The probability level was searched for and set in such a way that it gave the best balance between correct notifications and false notifications. The system has been in test use at the Outokumpu copper smelter in Harjavalta. A considerable amount of improvement in the results has been achieved during the last year, and the diagnosis system has evolved into a useful tool for process monitoring. In order to achieve even better results, more detailed information about the formation of dust aggregations should be collected. It was also apparent that the two disturbances seem to be linked to one another. After heavy concentrate aggregations there were usually more dust aggregations than normal. During the 1-month testing period a number of temperature sensors around the reaction shaft started to malfunction, which made it more difficult to test the system. Better instrumentation would enable more precise monitoring of the phenomenon, and make the system less vulnerable to sensor failures. Also, more sensors should be installed to cover a larger area of the shaft walls. According to the theory, unsupervised neural network models can be constructed solely on the basis of measurement data from the process. However, if we want to label the neurons in the SOM, we also need information about process states. As this cannot be easily measured, we have to rely on the operators’ observations and make the necessary assumptions. This demonstrates that, despite the new modelling methods, process knowledge still plays an important role in fault detection systems.