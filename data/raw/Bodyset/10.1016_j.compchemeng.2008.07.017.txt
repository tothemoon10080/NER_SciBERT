In the framework of process optimization, the use of measurements to push the plant to the economically optimal operating point has re-emerged as an active area of research. One of the ideas therein is to adapt the inputs in order to track the active constraints and push certain sensitivities to zero. There are several ways of doing this. With perturbation-based optimization, the sensitivities are evaluated by perturbation of the inputs and measurement of the cost function. However, since more measurements (typically the outputs) than just the cost function are available, the idea developed in this paper is to use both the nominal model and measured outputs to optimize the process. This is done by extending the neighboring-extremal scheme to the case of output measurements. In the case of parametric uncertainty, and if measurement noise is negligible, the approach is shown to converge to the optimum in at most two iterations. The effect of measurement noise is also investigated. The use of neighboring-extremal output feedback for optimization is illustrated via the simulation of a continuous chemical reactor.The use of measurements to improve process operation has re-gained popularity in recent years For steady-state production, it is critical that the system be operated as closely as possible to the optimal operating point. Standard optimization tools rely on process models, which, for industrial applications, are often inaccurate or incomplete. As a result, the optimal set points computed from the available models are not optimal for the plant. Hence, measurement-based optimization tools have been developed to help solve this problem. The measurements can be used to either: (i) adapt the parameters of a process model and re-optimize the process on the basis of the updated model (  Search (zeroth-order) methods: In techniques labeled Perturbation (first-order) methods: In techniques labeled Reformulation methods: In techniques such as This paper proposes an optimizing scheme that belongs to the third class above. It uses output information to evaluate the gradients in one go, i.e. without having to rely on several measurements at different operating points as this is the case when only the cost function is measured. Hence, the number of iterations required to reach the optimum is considerably smaller than with a perturbation-based approach. Gradient evaluation is done implicitly using the neighboring-extremal (NE) scheme, which is well known in the optimal control of dynamic systems The paper is organized as follows. Section Steady-state optimization consists of minimizing a cost function under equality and inequality constraints. At the optimum, some of the inequality constraints are active. A standard assumption is that the set of active constraints is known and does not change with process disturbances. In such a case, the active constraints can be kept active using simple controllers, which removes certain degrees of freedom from the optimization problem. As a result, a problem without inequality constraints and with a smaller set of decision variables can be formulated as this is done in extremum-seeking and self-optimizing control The general formulation of a static optimization problem Introducing the Lagrangian The notation Gradient-based schemes are based on the following input update equation: The gradient Neighboring-extremal control attempts to maintain process optimality following the effect of disturbances. It is based on the variation of the conditions of optimality. Consider process operation around the nominal optimal operating point The corrective action Since Unfortunately, the update law It will be shown that the NE-control scheme    Subtracting Taylor-series expansion of Using Next, the proposition is established.     The derivatives of The adjoint variables Using Since the gradient-based update law The drawback of NE control is that the second- and higher-order terms are neglected as a comparison of NE control allows computing, to a first-order approximation, the optimal input update from state measurements, i.e. without having to evaluate the cost sensitivities experimentally. NE control is usually based on full-state feedback. Here, an extension that accommodates output feedback will be introduced. Consider the measurement equation Eq. Using Note that setting Note also that NE control allows estimating the cost gradient via input and output measurements. Indeed, a comparison of It will be shown next that, for the case of parametric uncertainty and noise-free measurements, and under certain conditions, the proposed output-feedback update scheme converges to the optimum in at most two iterations.    Using the linearized system equation The evolution of Note that Note also that If The converged values   NE control relies on the implicit estimation of the parametric disturbance The convergence relies on the output measurements available at a given iteration: a parameter variation generates an output deviation that will be used to compute an appropriate input update. In contrast, since the perturbation approaches rely solely on the measurement of the cost function, information including several iterations is needed. Hence, the resulting gradient-type update is much slower. There is a fundamental difference between NE feedback and explicit optimization techniques based on model adaptation followed by re-optimization. In explicit optimization, the parameter update is done through model inversion and thus suffers from the presence of modeling errors. In contrast, in the NE approach, the correction acts directly on the system inputs and will be applied until the output offset has been fully eliminated. The convergence of measurement-based optimization schemes in the presence of time-varying parametric variations is usually based on a time-scale separation between the time variations of the parameters and the dynamics of the update scheme, i.e. the parameters must not vary significantly during the time span required for the update scheme to converge. Hence, the parameters can vary only very slowly when the number of iterations required for convergence is large, as this is usually the case with the perturbation approach. On the other hand, since the proposed NE feedback converges within a few iterations, the proposed NE feedback is better suited for handling time-varying parameters. In the following, the effect of measurement noise on the performance of the NE output-feedback scheme is analyzed. With the measurement noise The goal is to evaluate the cost improvement obtained with the NE output-feedback scheme compared to using the nominal inputs on the perturbed plant: For the NE output-feedback scheme to be useful,      For Using the notation Note that  The cost variation obtained upon using the nominal inputs on the perturbed system is given by  It follows from From Upon defining the parameters: For a zero-mean noise   Input update via NE feedback is only useful if the cost variation due to measurement noise is small compared to the cost variation due to parametric disturbances. Let the parameter For The parameter From Hence, the parameter If the distributions of the parametric disturbance The matrix An isothermal continuous chemical reactor with the two reactions The parameters If the number of measurements is sufficient to reconstruct the uncertain parameters according to  Consider the case with a single measurement, The feedback gains obtained for the nominal operating point are  Consider the case with two outputs as in Section The feedback gains obtained for the nominal operating point are the same as in Section Three cases are presented next:    These examples show that, for a fixed amount of parametric uncertainty, the efficiency of the proposed scheme decreases with higher measurement noise. However, for a fixed amount of measurement noise, the relative efficiency of the proposed scheme, as defined by The optimization of static processes has been addressed for the case of imperfect model but availability of measurements. NE-based output feedback is used as an alternative to the classical perturbation approach to update the process inputs. It relies on more information (output instead of solely the cost function) and thus requires far fewer iterations to reach the optimum. In fact, for the case of parametric uncertainty and noise-free measurements, convergence is achieved in at most two iterations. The symbolic and numerical computations required to compute the feedback are rather straightforward and can be performed off-line. A predictor of the performance of the NE scheme in the presence of measurement noise has been proposed. This predictor can be computed off-line if the stochastic properties of the uncertain parameters and the measurement noise can be assessed. Though the accuracy of the predictor is limited by first-order approximations, it is consistent with the behavior observed in simulations. It is worth emphasizing that the NE approach only represents a first-order approximation to the optimal solution. Furthermore, it does not necessarily converge to the true optimum in the presence of unstructured uncertainty. Note that the convergence proof has been obtained for the nominal case with only parametric uncertainty. Although the resulting sub-optimality is often small (like in the reactor example that has been considered), it can be unacceptable in certain applications. The way to handle non-parametric perturbations is the subject of future research.