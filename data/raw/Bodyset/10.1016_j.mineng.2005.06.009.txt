A model for the coordination number of multi-sized spheres in a packed bed as a function of size distribution and porosity is evaluated using a CT scanner. The model being investigated was only evaluated using a particle packing algorithm by the authors, and not experimentally. This is done with the aim of using this model to quantify the distribution of grains within pellets used as ore bearing feed to the blast furnace. This allows for the prediction of the distributed phase transformation that occurs in pellets, and results in a better overall understanding of the bed in the blast furnace, which can result in a minimisation of the coke feed to these furnaces. Experiments were done using glass spheres of various diameters to construct packed beds of different size distributions which were then scanned in a CT scanner. The images from the CT scanner were subject to image analysis and the coordination number of the spheres calculated. The results obtained compared favourably with the model predictions.Pellets are a main iron bearing feed to the iron blast furnace, which is responsible for the majority of iron production in the world. These furnaces emit large quantities of CO  In the past much work done on the construction of empirical models for the estimation of the average coordination number of packed beds made up of mono-sized spheres as a function of the overall porosity of the bed ( In this paper the model derived by Suzuki and Oshima proposed the following model for the estimation of the coordination number of spheres in a multi component packed bed ( To test the models described in the previous section experimentally, samples were made up of glass spheres with five different diameters, namely 5, 6, 7, 8, and 9 The samples were made up using three different types of size distribution (based on volume), namely log-uniform, Rosin–Rammler and Andreasen (Gaudin–Schuhmann) with three separate samples each made up for the Rosin–Rammler and log-uniform, and four samples for the Andreasen. The size distributions were made up by first setting the relevant parameters for each correlation, and then calculating the required mass of each distinct sphere size needed in order to obtain the required distribution. Before this was done the density of each size of sphere was calculated by immersion in water. This was done to ensure the accuracy of the volume size distributions, because if the densities of the spheres differed this would have to be accounted for when calculating what mass of spheres necessary for each size class. The total mass of each sample was 200 The log-uniform cumulative distribution function appears linear when plot on semi-logarithmic axes, where the logarithm of particle size is taken. The Rosin–Rammler distribution function is In the Andreasen distribution the maximum and minimum particle sizes are set as constant. This results in a distribution where the fraction of each particle size varies with the expansion of the distribution. This is contrary to the log-uniform and Rosin–Rammler distributions where the minimum and maximum particle sizes vary with the expansion of the distribution. The cumulative Andreasen distribution is shown in the following equation: Each sample was subject to three scans, two in the large and one in the small diameter sample holder. This was done in order to ascertain the reproducibility of the results, and as mentioned previously, to see if there was any affect on the results due to the differing length to diameter ratio of the packed bed. Prior to the scans, the spheres were poured into the sample holder, the removable plastic lid was then bolted tight and the sample shaken vigorously to ensure that the spheres were well mixed. The steel piston rod was then screwed tighter pushing the plastic disk down onto the sample. Subsequently the holder was tapped repeatedly and the piston rod screwed tighter until no more movement was possible. The length of the sample space was then measured, after which the sample holder was placed horizontally onto the moving table of the CT scanner and the scan completed. The experiments were carried out using a Siemens Volume Zoom CT scanner. The scan were done with a slice width of 1 Once the scans were completed, the image data obtained were processed using the Image Processing toolbox of Matlab 6.5. Starting with the first image of the scan in which the spheres were visible, the global image threshold was calculated using Otsu’s method ( These properties were used to identify the corresponding object (if any) in the next image. This was done by calculating the two dimensional Euclidean distance between the centroids of all objects in consecutive images. If this distance was less than 0.4 Once all of the images in the scan were subject to these calculations, a numbered array with an entry for each identified sphere was created. Each entry in this array contained a sub-array in which the These calculations resulted in an array containing the The results will be divided into three sections. Firstly the focus will be on the image analysis. The integrity of this analysis needs to be verified before the experimental results obtained can be compared. Once this has been completed, the size distribution with re-estimated parameters will be discussed. This re-estimation is made necessary because the pre-determined size distributions did not take the variance in sphere size within each distinct size class into account. Finally, the performance of the coordination number model when compared to the experimental results will be shown. Before the coordination model results can be evaluated, it is important to analyse the results obtained from the image analysis. It is necessary to ascertain whether there are any anomalies in the image analysis routine that result in nonsensical results. Firstly the number of particles identified through image analysis for each sample was compared to the actual number found through a hand count. This was done for each size category in each sample, and the results are shown in In From When looking at the number of identified spheres per size category it can be seen that in the majority of cases they agree with one another. This is slightly more difficult to evaluate as there was no hand count done of the spheres per size category. For this reason it is impossible to say for sure which sample in each separate size distribution has the correct number of particles per size category. On comparing the results of different samples of the same size distribution it is possible to make some assumptions regarding the number of spheres per size category, but only if the sum of the spheres in each category is equal (i.e. the total number of spheres identified is equal to the hand count). For example, in sample set LU2, samples L1 and L2 have the same number of spheres in each size category. Sample S, however, shows some deviation in the 6.5–7.5, 7.5–8.5 and 8.5–9.5 The discrepancy in the number of particles in each size class could be attributed to noise. Consider a sphere for which, after the erosion and dilation routine, there are a total of four slices in which the an object representing that sphere should be identifiable. If, for example, the object representing that sphere in the third slice is corrupted by noise, the equation for the sphere will be calculated using only two sets of points representing the Due to these discrepancies in the calculation of the equation of the sphere, it was considered important to compare the average diameter of the identified spheres in each size category for each sample. This calculation gives an indication of the accuracy of the image analysis. These data are shown in Prior to the scans, the size distributions were made up by first setting the relevant parameters for each correlation, and then calculating the required mass of each distinct sphere size (5, 6, 7, 8, and 9  In Section The results for the coordination number of the spheres obtained from the experiments were compared to those calculated using the multi-sized model. This was done using each of the above mentioned mono-sized models and the results compared in order to identify which mono-sized model gave the best estimation of the coordination number when used in the multi-sized model. When comparing the results it was found that the mono-sized models of The model performance and the porosity of each sample are shown in The innovative technique used in this paper to validate the coordination number model delivered both the credibility associated with experimental validation, as well as the ease and reproducibility associated with particle packing algorithms. The image analysis algorithm used to evaluated the data obtained from the CT scanner was found to produce consistent and reproducible results when evaluating the coordination number. The particle count obtained from the image analysis was in almost all cases consistent with the hand count of the spheres. The existence of unaccounted for particles in a few of the experiments was attributed to the fact that the glass spheres used were not perfectly spherical. When these particles were orientated in such a way as to interfere with the algorithm used to identify corresponding objects in consecutive slices, the particles were unidentified. In the majority of cases the particle count per size category in samples belonging to the same set corresponded to one another. The few cases where this did not hold were attributed to noise in the image data. This lead to the equation for the sphere being calculated with a minimum of data, which resulted in erroneous calculated values for the diameter of the corresponding sphere. The previously unvalidated model of This model can now be safely used to estimate the coordination number of grains in a pellet used as ore feed to the blast furnace. This facilitates the construction of a probability model which can be used to predict isolated volumes of local composition within the pellet. These isolated local compositions will then be subject to thermodynamic equilibrium calculations and the distributed equilibrium composition of the pellet can hence be calculated. This work is part of the E.E.T. (Economy, Ecology and Technology) Project (