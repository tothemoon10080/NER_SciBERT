Occupying more than 70% of the concrete's volume, aggregates play a vital role as the raw feed for construction materials; particularly in the production of concrete and concrete products. Often, the characteristics such as shape, size and surface texture of aggregates significantly affect the quality of the construction materials produced. This article discusses a novel method for automatic classification of aggregate shapes using moment invariants and artificial neural networks. In the processing stage, Hu, Zernike and Affine moments are used to extract features from binary boundary and area images. In the feature selection stage, discriminant analysis is employed to select the optimum features for the aggregate shape classification. In the classification stage, a cascaded multilayered perceptron (c-MLP) network is proposed to categorize the aggregate into six shapes. The c-MLP network consists of three MLPs which are arranged in a serial combination and trained with the same learning algorithm. The proposed method has been tested and compared with twelve machine learning algorithms namely Levenberg–Marquardt (LM), Broyden–Fletcher–Goldfarb–Shanno quasi-newton (BFG), Resilient back propagation (RP), Scaled conjugate gradient (SCG), Conjugate gradient with Powell–Beale restarts (CGB), Conjugate gradient with Fletcher–Reeves updates (CGF), Conjugate gradient with Polak–Ribiere updates (CGP), One step secant (OSS), Bayesian regularization (BR), Gradient descent (GD), Gradient descent with momentum and adaptive learning rate (GDX) and Gradient descent with momentum (GDM) algorithms. Also, the classification performance of the c-MLP network is compared with those of the hybrid multilayered perceptron (HMLP), the radial basis function (RBF) as well as discriminant analysis classifiers. Concerning the cascaded MLP, 3 stage c-MLP gives the best accuracy compared to the 2 stage c-MLP and the standard MLP. Compared to other learning algorithms, LM algorithm achieved the best result. As far as the overall conclusion is concerned, c-MLP gives better classification performance than that of the HMLP, RBF and discriminant analysis.Quarries provide earth materials such as sand, clay, gravel and crushed rocks that will be processed further into raw material inputs for buildings and construction, agriculture and industrial processes. The demand for these materials is derived by the demand for the goods and services that these materials provide, with each user industry defining specifications fit for their final products ( At least three-quarters of the volume of concrete is occupied by aggregates and hence it is not surprising to know that its quality is of considerable importance (  Overall, stronger aggregates with improvement in particle shape and textural characteristics tend to produce stronger concrete as the weak planes and structures are being reduced. Substitution of equidimensional particles derived as crushed product produces higher density and higher strength concrete than those which are flat or elongated because they have less surface area per unit volume and therefore pack tighter when consolidated. Aggregates which are flat or elongated decrease the workability by poor packing, reducing the bulk mass and consequently decreasing the compressive strength of concrete with much more requirements of sand, cement and water. Thus, it is of utmost importance to change the traditional quarrying scenario towards optimization of the crusher performance to produce high quality aggregates so that this will be in tandem with the current development and changes in the concrete industry. Furthermore, it is necessary to develop a more quantitative and systematic measurement system for aggregate classification. Traditionally, standard techniques and test procedures complying with British Standards, American Society for Testing and Materials (ASTM) and New Zealand Standards have been widely used to analyze and evaluate the shape, size grading and surface texture of aggregates. Generally, the grading profile of aggregates is identified by sieving with standard sieves and sieve shakers. The flakiness and elongation gauges are the aids used to determine the flakiness and elongation indices (FI's and EI's) of coarse aggregates while the shape of fine aggregates is determined through the voids content percentage (uncompacted and compacted) and flow cone method. However, the analysis for coarse aggregate particles has limitations since it involves manual gauging of individual aggregate particles. It is also difficult for engineers to analyze the concrete for improvement in real time due to lack of accuracy and systematic database storage for the mass aggregate production. Over the past 20 years, many works have been done to improve the methods for analyzing aggregate images using digital image processing (DIP) technique particularly to shorten the time for classification thus making it more cost effective and faster compared to the conventional processes. Much of the work tried to explore the advantages of DIP to have a real time classification system and the data information storage for the aggregates, making it more automated thereby simplifying the analysis in the future. Different methods and algorithms were developed to tackle the issues encountered and to improve the process further. A number of methods using imaging systems and analytical procedures to measure aggregate dimensions are already available. An imaging system consisting of a mechanism for capturing images of aggregates and methods for analyzing aggregate characteristics have been developed such as Multiple Ratio Shape Analysis (MRA) by Jahn (2000), VDG-40 Videograder by Emaco Ltd Canada, Weingart and Prowell (1999), Computer Particle Analyzer (CPA) by Tyler (2001), Micromeritics OptiSizer (PSDA) by Strickland, Video Imaging System (VIS) by John B. Long Company, Buffalo Wire Works (PSSDA) by Penumadu, Camsizer by Jenoptik Laser Optik System and Research Technology, WipShape by Maerz and Zhou (2001), University of Illinois Aggregate Image Analyzer (UIAIA) by Tutumluer et al. (2000), Aggregate Imaging System (AIMS) by Masad (2003) and Laser-Based Aggregate Analysis System (LASS) by Kim et al. (2001). Description of the existing test methods can be found in To select a set of appropriate numerical attributes of features from the interested objects for the purpose of classification is one of the fundamental problems in the design of an imagery pattern recognition system. One of the solutions, the utilization of moments for object characterization has received considerable attention in recent years. Moment is an important shape descriptor in computer vision and has been used widely in pattern recognition applications ( In the present study, 7 orders of Hu, 11 orders of Zernike and 6 orders of Affine moments are used. Two sets of these moment are implemented, one from the aggregate area and the other from the boundary. So a 48-feature vector has been constructed from each aggregate sample. In most of the feature extraction cases, larger than necessary number of feature candidates are generated. However, the irrelevant or uncorrelated features could actually cause a reduction in the performance of the classifier ( As far as the use of artificial neural network (ANN) is concerned, ANN learns the relationships that exist between the input and output variables from a set of training data, builds a model to fit the data samples and uses the model to predict the outputs of new input data. Different ANN architectures such as multilayer perceptron (MLP), radial basis function (RBF) and recurrent neural networks (RNN) have all been proposed in the literature for pattern classification problems ( In this work, the aggregate data was extremely random owing to manual collection of aggregate samples. Consequently, it was not possible for the standard MLP to recognize and categorize these highly complex samples into six shapes with good accuracy. To overcome this difficulty, a cascaded MLP network is introduced which is denoted as c-MLP in this literature. Here, the proposed c-MLP consists of three MLPs which are arranged in a serial combination and trained sequentially, one after the other with the same learning algorithm. There are many types of powerful training algorithms and each of the algorithms has its own limitation. Some of the algorithms may perform well in classification problems while some may perform well in function approximation problems. The proposed method has been tested and compared with twelve machine learning algorithms namely LM, BFG, RP, SCG, CGB, CGF, CGP, OSS, BR, GD, GDX and GDM algorithm. More details of these algorithms are available in Data of aggregates are obtained from the School of Materials and Mineral Resources Engineering, Universiti Sains Malaysia (USM). A total of the 4242 samples with different sizes and shapes are gathered after crushing the stones using Metso Barmac Rock on Rock Vertical Shaft Impact (RoR VSI) crusher. A new aggregate shape classification method based on the Euler's Polyhedron formula developed by The feeds from a Malaysian Quarry have been crushed using Metso Barmac Rock on Rock Vertical Shaft Impact (RoR VSI) crusher from New Zealand. A series of experiments was carried out to determine the shape of the feed and crushed products of all the tests run using the parameters of Euler's Polyhedron formula, which states that the number of corners plus the number of faces was equal to the number of edges plus two ( Direct comparison of the number of faces, edges and corners were made with a perfect ‘cubic’; which has six faces (f: 6), twelve edges (e: 12) and eight corners (c: 8) as shown in The proportion of each type of particles in the feed and crushed products for any rotor speeds or cascade test work could be better quantified and classified according to this six shape classification. It could be seen that the number of faces for the flaky, elongated and flaky and elongated particles could be as low as two; whereas the angular particles had greater number of faces (4–8). Also, the flaky, elongated and flaky and elongated particles were more flat and less in crushed faces compared to angular and cubical type particles. Similarly, the irregular particles apart from being blocky, could be seen as having less number of faces, edges and corners compared to the other better shaped particles (cubical and angular) ( The proposed methodology for image acquisition and feature extraction which uses a camera–object setup is discussed in this section. CCD camera is used to gather images and information from a scene of interest. The maximum resolution of the input image is fixed to 640 For each aggregate, only one image is captured as the system is developed to recognize the shape of a single aggregate's image. The aggregate images are captured and digitized by frame grabber and stored in a lossless digital format, bitmap (.bmp), inside the desktop computer memory. A total of 4242 aggregate images (i.e. the same aggregate samples mentioned in The pre-processing stage consists of thresholding the image automatically using iterative thresholding method, followed by growing and shrinking the image to provide a clear and better separation between object and background ( One of the real challenges in this study is using the geometrical moments for feature extraction in aggregate shape classification. The invariance property of Hu, Zernike and Affine moments against geometrical transformations like scaling, translation and rotation makes it a good candidate feature extractor to be used for aggregate recognition. Also, the simplicity of 2D moment calculation will reduce the processing time, hence increases the system efficiency and suitability for real time computer vision system. In order to understand how to utilize moment invariant method, let The central moments of order ( The moment invariant under scale is defined as Normalized un-scaled central moment is then given by From the second and third order moments, a set of seven invariant moments which are invariant to translation, rotation and scale derived by The algorithm of Hu moment invariants is implemented as: Calculating the value of Computing each value of Computing each value of Calculating the value of Hu moments In order to take advantage of the information content of both the area and the boundary of the aggregate image, two sets of seven Hu moment invariant functions are computed; one set derived from the area ( Zernike moments are defined over a set of complex polynomials which a complete orthogonal set over the unit disk Zernike polynomial For a digital image  The following conditions are obeyed for calculating the Zernike moments: Calculating the value of Computing each value of Calculating the value of Zernike moments In this study, two sets of eleven Zernike moment functions are computed; one set derived from the area ( The Affine moment invariants are derived to be invariant to translation, rotation, scaling of shapes and under general 2D affine transformation. The six Affine moment invariants ( The algorithm of Affine moments is implemented as: Calculating the value of Computing each value of Calculating the value of Affine moments Two sets of six Affine moment functions, one set derived from the area ( In summary, a total of 4242 samples of aggregate were used in this study. Each input sample has 48 attributes extracted based on object's mass and boundary, which are 14 Hu moments ( After completing the feature extraction process, all the 48 features for 4242 aggregates with its 6 groups are tabulated in the Microsoft excel spreadsheet. Then, the discriminant analysis using SPSS software version 14 is put into action to analyze, determine the optimum features (i.e. to eliminate the noisy and unwanted features), quantify the performance of each group and calculate the overall accuracy of the classification. The 48 features are denoted as Ward's Linkage method with univariate and multivariate tests was applied to the analysis results. This type of analysis was needed in order to identify clusters of analysis methods. Here, the 45 features which give high impact have been processed using multivariate test. Based on discriminant analysis, it is found that only 23 dominant features have the ability to classify the aggregates into 6 groups (shapes) properly. From The discriminant function The separation point must be ascertained because the value can be used to identify the range for each group of the aggregate. With ascending order, it is found that: Then, the separation points between the groups are defined as follows: For the flaky and cubical group, the separation point is: The separation point for the cubical and angular group is: The angular and irregular groups are separated at point: The separation point between irregular and elongated group is: Finally, the separation point between elongated and flaky and elongated group is: From separation points obtained, the range for each group is determined. The flaky group is located at separation point which is less than − Apart from determining the dominant features which cause high impact, the discriminant analysis is also able to classify the data into groups identified (i.e. determine the number of correctly classified data, the number of misclassified data and the accuracy for each group). In this study, the discriminant analysis conducted into 6 groups of aggregate gives results as shown in  In recent years, the MLP network has been increasingly popular for applications in pattern classification, learning and function approximation. The MLP network consists of three main layers namely input layer, hidden layer and output layer. Each layer contains neurons which are linked to neurons of other layers through the weight and bias values. The network learns the relationship between pairs of inputs (factors) and output (responses) vectors by altering the weight and bias values.  The weights As this study proposes the MLP network to classify the aggregate into six shapes, thus the number of output nodes for the MLP network is set to 6, which each node will represent one shape of aggregate. For determining each shape, the actual output In order to increase the performance of the standard MLP network, this study introduces the cascaded MLP (c-MLP) network. For the classification purpose, the number of the inputs for the first MLP was assumed to depend on the number of moment features, which were 23 input features while the numbers of outputs depend on the number of aggregate shapes to be recognized, which were 6 in type. Since the third MLP takes input data from the second and the second MLP takes input data from the first one sequentially, the number of inputs and outputs of the second and third must be equivalent to the number of outputs of the first MLP which is equal to 6 (i.e. 23 input and 6 output nodes for the first MLP, but 6 input and 6 output nodes for the second and third MLP). For simplicity, we suggested that all the three MLPs adopt the same initial setting. For example, if the first MLP has 50 hidden nodes or being trained for 10,000 iterations (epochs), then the second and third will hold the same value of hidden nodes and iterations, and so on. The three classifiers in the c-MLP network function together to refine the weights of the input samples and improve the performance. After the input object is recognized using the first MLP, if any feature of an input object is not recognized correctly, the second MLP will take up the task and the same is repeated in the third MLP, thus increasing the classification capability of the system. In other words, each MLP has new input data with different normalizations, the second MLP re-trains the predicted outputs from the first and enhances the probability of having a correct detection and directly minimizes the classification errors caused by the first thus refining the weights of the faulty samples and this leads to increase the classification performance. The predicted outputs from the second MLP automatically feeds to the third in which the same scenario is repeated. In short, each succeeding MLP is employed to review and analyze the predicted outputs from the preceding MLP and give high priority for the misclassified samples. A total of 4242 sample of aggregates (i.e. the same samples used in The performance analysis of the neural networks is based on two important characteristics, which are accuracy and mean square error (MSE). The measure of the ability of the classifier to produce accurate classification is determined by accuracy, as mentioned in Eq. In applying neural network as pattern recognition or classification, one of the important criteria in learning process is the determination of optimum architectures of neural network (i.e. number of hidden nodes and epochs) ( To determine the network parameters, the experiments were carried out by varying the number of hidden neurons from 1 to 50. For each number of hidden neuron, the network was trained by varying the number of epochs from 1 to 10,000. The purpose was to find the number of epoch that produced the best generalization for each number of hidden neuron. The optimum epoch and hidden neuron, which produced the minimum value of mean squared error for the testing set, was noted and its classification accuracy was determined. To find the best learning algorithm, the proposed method has been tested and compared with twelve machine learning algorithms namely LM, BFG, RP, SCG, CGB, CGF, CGP, OSS, BR, GD, GDX and GDM algorithms. For each learning algorithm, the performance for the c-MLP with three MLPs (i.e. 3c-MLP) was compared with the c-MLP with two MLPs (i.e. 2c-MLP) and standard MLP network. Moreover, the performance comparison with other classifiers namely HMLP, RBF and discriminant analysis is studied.  As seen in The result in On the other hand, the performance of the proposed 3c-MLP trained with LM algorithm (as it's the best classifier) is compared with the HMLP, RBF and discriminant analysis as presented in From The result also shows that the 3c-MLP is the best classifier to further classify the aggregates into six shapes with high performance for each shape. Over the whole network comparison, the 3c-MLP performed better than other classifiers with recorded testing accuracy 94.04%, 98.46%, 94.13%, 98.52%, 99.79% and 95.55% for angular, cubical, irregular, elongated, flaky and flaky and elongated, respectively. In this paper, an efficient aggregate shape classification system using moment invariants and cascaded MLP network is introduced. Here, Hu, Zernike and Affine moments are calculated per boundary and area for 4242 images, where each image represents one of the six shapes in type. Using discriminant analysis, 23 optimum features have been chosen as suitable features for aggregates classification. The c-MLP is tested and compared with twelve different learning algorithms as well as comparing with other classifiers namely the HMLP, RBF and discriminant analysis. The comparison results show that the c-MLP network trained with LM algorithm can successfully be adopted for automatic aggregate shape classification with significantly high testing accuracy up to 97.1%. As seen in the experiments, the c-MLP is able to further classify the aggregate shapes into angular, cubical, irregular, elongated, flaky and flaky and elongated with high performance for each shape which is better than other classifiers. Our work concludes that the proposed c-MLP network is a powerful technique not only for accurate aggregates classification but also for improving the performance of learning algorithms. This technique is proved to be effective when three possible problems coexist, first, lack of sufficient input data to achieve low error rates; second, the poor features of the data; and third, a weak learning algorithm. As extension of this study, we plan to investigate the performance of the c-MLP in combination with other kinds of networks such as the RBF network, RNN, ART, ANFIS, etc., especially when dealing with multiple-input–multiple-output (MIMO) data. This work is supported by the Ministry of Science, Technology and Innovation (MOSTI) Malaysia, under Science Fund grants entitled ‘Development of an Automatic Real-Time Intelligent Aggregate Classification System Based on Image Processing and Neural Networks’ and ‘Development of a New Architecture and Learning Algorithm of Artificial Neural Network for Determination of Potential Drug in Herbal Medicine’.