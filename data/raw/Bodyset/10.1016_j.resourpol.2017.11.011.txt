Bulk commodities such as iron ore moving on a conveyor belt represent a one-dimensional lot providing an ideal opportunity for probabilistic cross-belt or cross-stream sampling at regular time intervals. The quality of such materials is measured by the mean, but the variability in the analyses arises from a variety of sources and is aggregated in a single figure for the standard deviation. The application of variography to a time-series of data analyses from a moving conveyor provides an effective means of analysing and disaggregating the sources of variability captured in the standard deviation of the data. Each component of variability leaves a distinctive fingerprint on the variogram, allowing its magnitude and contribution to the overall variability to be identified. Identifying sources of variability also enables one to make suggestions as to what aspect of the sampling protocol and sampling equipment requires improvement. The terms Sampling Capacity, Sampling Capability and Sampling Guidelines and their information content in the establishment of customer specification limits, in keeping with process plant capability, is described. Sources of variability arising from the Fundamental Sampling Error and Grouping and Segregation Error give rise to random variability that must be minimised through careful heterogeneity tests. Non-random variability due to plant process and biases associated with Delimitation Error, Extraction Error, Preparation Error and Weighting Error are identified and mitigated and may be eliminated by reducing the sampling interval and ensuring that sampling equipment recovers a correct sample. Cyclical variability in process streams is particularly detrimental to consistency in the grade of the product and its sources and methods for mitigation by reducing the sampling interval, are discussed. Reduction of large-scale variability provides significant opportunities to improve the product specifications and probably improve costs effectiveness through a less demanding blending routine. Determination of more appropriate specification limits can improve throughput and resource utilization.Pierre Gy addressed problems associated with incremental sampling of flowing streams during ship loading and mineral processing and applications of variography to the understanding large-scale variability in process plants and process control in the period 1960–1962. However, it was only in 1977 that he identified and quantified the rules regarding the shape and width of cutter openings, and their velocity through the material streams. More importantly, he found that samples collected at regular intervals from a moving conveyor belt, are “ Control charts (or Shewhart charts) in plant process control for solids, slurries, liquids and powders provide a graphical representation of the history of process variation in intermediate or final product composition with time ( Pierre Gy's 1960–1962 research into flowing streams of materials on conveyor belts and liquid launders brought to his attention the importance of sampling the “whole stream” for a fraction of the time, i.e. any increment must be a physical full slice of the stream. He identified the issues in regard to cross-stream sampler operation, namely that the cutter velocity through the stream, the width of the cutter opening and the shape of the cutter are all important, but it was first in 1977 that these issues were scientifically resolved. He also recognised that increments extracted at constant intervals from a flowing stream are correlated ( Sampling variability arising from selection of materials in a one-dimensional lot, the so-called Quality Fluctuation Errors are difficult to resolve into different components of variability, since one easily masks another. The variability arises due to the heterogeneity in a system or stream. This particular case study uses 150 data from a time series in excess of a thousand data. The choice of the number of data may depend on the time interval between samples, but more often than not about 150–200 data will provide the necessary information. The target average (TA) is the minimum acceptable grade prescribed by a customer whose requirements in terms of average grade and acceptable specification limits are a function of the plant feed for his processes or the maximum grade in the case of a contaminant. The difference between the target average required by a customer and the grade of ore delivered by a processing plant may be relatively small, in the order of 1–2 per cent, with the only consideration of the variability in the product stream being a calculation of the standard deviation of the analyses. A vast number of variables in Nature approximate a Gaussian or normal distribution in which the frequency of values is highest in the centre and tapers off symmetrically on either side of the centerline to extreme values ( Descriptive statistics for these data, provided in The value of the variogram lies in its simplicity as an effective tool for identifying the components of process variability ( Large-scale variability is most easily discernible in changes of product composition or cyclical variations of one-dimensional process streams in a process plant. This is typically variation within some range of limits determined by applying two or three standard deviations to the mean value over the total process stream. The importance of the variogram is that it relates process variation, not only to differences in grade between samples, but also from one sample to the next across time. The variogram allows one to identify such sources of variability and provides valuable insight into correlations between successive samples. Variography allows one to disaggregate sources of variability in process streams that conventional statistics and Statistical Process Control (SPC) are unable to identify and distinguish ( Understanding the combined effects of stream heterogeneity, the Quality Fluctuation Errors including the short range, long range and cyclical variation, provide the plant superintendent with the necessary insights to correctly manage the plant. This paper provides a systematic description of the components of variability in large-scale, time-based process streams that can be interpreted from the variogram. The iron ore illustration uses a control chart to show the mean, the target average, specification limits and control limits for 4-hourly data for percentage Fe. A 5-point moving average identifies the main cycles within the material stream. Having identified the values for random variability V[0], process variability V[1], and cyclical variability V[cyclic] from the absolute variogram these values then define the limits of plant process capability on the variability chart. Variability charts showing upper and lower limits for V[0], V[1], and V[cyclic], as well as upper (UCL) and lower control limits (LCL), derived from past performance, are presented here. Customer expectations about the variability of the suppliers product is reflected in the upper (USL) and lower specification limits (LSL). The supplier's knowledge of plant process capability ensures that an iron ore product, in keeping with customer expectations about the target average and specifications, is delivered. Control charts showing analyses from moving material streams as a function of time, indicate the presence of random or periodic fluctuations in grade. Individual point values are instantaneous measurements from a continuum, with the possibility that higher or lower grades may have passed between the points measured. Depending on the frequency of such measurements, the plant superintendent is able to monitor the variability in the material stream, adjusting the plant or process as required. The control chart may vary depending on the scale of observation, the length of time over which the random function is measured, the stationarity, and the nature of the variability ( The upper and lower Control Limits on a control chart define the range of product compositions a plant is able to produce. These limits together with the grade of the product, informs the superintendent's decision to adjust the processes when new changes, compared to past performance, justify such action. The 150 analyses of % Fe in The Control Limits, UCL′′ and LCL′′, defined by mean ± two standard deviations cover approximately 95% of the distribution telling us that 5% of assays or 7.5 of the 150 values, could lie beyond the upper and lower control limits; 4 assays or 2.7% actually lie beyond these limits The control chart is especially useful when customer specification limits or grades from Data Quality Objectives ( Control charts are simple tools for analysing and monitoring process stability. Based on past experience variability for stable, in-control processes are predictable within limits inherent to the process while unstable processes are subject to non-random variation from external factors ( Superimposing product specification limits ( In this iron ore case study, specification limits (USL and LSL) lie between the 3x standard deviation control limits (UCL″ and LCL″) ( The limits listed in The variability plot for percent iron in lumpy iron ore ( The dataset under consideration, with a lag of four hours, covers a period of 25 days, sufficient time for adjustments to the plant to remedy obvious sampling problems. Following an appropriate choice of width for the moving average window, the position should cover the most relevant data, usually the most recent data. Time dependent variations in grade on a conveyor belt due to material heterogeneity can be investigated using a variogram. Details of the variogram construction and interpretation of the variogram structure are covered in detail elsewhere ( where:     Since the variance of a constant is zero, the term The heterogeneity in a moving stream of material is best represented by a variogram, as shown in The absolute variogram using forty-five 4-hourly lags, shows two distinct cycles each with a period of 72-h ( A variogram-based hierarchy of control limits is defined in Pitard (1992) is of the opinion that these newly defined control limits listed in The mean grade, target average and customer specification limits form the framework of a control chart within which all other limits of variability can be analysed and interpreted. The customer in agreement with the producer sets the target average and specification limits, to provide the limits within which variability of the delivered iron ore grade must lie. The target average defines customer expectations for the average grade of the product he purchases, while the Upper and Lower Specification Limits (USL and LSL) define the necessary limits on variability. The mean grade of the stream of iron ore sampled from the conveyor belt should be marginally above the target average to ensure the producer has no difficulty delivering iron ore whose mean grade meets or exceeds customer specifications. In this case, the target average (61.18%Fe) lies exactly 0.38%Fe below the mean grade (61.56%Fe) in The range between TA and USL and LSL may vary depending on how the product will be used. Variations in iron ore grade within the specification limits shown in The relationship between sampling capacity, sampling guidelines and sampling capability provide a secure basis for matching and negotiating customer specification limits so they are congruent with the ability of the plant to deliver a given product. This assumes of course that the producer has done all that is necessary to optimise the plant in order to deliver the best possible product given the inputs he receives from the mining operation. The wider are the limits on sampling capacity, sampling guidelines and sampling capability the greater the inherent variability in the plant and hence the product. Customers prefer an iron ore product with as little variability as possible since a stable furnace feed makes it is easier to manage smelters and iron production. Sampling guidelines, one-third of the distance between TA and specification limits (Pitard, 1992), are established to ensure that the limits of plant capability to produce iron ore within a specified range are not exceeded. Where the limits of sampling capability exceed sampling guidelines, the customer will find the product to be out-of-spec and penalties will accrue to the supplier. Because guidelines are one-third of specifcation limits, the link between sampling guidelines and customer specification means that expanding the sampling guidelines to the point they just exceed the sampling capacity will result in equally expanded customer specification limits (as shown in The sampling capacity measures the combined random and non-random variability in the plant between one sample and the next due to the inherent characteristics the plant and the quality of the sampling equipment. Clearly we would want the process variability to be as small as possible. Lines in the control chart representing the upper and lower sampling capacity define the limits between which the total process variability, V[1] of the plant may fluctuate. When √V[1] is placed around the target average (TA) in the control chart it indicates the upper and lower sampling capacity. Limits to upper and lower sampling capacity are defined as the TA ± 1 SD of V[1] ( The answer to the important question about whether or not V[1] can be reduced, is yes. Provided the engineering aspects of the sampling technology and equipment fully complies with the principles in the Theory of Sampling, applicable to sampling equipment, it is possible in principle to remove all the so-called incorrect sampling errors (components of the increment materialisation error). Realism however suggests that process variability will never be removed completely, simply because of imperfections, even in the most carefully engineered equipment. The importance of the sampling capacity is that it, in conjunction with the sampling guidelines, informs the producer (and the customer) about the likelihood of the plant product meeting the customer specifications. The closer are USC and LSC to the target average the better, because the smaller is V[1] for the sampling process, the better. Narrow limits for the sampling capacity implies that the sampling equipment functions correctly, the sampling protocol is robust and precision is good. Wider sampling capacity limits places them closer to the USL and LSL and the worse is the precision with the current sampling equipment. The limits on sampling capacity indicate that it is not statistically possible to obtain a better precision than this. Limits on the upper and lower sampling guidelines are centred on the target average. They are placed in the variability chart according to a recommendation by Pitard (1992), that they lie one-third the distance between the target average and the customer specification limits, USL and LSL, as shown in Once sampling guidelines are established any adjustment on their limits also means an adjustment must be made to the customer specification limits. The producer, with the agreement of the customer, must set the limits on sampling guidelines, so that they are marginally wider than the sampling capacity. Where limits to the sampling guidelines are increased, the agreement of the customer to widen the specification limits must also be sought, without which the producer is likely to pay penalties for out-of-spec product deliveries. The sampling guidelines indicate the maximum acceptable variability in the stream and define limits between which the sampling variability should lie. The limits for USC and LSC inform the position of the USG and LSG relative to the USL and LSL. Pitard's (1992) suggestion that the guidelines lie about a third of the distance between the target average and the upper and lower specification limits, means that USG and LSG are linked to USL and LSL. Where this is not the case the upper and lower specification limits must be relaxed, as shown in Ideally, the sampling guidelines should be marginally wider than the sampling capacity and a graphical illustration of the effect of marginal increases in sampling guidelines relative to sampling capacity and the effect on the specification limits is shown in For the iron ore data under consideration, marginally widening the specification limits by 2.5%Fe to 63.68%Fe (USL) and 58.68%Fe (LSL) allows for sampling guidelines that are slightly wider than the sampling capacity. This allows the producer to operate within the plant capabilities and thus deliver in-spec product to the customer. Although the specification limits may be termed a nice-to-have, it is clear that the plant is unable to operate at this level of stringency and is likely to deliver a product that fails to meet the required grade. Provided the producer is able to convey the advantages of such modifications to the customer, both parties are better off. Whereas sampling capacity is the TA ± √V[1], the sampling capability is the TA ± √(V[1] – V[0]), so that V[process] is the difference between V1] and V[0] at the first lag, i.e., where j = 1. The V[process] component of variability indicates the size of the bias generated because of the interaction between the steel of faulty sampling equipment and the particulate material of interest errors in the plant, as shown in Sampling bias arises from two main sources, both of which are related to sampling equipment that fails to obey the principles of the Theory of Sampling. The first is the principle of symmetry, namely that the interaction between the stream of particles and sampling steel must be the same when the cutting device exits the stream, as it is when it enters the stream. The second principal is the centre of gravity rule that requires that fragments, whose centre of gravity lies inside the edge of the sampling device, must be captured as part of the sample. Alternatively, fragments whose centre of gravity lies outside the edges of the cutting device must not form part of the sample. Poorly designed cutting devices are the source of non-random variability related to the delimitation error (DE), and the extraction error (EE). Other bias generating activity can arise from the preparation error (PE), or weighting error (WE). The smaller the difference between V[0] and V[1], the less is the influence of bias generating errors. Sampling capability refers to the overall ability of sampling equipment to correctly delimit and correctly extract samples that are subject to correct preparation and weighting. If for example there was no bias in the system, V[0] be V[1] would be the same and V[process] would be zero. In summary, the relationship between control limits for the sampling capacity (TA ± combined random and non-random variability, V[1]), sampling guidelines (one third of the distance between TA and customer specification limits) and sampling capability (TA ± component of non-random variability, V[1]-V[0]) placed symmetrically around the target average, is shown in V[0] is the short-range random variability shown by the lowest horizontal, dash/dotted line in the Absolute variogram ( The total sill is a relative measure of the overall variability in the samples collected from the conveyor belt, but the random component V[0] may be reduced if appropriate attention is paid to the sampling protocol. If the ratio, V[0] to Sill is high relative to the overall variation, anything above 65%, it suggests that the sampling errors associated with short-range random variability, GSE and FSE, are significant problems. Because FSE and GSE cannot be disaggregated, the frequency of increment extraction, and hence the number of increments per sample, may be increased in order to reduce the component of variability arising from the GSE. The position V[1] in the variogram measures the random variability due to correct sampling errors, poor sampling protocol, FSE and the GSE combined with the non-random variability of incorrect sampling errors associated with delimitation, extraction, preparation and weighting errors, in effect V[1] = V[0] + V[process]. V[process] is the continuous, non-random component of variability in the plant between any two consecutive analyses; it is simply the difference between V[1] and V[0] at the first lag point. The variance and standard deviation of the non-random component calculated in Short-range random variability is represented in the control chart by the upper and lower random variability control limits (URL and LRL) by adding three times the standard deviation of V[0] to the mean or the target average, in order to cover the 99.7% confidence interval, as shown in The value of V[0] from the absolute variogram means the upper and lower random variability control limits (URL and LRL) lie slightly more than halfway between TA and the USL and LSL on the control chart ( V[1] is the typical value at the first lag point in the variogram, giving the total non-random variation between any two consecutive analyses. It combines the total random sampling V[0] and non-random process capability (V[1] − V[0]) between consecutive samples. The position of the upper and lower process control limits, UPL and LPL, are set in the control chart by multiplying the standard deviation of V[0] by 3 in order to cover the 99.7% confidence interval, and then adding the contribution from √V[process] as shown in The upper and lower process control limits (UPL and LPL) include both random and non-random variability arising between two consecutive samples. UPL and LPL are set in the control chart by adding 3 standard deviations of V[0] in order to cover the 99.7% confidence interval, and then adding the contribution of a single standard deviation from √V[process]. The position of the sampling, measuring and process variability relative to the product stream is shown in the control chart as UPL and LPL, shown in Cyclicity in the process, evident in the moving average (  Upper and lower cyclical (or alternating) control limits (UAL and LAL) based on the component of cyclical variability, V[cyclic], in the system are shown in Pitard's (1992) caveat that control limits UAL and LAL, should not lie beyond the customer specification limits means the cyclical variability is an unacceptable and major component of the difficulty in trying to maintain stability in the iron ore product. Cyclical interventions are the primary source of variability in this particular case study. Generally, adjustments to a process stream, such as changing the liquid concentrations in a launder in hydrometallurgical processes or changes in the process when the system is already near the peak or trough of a cycle, is probably the worst time to make corrections to the process. The total variability contribution from UAL and LAL exceeds the variability prescribed by the Data Quality Objectives (DQOs), specifically the upper and lower specification limits. The interpretation of the position of in the control chart indicates that the process is not controlled using the current protocol. In addition, the reasons for the 3-day cycle are poorly understood. Once the source of the cyclical variability is identified, the opportunity exists to reduce the variability and control the process much more rigorously. The only way in which cyclical variance can be reduced to an acceptable level is by identifying the source of the cyclical variability and removing it ( V[sill] is the average variability of the process measured across the entire variogram and is a measure of the total variance in the total 150 data set. V[sill] is the brown, dotted, horizontal line in V[trend], shown in Probabilistic sampling from a moving conveyor belt provides a one-dimensional stream of samples collected at regular time intervals. The use of the variogram as a tool for understanding aspects of the variability in the composition of the product on the conveyor belt or process plants is essential if plant and processes are to deliver a product that is acceptable to the customer. The variogram provides the only detailed means of disaggregating the components of variability from one another and thereby understanding the characteristics of the process plant. Once the different apects of variability in a plant are fully understood, a strategy to produce a product that will meet customer specifications can be determined ( Random, non-random and cyclical sampling variability are related to sampling errors identified by the Theory of Sampling. The only means of reducing sampling variability is to improve sampling protocols and sampling equipment. In general reducing sampling error and sampling bias by careful application of the principles of the Theory of Sampling leads to reduced sampling variability and hence to improved resource use.  It is evident from the moving average plot, the variogram and the control limits that the most damaging source of variability is a 3-day cycle in the system. The pie diagram shown in In this particular case study, the position of the sampling guidelines indicated that the specification limits would have to be relaxed if the sampling capacity is to be correctly accommodated by the plant equipment and protocols. Strictly, an alarm to investigate the primary and secondary sampling procedures should be triggered, and heterogeneity studies in order to minimise the FSE and GSE should be initiated. By adding the total process variability (UPL and LPL), the control limits lie beyond the suggested range and are close to the specification limits. In this case study the process variability V[1] is greater than the random variability V[0], suggesting that a sampling interval closer than 4 Surprisingly the 14.5% contribution from non-random sources of variability ( Francis Pitard (fpsc@aol.com) and Max Pitard (mpitard@honuatek.com,