The open pit mine production scheduling problem (OPMPSP) consists of scheduling the extraction of a mineral deposit that is broken into a number of smaller segments, or blocks, such that the net present value (NPV) of the operation is maximised. This problem has been formulated as an integer programming (IP) model, involving both knapsack and precedence constraints. However, due to the large number of blocks and precedence constraints, this model has remained impractical in real planning applications. In this paper, we propose a new method to quickly generate near optimum feasible (integer) solutions by using the fractional solutions from the linear programming (LP) relaxation of the IP model. To be applicable to real sized problems, a new heuristic that quickly computes a feasible LP solution is also proposed. Our methodology is tested on a set of both academically designed and real-world mine deposits, and shows better performance than the heuristic used to tackle the same deposits in the literature. Interestingly, the proposed methodology improves the best known solutions for the majority of the instances. For the purpose of planning and scheduling the extraction of a mineral deposit, it is broken into a number of smaller more manageable segments or blocks that contain an estimate of several key attributes, including the quantity of valuable material within each block. The combination of all blocks that comprise a mineral deposit is known as a block model. The attributes associated with each block are generally estimated from drill-hole data samples using geo-statistic techniques to interpolate between drill-holes. Blocks may all be uniform in size or may vary in size depending on the nature of the mineral deposit; however their dimensions are generally compatible with the span and reach of the equipment that is used in the extraction process. Blocks containing valuable mineral and waste material are scheduled across the life of the mining operation. The objective of this strategic mine plan is to maximise Net Present Value (NPV) while complying with all constraints. In the planning of mining operations, the major issue is to determine the optimal schedule for block extractions subject to a variety of operational constraints. This gives rise to the open pit mine production scheduling problem (OPMPSP). Due to the fact that extraction should be carried out with a specific angle, known as wall-slope angles, the block extraction process must follow a sequence in which all corresponding blocks located above each block have been removed. This is reflected as a precedence constraint when modelling OPMPSP. When scheduling the extraction of valuable mineral and waste material of an open pit mining operation across a predetermined time horizon it is essential to maintain resource capacities. The maximum processing capacity limits the amount of valuable mineral that is sent to the processing plant across each time period. The maximum mine production capacity limits the amount of valuable mineral and waste material that may be extracted in each time period. The physical limitations reflect on site equipment capabilities, haulage distances and the size of the processing plant. wSince the 1960s, numerous researchers have been addressing OPMPSP. Early studies were only focused on the  set of time periods set of blocks set of resources amount of resource profit obtained from block amount of resource the set of all precedence relationships in the problem 1 if block Subject to: In this formulation, the objective function ( Since the 1980s, a number of methods have been developed to solve the ILP. Dagdelen and Johnson Chicoisne et al. Cullenbine et al. A topological sort, or a topological ordering of a directed acyclic graph (DAG), is a linear ordering of its vertices such that for every directed edge We now describe the contribution of this study. In an attempt to address C-PIT using the TopSort heuristic, we observed the following two special properties in the solution of the LP relaxation formulation. Based on the concept of mathematical expectation (expected value) in probability theory, an expected value of In the solutions generated by the LP relaxation, the values of the decision variables in the last time periods are generally identical with those of the optimal solution. To our best knowledge, these properties have never been discovered in the literature. We propose a methodology to employ these properties in order to directly and efficiently schedule large size OPMPSP instances. In order to test the abovementioned properties, the LP relaxation solutions will be evaluated by transforming them to integer schedules. This transformation will be conducted by a heuristic that is based on the topological sort concept, i.e., the TopoSort heuristic. In The efficiency of the proposed methodology is judged in In this section, we first describe the well-known TopoSort heuristic. In Throughout this paper, we refer to two sets of problems on which our experimental studies have been performed. The first set contains eleven instances available in an online library known as “MineLib” ( Apart from the instances in Mine Library, we have also used a set of conceptual instances created by Samavati et al. Before explaining our methodology, we describe both the topological sort concept and the TopoSort heuristic that have been applied to several scheduling problems with precedence constraints. We exploit this heuristic to evaluate the LP relaxation solutions generated in our methodology. A topological sort, or topological ordering of a directed acyclic graph (DAG), is a linear ordering of its vertices such that for every directed edge In topological sort, an eligible set contains the vertices with 0 in-degree. The sort process generates a precedence feasible sequence of blocks by repeatedly selecting a vertex from the eligible set, en-queuing it into a sequence, removing the vertex and its outgoing edges from the DAG, and finally updating the eligible set. For instance, in Because a DAG can have many different topological orderings, a weight Given a weighted topological ordering, a feasible schedule can be simply obtained by the TopoSort heuristic. For the convenience of following the paper, this heuristic is described in Chicoisne et al. Finally, for each block Based on the concept of mathematical expectation (expected value) in probability theory, it is not hard to see that the abovementioned Considering this fact, it is clear that if In the LP relaxation solution of a given problem ( Subject to: ( In order to check the assumption whether  Subsequently, we randomly selected a non-integer decision variable from the LP relaxation solution of node 2 (decision variable It is not guaranteed that the TS heuristic yields a better schedule with a more realistic probability distribution due to the aforementioned TopoSort random issue. Even though by cutting off the current LP relaxation solution (the current non-integer optimal point) the continuous feasible space of this formulation becomes smaller, and in effect the probability of getting the optimal integer solution is increased, there is no guarantee that the new LP solution (i.e., For all three instances in Experiment 1, we continued for 20 nodes. As can be seen from In In Experimental Study 1, we rounded variables according to their values in the optimal schedule. In practise where the optimal schedule is unknown, we have to separately add both cuts However, it is not possible to recognise this better cut, as the other cut may lead to an enhancement in the schedule too, which can be considered as a local optimum. In this case, both of the generated nodes need to add a new cut for further improvement. By continuing to add cuts to both nodes, a node tree will be obtained. In Experimental Study 2, conducted on all the instances in  From this figure, at least 80% of the generated nodes have improved the schedule in the root node. Note that, as stated earlier, Chicoisne et al. In this section, we propose the adding cut technique to exploit the first property in the LP relaxation solution. This technique is essentially a branch-and-bound algorithm that applies TS in each node of the tree. Let a root node be the first node in which the LP relaxation solution of C-PIT is solved. Similar to Experiment 2, non-integer decision variable While this method is fast (simply because LP relaxations can be solved quickly using LP solvers for small problems or Critical Multiplier Algorithm (CMA) by Chicoisne et al. One of the problems in the AC approach is solving the LP relaxation formulation of C-PIT. Although MIP solvers are fast and efficient for solving LP formulations, they may have difficulty solving extremely large instances of OPMPSP. Chicoisne et al. In Also, suppose Note that for generating LP solutions by either the CMA of Chicoisne et al. It has been stated above that selecting non-integer variables from the first period is the best choice in our AC technique due to the second abovementioned property. In this section, this property is assessed. When applying the AC method to different instances, we observed the following three facts: A huge proportion of decision variables in a generated LP relaxation solution has a value of 0 or 1 in the last time periods. The main reason for this observation would be constraint ( A large number of decision variables in different LP relaxation solutions have identical values in the last time periods. For example, if As stated earlier, for generating a LP solution by either CMA or our developed heuristic, it is necessary that the formulations have a single resource constraint per time period, and thus instances with more than one resource must be divided in separate formulations, each containing one of the resource constraints. Our third observation is the fact that in an instance with say two resources, the decision variables from the two resulting LP relaxation formulations are extremely similar in the last time periods. From these three observations, as well as the fact that the AC's LP relaxation solutions are near optimal, there is a possibility that the decision variables in the last time periods of these solutions are already identical with or similar to optimum. If this is true, then the decision variables of last time periods have little to no effect on improving the solution quality. In order to test this possibility, an experiment was performed on the instances of  We now illustrate our experiment. The decision variables were divided into two categories A and B. Category B contained the decision variables in the last time period, and category A contained the variables in the remaining columns. The groups of decision variables were generated from categories A and B separately. Therefore, the groups from the two categories were entirely distinct from each other. As the black-box progressed, the best NPV found in each group at the end of each step was recorded. Having analysed the results for other instances, we come to an overall conclusion that the further we get from the first time period, the less effective the decision variables are on the convergence process, and for the last time periods, the convergence is almost zero. Thus trying to improve the decision variables of the last time periods is not computationally reasonable. We believe this conclusion can revolutionise the research area, as the dimensionality of a problem can be significantly reduced. Many algorithms can be developed in the future in order to converge the AC's LP relaxation solutions towards the optimal solution, without including some of the last time periods. In the next section, we obtain the solutions of the Mine Library instances, by excluding the decision variables of the last 30% of time periods. To evaluate the performance of our AC technique, we test it on a set of benchmark instances known as “MineLib” compiled by Espinoza et al. The benchmark instances provided by Espinoza et al. The algorithm was coded using MATLAB 7.12.0 (R2011a) and run on personal computers with an Intel Core i7 CPU at 3.40 GHz, 16 Gigabytes of RAM, operating under Microsoft Windows 7. The LP relaxation solutions for all instances were computed in IBM ILOG CPLEX studio 12.6. The best known NPV of the test instances until 2013 has been provided by Espinoza et al. Liu and Kozan As stated in We solved instance  In this work, we proposed a new algorithm, called AC, in order to address large scale OPMPSPs in a more effective and efficient way. We first raised two special properties in the LP relaxation formulation: (1) by adding some special In order to exploit these properties, we proposed the AC technique in which we iteratively add We tested the performance of our AC algorithm on the recent benchmark instances from MineLib Regarding the future research directions, we demonstrated that a number of decision variables in LP solutions are not fractional and can be identical to the optimal solution. We believe this can be considerably exploited in the future, as some variables can be fixed before starting a solution procedure, thereby reducing the dimensionality of the problem. However, there is still a question of how many time periods should be fixed in order to reduce dimensionality without losing quality of solution. This trade-off between quality and computational effort can be considered for future work. The proposed AC algorithm showed impressive results; however, the minimum resource requirements that are of importance for mining companies should also be taken into consideration in the future. It is believed that the AC technique is more flexible than other successful algorithms in the literature and thus can potentially be modified to involve the minimum resource requirements. As mentioned earlier, we iteratively generate LPs and run TS on them in a black-box that uses a general Evolutionary Algorithm. This can be done by any Evolutionary Algorithm, heuristic or metaheuristic. In this study, we selected the Genetic Algorithm (GA). GA solves optimisation problems based on a natural process mimicking biological evolution. This algorithm repeatedly changes a population of individual solutions by modifying the solutions. For details about GA, readers are referred to Holland Instead of starting from one node (LP solution), our black-box starts with several nodes at the same time and implements the process of generating LPs and running TS in parallel. In each node, the decision variables are divided into different groups. The groups progress simultaneously and in parallel too. Each group progresses for a certain number of steps, and afterwards, the black-box takes the LP with the best obtained NPV and starts the process all over again from that LP. We call this a ‘cycle’. Thus, if cycle is equal to 5, it means that the black-box does the process of taking the best LP and starting from it, for 5 times. We do this procedure by GA. For convenience of coding and using our black-box, we provide the pseudocode in In Step 4, several different subproblems are generated. Each subproblem includes a few LP solutions. The aim of each subproblem is to only evolve a specific group of decision variables. The subproblems progresses separately and in parallel. Step 6 describes the process of evolving each subproblem using GA operators. Over the last few decades, several crossover and mutation operators have been introduced for optimising problems with a continuous search space, such as blend crossover (BLX- A generational scheme is the second aspect that needs to be considered when using GA. It is related to the way the generated offspring are inserted in the population after applying crossover and mutation. The most basic way is that offspring directly replace the parents. In this paper, the elitism rate is 3, implying that each population holds the best three individuals and replace the others with generated offsprings. This means populations in each subproblem in Algorithm III contain different solutions, whilst concurrently evolving steadily to better NPVs (fitness function values). Similar to any other optimisation algorithms, our algorithm involves control parameters that need to be calibrated. In the proposed algorithm, two parameters require such calibration: (1) subproblem size ( For the purpose of calibration, the Design of Experiments approach has been applied in this study (see Mongomery   Parameter tuning using factorial design has been taken into account in several studies Thus, the procedure of calibration by means of factorial design is as follows: it begins by running all the alternative algorithms, yielded by different combinations of studying factors, on one or a series of instances. The results (the response variable of the experiments) are then analysed by means of the ANOVA method. This analysis yields an The procedure continues this way until all the factors are fixed, that is, all the parameters of the algorithm are tuned. We applied the same procedure to the Mine Library problems to calibrate our algorithm's parameters. In our case, we had a total of 4  ×  7 = 28 different combinations to test. Note that we divide the Mine Library set of problems into three different categories, based on the number of decision variables, as illustrated in The first instance of the Mine Library set of problems was not considered in any of the categories for calibration, as the size of this academically designed instance is extremely small and would cause great influence to the calibrated precision of parameters. Regarding the response variable for the experiments, the following performance measure is considered for every instance: Having conducted the ANOVA test on each category separately, it was noticed that the highest and lowest