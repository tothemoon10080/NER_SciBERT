After reviewing the wide field of application of stochastic processes in Chemical Engineering, with specific attention to particulate processes, the definition of a Markov chain is given and commented upon using an example. Batch grinding processes are then analysed from this point of view, emphasizing the link that exists between both stochastic and deterministic (based on population balance) approaches. Breakage and selection functions appear to be clearly linked to the transition probabilities of a Markov chain via the definition of a time interval characteristic of the grinding process. This provides a physical significance for the time interval. An identical analysis is made for continuous grinding processes which underlines again the similarity between both approaches. These concepts are illustrated by the use of experimental grinding data obtained in a stirred bead mill which shows the high degree of fit of the Markov chain model for both continuous and batch experiments.Over the last thirty years, the use of stochastic processes – and Markov chains – has slowly developed in Chemical Engineering and is now accepted as an alternative to traditional descriptions of physical and chemical transformation of materials by means of conservation equations and kinetics. Because the nature of this type of approach is probabilistic, it has been successfully applied in fields where ideas and phenomenon at play demonstrate a strong statistical character. Therefore, it is not surprising to see that stochastic processes have slowly found its place in the general field of discontinuous media and, in particular, granular media (see The problem of solids mixing, and essentially static solids mixing, has been investigated from this point of view. On dealing with the application of stochastic approaches to grinding processes, the literature seems to be less abundant. The point of view which is generally presented (see Many systems have the following property: if the present state of a system is known, passed states do not affect the transition from the present state to the next (future) state. This particular property that describes the lack of “memory” of a system, is called “the Markov property” and systems that obey this property are “Markov chains” or “Markov processes”. Consider now (see Let In order to introduce more concretely these ideas, we use here an example inspired by the work of More precisely, and to complete the analogy with the notions mentioned above, each compartment of the labyrinth is a state of the system, and the probability of movement from one compartment to any other one is the probability transition between these states. As probabilities do not vary with the time spent in the labyrinth, the associated Markov chain has stationary probability transitions. It is important to note that it is assumed that the displacement of the animal occurs in discrete steps of equal duration. The consequence of this point is that all the transitions occur at each step, making the Markov chain time discontinuous. When referring to Markov processes, the notion of absorbing states often appears to be important. When the systems “falls” in such a state, there is no possibility of its transition to other states (consequently, the transition probability from this state to itself is equal to 1), it is absorbed and “goes out” of the chain. For the above-mentioned example, the absorbing states correspond to the compartments occupied by lions, which are supposed to be predators of the cow. For ease of calculation, the absorbing states often corresponds to the greatest numbers of states. In the example above, if we suppose that the probability transitions from a given compartment are only possible towards the neighbouring ones, and are the same for each of these, then the transition matrix (for the numerotation of the states in The conventional approach (see  If we define a system that can distribute itself through steps, and if we are able to evaluate the probability transitions between these steps, then we can derive a stochastic analysis as in the example in the first part of this work. Let us choose a mass When dealing with the “traditional” approach, and in particular when solving the batch grinding equation as in First of all, as both For any size fraction  Even if parameter If the probability transitions are stationary, it can be observed that The probability transitions being independent of the states of the system (Markov property), Breakage and Selection functions appear to be independent of The following example uses the previous data ( As it was expected, the more steps considered between 0 and This demonstrates that the grinding process in a stirred bead mill can be represented by a Markov chain characterized by 100 steps of grinding for 12 In the above, it must be borne in mind that the probability transition matrix was calculated from a set of Breakage and Selection parameters, and not from direct experimentation. The best way of applying this protocol to experiments would consist in milling a sieve size fraction (noted by the size index This experimental procedure has two main advantages with respect to the traditional method for determining It does not require any tracer experiments, avoiding the problem of the grinding behaviour of the tracer with respect to that of the “real” particles. It requires as many experiments as the number of defined size fractions, whereas the  Again, a stochastic analysis can be applied to this process by defining a system, its states and transitions. Let the system be a constant mass of powder Therefore, there exists a transition matrix When dealing with continuous grinding, it is usual to refer to the Residence Time Distribution (RTD) of the particles in the mill ( The link between both approaches again appears to be clear. As in the first case the particle size distributions are line vectors and the second column vectors, the transition matrix must be the transposed of matrix Let us take the example of the stirred bead mill that can be used continuously ( This model allows for the establishment of the following expression for the Laplace transform of the RTD, involving the geometric residence times in every compartment In this paper, we have tried to demonstrate the ambivalence of the two approaches that describe the change in particle size distribution during grinding (in both continuous and discontinuous modes), namely a stochastic analysis and the so-called deterministic analysis which is fundamentally based on the definition of two statistical functions (the breakage function and the selection function). We then showed that these functions could be easily expressed in terms of the probability transitions of a Markov chain and a characteristic grinding time that corresponds to the time interval between two breakage events. This description is perfectly suited to the grinding process that takes place in a stirred bead mill, for which a characteristic time of 0.12 min is enough to model the grinding action of the mill. The main interest of this stochastic approach lies in the reduction of the experimental work with respect to the traditional approach for which a complete kinetic study is necessary. Several perspectives arise from this work: A new methodology can be proposed for determining the Breakage and Selection functions from the stochastic analysis, as these functions appear explicitly in the probability transition matrix. The Breakage and Selection functions could be defined from the probability transitions, in relation with the different grinding mechanisms (destructive breakage, cleavage and abrasion). Non-linear breakage could be analysed as being through unsteady-state probability transitions. This would be possible by taking into account a variation of Taking into account different time intervals Such a model could be extended to take into account other distributed end-use property rather than particle size. This should be the case of particle shapes that can be quantified and discretized through morphological descriptors, and for which the states could be represented by “morphological intervals” in the same way as for “size intervals”.