Didactic data sets representing a range of real-world processes are used to illustrate “how to do” representative process sampling and process characterisation. The selected process data lead to diverse variogram expressions with different systematics (no range vs. important ranges; trends and/or periodicity; different nugget effects and process variations ranging from less than one lag to full variogram lag). Variogram data analysis leads to a fundamental decomposition into 0-D sampling vs. 1-D process variances, based on the three principal variogram parameters: range, sill and nugget effect. The influence on the variogram from significant trends and outliers in the original data series receive special attention, due to their critical adverse effects. We highlight problem-dependent interpretation of variographic analysis a.o. the problem-dependent background for periodicities and trends. All presented cases of variography either solved the initial problems or served to understand the reasons and causes behind the specific process structures revealed in the variograms. Process Analytical Technologies (PAT) are not complete without process TOS.The Theory of Sampling (TOS) has been introduced in chemometrics, analytical chemistry and process technologies by a recent, dedicated Scandinavian effort, based on classical TOS references Sampling representativity will always be strongly coupled to process and product types, because each process/product poses an intrinsic heterogeneity characteristic. It is not possible to rely on one general sampling scheme for all process sampling, indeed such a notion is but a wishful thinking. Empirical, experimental sampling error evaluations are needed for every principally new product or process. TOS offers a completely general approach for characterizing the 1-D heterogeneity of any process or 1-D material stream termed In this work focus is on the practical issues associated with a  A A For process sampling in industry at large, over time many different combinations of equipment and procedures have been developed locally, very many of which are far from based on a full understanding of the Theory of Sampling (TOS) unfortunately, The scope of the present work is to present a universal approach for evaluating the existing sampling equipment and the 1-D heterogeneity present for any process/product stream and to suggest improvement initiatives where necessary. Even though there exist a widely varying plant and production logistics situation at industrial process technological production sites at large, it will never-the-less be possible to delineate an extremely simple approach based for the estimation of the total sampling error (TSE) based on a data analytic (variographic) treatment of as little as 40–60 samples only. The process of taking a sample — characterizing a complex, large system based on a small part hereof is, contrary to many beliefs, not an easy one, although the task specification could not be simpler: a A minimalist terminology used in TOS: The A A An A A The The TOS defines sampling as a multi-stage process, which covers all operations from an increment is materialized until an aliquot (measured portion of a sample taken for analysis) is administered to the final analytical operation — for example a spectrometric determination in the quality control laboratory. The goal of a sampling procedure is to extract a sample with the same properties as the lot where the sample came from — a With process sampling, a sample is preferably always materialized through several increments from the lot to make up a The relative sampling error is defined as: A sampling process is said to be The notion Only a The random component of the sampling error represented by the variance tends to reduce when averaging over a large number of increments (or samples, as the case may be). The systematic part, however, does not. It is essential to assure a correct and hence accurate sampling in order to cancel the systematic part, the bias part of the sampling error. When a correct sampling is in place the potential in TOS lies in characterizing and minimizing (if not eliminating) as many as possible of the remaining sampling errors, Analytical results always have an inherent uncertainty. This uncertainty is a consequence of imprecision caused by sampling errors, in addition to the ultimate analytical error, at In TOS the With exception of IPE FSE TFE and CFE ( The compositional differences between particles in a lot always result in a sampling error (called the fundamental sampling error) because not all particles are analyzed. The adjective “fundamental” is substantiated by the fact that this error is always present in any practical sampling situation, meaning that even a perfect sampling implement will not be able to materialize two samples with the exact same composition. The The grouping and segregation error (GSE) originates from an inherent tendency for particles to segregate and/or to group together (spatial coherence to a larger or smaller degree) in a lot. Unlike FSE this error is MPE is by definition the sum of the fundamental error (FSE) and the grouping and segregation error (GSE): The minimal practical error plays a particularly important role in Different errors are made during sampling and they all affect the degree of representativity of the final aliquot going into the analytical equipment in the laboratory. The incorrect sampling errors all come from ill-designed sampling procedures or equipment, non-optimal maintenance hereof or human errors. However, they are possible to avoid when one is aware of their existence. Two of the incorrect sampling errors — the These incorrect sampling errors should all be eliminated instead of estimated In principle, there is no trade-off or bargain with incorrect sampling errors, but All this, and much more, can be achieved in one single operation, establishing a variographic heterogeneity characterisation of the 1-D process or material body in question. The true concentration of a particular component in a material stream (pipeline, conveyor belt, product series) is never known. The conceptual series of successive concentrations of component A along the 1-dimension is in theory a continuous function of time, The The sill represents the average overall variance of the heterogeneity The nugget effect is estimated by extrapolating the variogram backwards to The nugget effect is a sum of all variances in the 0-D sampling situation — correct and incorrect sampling errors as well as the total analytical error The historical TOS literature This section makes use of industrial, technological and other real-world data sets and gives a description of the sampling and analytical setup that supports a variographic evaluation and estimation of the total sampling error for each. The latent information in process data series, brought about by a careful problem-dependent Practical estimation of TSE is extremely easy, as it follows directly from the same basic calculations attending the variogram. It is possible – at From a didactic point-of-view, it proves highly advantageous first to present the specific data sets and their variographic interpretations; 2003 ACABS carried out an extensive didactic experimental campaign, designed to illustrate major sampling factors and their influence on the total sampling error, and its breakdown into FSE, GSE, ISE, CSE, amongst other grab sampling vs. composite sampling, increment size vs Two different concentration levels are investigated here: 0.1% and 25% (w/w). These mixture systems were sampled completely using three scoop sizes: 5 ml, 25 ml and 100 ml respectively (realistically related to the total volume of the model lot). The total weight of mixture material in the container was 4.000 kg, corresponding to a volume of approximately 3500 ml. For both the trace concentration, 0.1% and the major level concentration, 25%, each loading of the model lot was performed as a pre-mixing of the yellow and black pellet fractions in the aquarium. Mixing was effective, but not complete (i.e. not reaching a complete minimum residual heterogeneity), as it was desired to illustrate sampling from significantly heterogeneous systems; mixing was therefore performed only until visual inspection did not reveal any systematic trends.   The heterogeneous mixture system with identical analyte concentration (0.1%), when sampled by a five times larger (25 ml) scoop, reveals a sill level estimate of 0.6, compared to 2.0 for the smaller (5 ml) scoop, By way of contrast, a 100 ml scoop is now used, resulting in only 42 scoops before the lot is completely emptied. A further reduction in sampling variance results, by a factor of 6 compared to the 25 ml scoop above, and by a factor of 20, compared to the 5 ml scoop, see The level of the sill of the variogram carries essential information of the sampling variance experienced in repeating the unit sampling operation with differently sized increments, witnessed by the progressive reduction of the overall level of the sampling variance: 2.0–0.6–0.09 respectively. Variography of all three trace concentration systems revealed no trends in the spatial (3-D) constitution of the entire lot, evidenced by there being no ranges or trends in the variograms. For a typical “major concentration” of 25%, the material system no longer behaves in the same manner, as it is obviously no longer in the trace concentration domain. It is generally The overall sampling variance, the sill, is now approximately 0.011, but most importantly, a distinct trend is observed in the variogram. The trend is present to a range of approximately 250 lag. Inspecting the raw data series (upper left panel) reveals a statistically distinct, increasing trend almost exclusively for the last 250–300 scoops for which an average level of 23–24% increases towards an ultimate concentration of > The major issue here is that FSE (together with GSE and TAE) is isolated, and subtracted, into the nugget effect (MPE), so prominently depicted in the lower left variogram panel of When sampled by the largest scoop, 100 ml, the trend in the system is still present — in fact it is distinctly clearer; the variogram in Comparing In Comparison reveals that the only effect of the removal of a marginal outlier is a slightly more well-expressed flat variogram for the important smallest lags (first half lag series). We shall see more adverse effects from significant outliers further below. The The Ribe Biogas plant was commissioned August 1990. For a decade it has been the largest agricultural manure and food waste-based anaerobic digestion plant of its kind in northern Europe. It is based on three bioreactors (each of a volume: 1800 m Process monitoring and laboratory analysis of routine samples from the anaerobic digestion plant is performed daily as part of a systematic quality assurance program. Several parameters are analyzed in the raw materials and the product gas. Here we make use of the most important product parameter, the methane (CH The biogas product yield and the pollutant H H From the science of The variogram in the lower left panel in The exact 7-day period is related to the fact that during weekends the capacity for a constant pre-mix of the loading raw feedstock is restricted. Even though all storage capacities are full by Friday evening, there is lag of concentrated industrial waste being mixed in the bioreactors by the end of the weekend, most pronounced on Sundays. As a consequence, the biogas raw material is changing its profile, experiencing reductions in the amount of industrial waste containing iron chloride. Iron chloride in the organic industrial waste reduces the H Variographic analysis is fatally influenced by significant outliers, as is very well illustrated by the sequence of The variogram in The difference in the resulting variogram could not be any more contrasting. The variogram now reveals one, maybe two cyclicities superposed on a somewhat unclear sill and range, characterised by a range of ∼ The resulting variogram is now simplicity itself as compared to its two predecessors: the nugget effect shows a drastic reduction (0.40, 0.006 and 0.001 respectively), as does the sill(s), but most importantly, the true underlying variogram reveals a The biomass feedstock composition consists Irrespective of the detailed explanations eventually laid bare, the effect of the variographic analysis has already resulted in a new Outliers, defined here as extreme, or very irregular–missing or otherwise bona fide “unreliable” increments influence all variograms significantly–sometimes fatally; outliers should be delineated and deleted The periodicity of a variogram carries essential information about the underlying process characterised by the data series. Variography of the two selected biogas parameters revealed cyclicities with very different expression and distinctly different causes — fully understood only when detailed interpretation of the variogram information was undertaken in the proper problem context. Reasons and causes behind periodicities were known–or inferred–in the present context. This demonstrates how detailed interpretation of the potential information present in a variogram leads to increased understanding of the process being analysed. Unrecognised periodicities may easily have significant negative economic consequences. This data set (downloaded from the public domain) represents a sector in which variographic analysis plays an important, growing role, the financial sector. Any commercial company with a significant interest in metallic raw materials or products, or similar materials traded and quoted on the international commodities exchanges, will be interested in analyzing (thereby hopefully more full understanding) the time-dynamic fluctuations involved. As is well-known, data types like stock exchange share prices, commodity prices and similar economic forecast data, are overwhelmingly characterised by In financial circles it is strongly believed that analysis into the specifics of the trend-, periodic or chaotic behaviour of such data series, termed “chartism”, may lead to a valuable (in the most original sense!) insight in the future behaviour of prices, which may be cashed in (again — in the most original sense) by judicious The objective of the analysis of this data set is here simply to illustrate what can be gained from a variographic decomposition (and interpretation) in which the process relationships behind the data series are not known with certainty, but very tenuous at best — if existing at all:  A variographic analysis of such data will be an objective, neutral description only (but anyone is free to speculate and interpret the results, of course). Our main interest in such data analysis will be to isolate, and to interpret if possible, the nugget effect (MPE) and, if possible, to interpret the The major trends in the Zn-data cover a dramatic large-scale increase at the ending of the 5 years in question. From what has transpired above, it would not be of interest to include these mega-scale trends in the variographic analysis. One way to get rid of “annoying trends” is to prune the data series into a set of stationary segments; proper de-trending shall also be illustrated below. We shall first limit the variographic analysis to two subsets, both with approximately There is a remarkable evolution to the series of three variograms above. While the full data set variogram, as well as that for the < For a more strict scientific data analysis point-of-view, there is one new feature not yet encountered in any variograms above however: there is The proper variogram speaks very directly: here be A second illustration pertains to a similar variographic analysis of the daily spot price for North Sea Brent crude oil, which serves as a benchmark commodity. These two oil price data series and variograms, one apparently suffering both from a prominent outlier peak as well as potentially debilitating severe trends ( The last demonstration data set stems from the comprehensive TOS textbook by Pitard One legitimate concern could be that too trigger-happy de-trending may perhaps endanger full understanding of the behaviour of the original data series. This worry can be fully alleviated by  Significant trends (and/or periodicities) in the original data series may be subjected to appropriate time-series analysis The power of variographic analysis was demonstrated with full clarity: absolutely all pertinent structural and/or MPE details will be revealed in the variogram; examples includes a small, yet fully distinguishable MPE and pervasive systematic, but Estimation of TSE, the total sampling error, is extremely easy, as it follows directly from the same basic calculations attending the variogram. It is possible–at Any process sampling scheme is fully characterized by two parameters only: the sampling rate, For all examples a set of In addition, VARIO also allows for completely free specification of the sampling rate, Together, these two optional features will allow It is easy to find an optimal sampling strategy by inspecting the plot of TSE as a function of The level of the The trend of the variogram carries essential information about the range of important trending in the original data series. Outliers and extreme, or irregular, increments influence all variograms significantly — sometimes fatally. Outliers should always be deleted (perhaps sequentially). Significant outliers mask and modify the underlying true variogram to serious degrees. No variogram interpretation should be carried out before complete outlier removal has been secured. Small outliers do not influence the variogram overly — data analysts are obliged to develop the necessary experience with variography. The Special data types, here illustrated by commodity price series, carry a feature not encountered in variograms pertaining to sampling of physical systems: Significant trends in the original data series may often advantageously be pre-treated so as to correspond with the geostatistical prerequisite of Detailed interpretation of complex variogram relationships belong to the It has been shown how TOS-correct, i.e. representative 1-D process sampling forms a critical prerequisite for a reliable variographic analysis. Variogram analysis reveal a multitude of 1-D or process data structures by a set on only three, systematic parameters: the sill, the range and the nugget effect. Selected didactic examples of data series’ contexts and their manifestation in interpreting the resulting variograms were outlined, designed to illustrate the practical aspects of process sampling and estimation of the associated total sampling errors, TSE. It is possible to In the context of the popular simple time-series plotting of a plethora of current Process Analytical Technologies (PAT) parameters with direct interpretation, e.g. SPC, multivariate SPC o.a. — it has become clear that process TOS can illuminate process state, process variability (heterogeneity) and process data structures with distinctly more objective interpretation power. Process TOS forms a Process variographic analysis will always be able to decompose 0-D vs. 1-D variances. It is especially useful to be able to quantify the specific MPE associated with an existing sampling procedure or any contemplated alternative. All sampling errors are covered in the comprehensive TOS approach, including the sum total analytical error. However, not all analytical, and data analytical errors can be delineated and brought forward by process TOS. It is still necessary to be on the guard for e.g. “systematic (constant) analytical errors”, which cannot be detected by process variographics alone — but a varying systematic error will be detected, by contributing to a sampling bias, i.e. by inflating MPE. All pertinent calibration and validation issues associated with analysis It also bears mentioning that none of the traditional data analytical calibration and validation issues in chemometrics has any bearing on the issues discussed in this paper. Data analysis is the These issues have a profound bearing on the standing discussion within chemometrics of the merits VARIO was programmed by We thank two anonymous referees for the scholarly, penetrating and helpful reviews.