Over the past 15 years, artificial neural networks (ANNs) have been used increasingly for prediction and forecasting in water resources and environmental engineering. However, despite this high level of research activity, methods for developing ANN models are not yet well established. In this paper, the steps in the development of ANN models are outlined and taxonomies of approaches are introduced for each of these steps. In order to obtain a snapshot of current practice, ANN development methods are assessed based on these taxonomies for 210 journal papers that were published from 1999 to 2007 and focus on the prediction of water resource variables in river systems. The results obtained indicate that the vast majority of studies focus on flow prediction, with very few applications to water quality. Methods used for determining model inputs, appropriate data subsets and the best model structure are generally obtained in an ad-hoc fashion and require further attention. Although multilayer perceptrons are still the most popular model architecture, other model architectures are also used extensively. In relation to model calibration, gradient based methods are used almost exclusively. In conclusion, despite a significant amount of research activity on the use of ANNs for prediction and forecasting of water resources variables in river systems, little of this is focused on methodological issues. Consequently, there is still a need for the development of robust ANN model development approaches.Over the last 15 years or so, the use of artificial neural networks (ANNs) for the prediction and forecasting of water resource variables has become a well-established research area. In the early years (1992–1998), ANNs were considered a novel modelling approach and, consequently, research efforts were directed primarily towards the application of ANNs to different types of problems and case studies in order to assess their utility as an alternative modelling approach. The large amount of research activity in this area led to a number of review papers in 2000 and 2001 ( In their review, The remainder of this paper is organized as follows. In Section The articles reviewed in this paper are taken from the following international refereed journals (the numbers in brackets are the journals' 2008 ISI impact factors): Advances in Water Resources (2.235), Civil Engineering and Environmental Systems (0.425), Environmental Modelling and Software (2.659), Environmetrics (0.719), Hydrological Processes (2.002), Hydrological Sciences Journal (1.216), Hydrology and Earth System Sciences (2.167), International Journal of Water Resources Development (0.738), Journal of Environmental Engineering (1.085), Journal of Hydroinformatics (0.681), Journal of Hydrologic Engineering (1.007), Journal of Hydrology (2.305), Journal of the American Water Resources Association (1.208), Journal of Water Resources Planning and Management (1.275), Nordic Hydrology (1.194), Stochastic Environmental Research and Risk Assessment (0.951), Water Resources Management (1.350), Water Resources Research (2.398), and Water SA (0.721). These journals were chosen because they are widely recognized international journals in the fields of hydrology and surface water resources. A keyword search of the ISI Web of Science was then conducted for these journals for the period 1999–2007 using the search term “Neural Networks”, resulting in 516 articles. This list was refined manually to exclude papers focusing on rainfall, groundwater, lakes and reservoirs, parameter estimation, etc., resulting in 210 selected papers focusing on the prediction and forecasting of water quantity and quality variables in river systems. Details of the selected papers, including year of publication, authors, study location and variable predicted are given in The number of papers in which water quantity and water quality variables were predicted is given in The distribution of time steps considered is given in The main steps in the development of ANN prediction models, as well as the way the data flow through, and the outcomes achieved at, different steps, are given in The first step in the model development process presented here is the choice of appropriate model output(s) (i.e. the variable(s) to be predicted) and a set of potential model input variables from the available data. Although ANNs are data-driven models, it is up to the modeler to choose which input variables should be All ANN prediction models take the following form: Consequently, in order to develop an ANN model, the vector of model inputs ( The vector of appropriate model inputs is determined during the “Input Selection” step ( The resulting “Model Development Data” are usually divided into calibration and validation subsets. The calibration data are used to estimate the unknown model parameters (connection weights) and the validation data are used to validate the performance of the calibrated model on an independent data set. If cross-validation is used as the stopping criterion, the calibration data are divided into training and testing subsets ( Next, the functional form of the model, While the choice of an appropriate model architecture is a function of modeler preference, the optimal model structure generally needs to be determined using an iterative process. This involves selecting a network with a certain structure (e.g. number of hidden nodes, transfer functions), calibrating (training) the selected ANN model, as part of which an estimate of the vector of model parameters ( In the subsequent sections, the input selection, data division, model architecture selection, model structure selection, model calibration (training) and model evaluation stages of the ANN model development process are considered in more detail. In each sub-section, the purpose and importance of the particular step in the ANN model development process considered are introduced, followed by a taxonomy of the main options available to modelers. Next, the options selected in the 210 papers considered are reviewed in light of these taxonomies, thereby presenting a snapshot of the ANN model development approaches used from 1999 to 2007. It should be noted that this information is presented in terms of the number of times a particular method has been used in the papers reviewed. This is because some papers used multiple methods and details about some of the methods addressed were not provided in some of the papers. Consequently, the total number of times a particular method has been used in the papers reviewed can be more or fewer than the number of papers reviewed (i.e. 210). One of the most important steps in the ANN model development process is the determination of an appropriate set of inputs (X). However, this task is generally given little attention in ANN modelling and most inputs are determined on an ad-hoc basis or using The consequence of excluding one or more significant inputs is that the resulting model is not able to develop the best possible input–output relationship, given the available data. The omission of important model inputs is more likely to occur in time series applications, where the potential model inputs consist of not only different input variables, but also their lagged values (unless recurrent neural network architectures are used). This increases the number of potential model inputs (as distinct from input variables) considerably, and in many previous studies, lags have been chosen on an ad-hoc basis ( The inclusion of too many inputs is usually caused by input redundancy, where some of the selected inputs provide significant information, but are related to each other and therefore provide redundant information. This can cause a number of problems. Firstly, redundant inputs increase the likelihood of overfitting (overtraining). This is because a larger number of inputs generally increases network size, and hence the number of connection weights (i.e. model parameters) that need to be calibrated. As the number of training samples is generally fixed, the addition of redundant model inputs increases the ratio of the number of connection weights to the number of training samples, thus increasing the likelihood of overfitting, while not providing any additional information to the model. Secondly, the inclusion of redundant model inputs introduces additional local minima in the error surface in weight space. For example, if two model inputs (x A number of techniques are available for assessing the significance of the relationship between potential model inputs and output(s), as shown in Options for selecting which input combinations to try as part of Model Based approaches include an ad-hoc approach, where the model developer selects which combinations of model inputs should be tried, a stepwise approach, where inputs are systematically added (constructive) or removed (pruning), or a global approach, where a global optimization algorithm, such as a genetic algorithm, is used to select the combination of inputs that maximizes model performance. Another approach is to develop an ANN model with a relatively large number of inputs and to use sensitivity analysis to determine which inputs should be excluded. In contrast to Model Based approaches, Model Free approaches to input selection do not rely on the performance of trained ANN models for the selection of appropriate inputs. As shown in In order to overcome the problem of redundant inputs discussed earlier, Input Independence needs to be considered in addition to Input Significance. As can be seen in The second approach to account for input independence in the input selection process is filtering. The most prominent example of this is the constructive stepwise model-building process, as part of which the candidate input that has the most significant relationship with the model output(s) is selected first, followed by the candidate input that has the next biggest As illustrated in In 37 of the 72 instances where a model based input selection approach was used, this was done in an ad-hoc fashion. A stepwise model building approach was used 14 times, followed by sensitivity analysis of trained models (seven times) and use of a global search procedure (five times). Input independence was only considered in 18 of the 210 papers reviewed ( The results of the review reveal that there is a need to pay greater attention to the input selection step in the development of ANN models. The inputs selected can have a significant impact on model performance, yet ad hoc approaches to input selection (either model based or model free) were used in the majority of papers surveyed. While analytical model free approaches were also popular, almost all of these used a linear method for determining input significance, which is counter to the premise of using a non-linear model, such as an ANN, as the actual model. Consequently, there is a need to make greater use of non-linear analytical approaches to input selection. The issue of input independence was ignored in almost all of the papers reviewed, which can have significant negative impacts on model performance and the ability to extract any meaningful information about underlying physical processes from trained ANN models. Consequently, this issue requires increased attention. As part of the ANN model development process, the available data are generally divided into training, testing and validation subsets. The training set is used to estimate the unknown connection weights, the testing set is used to decide when to stop training in order to avoid overfitting and/or which network structure is optimal, and the validation set is used to assess the generalisation ability of the trained model. As ANNs, like all empirical models, perform best when they are not used to extrapolate beyond the range of the training data, all patterns that are contained in the available data need to be included in the training set. Similarly, since the test set is used to determine when to stop training and/or which network geometry is optimal, it needs to be representative of the training set and should therefore also contain all of the patterns that are present in the available data. If all of the available patterns are used to calibrate the model, then the most challenging evaluation of the generalisation ability of the model is if all of the patterns are also part of the validation set. Consequently, the training, testing and validation sets should have the same statistical properties in order to develop the best possible model, The methods for dividing the available data into appropriate subsets can be divided into supervised and unsupervised approaches ( The explicit goal of supervised data division methods is to ensure that the statistical properties of the various subsets are similar. This can be achieved by using a trial-and-error approach, as part of which manual adjustments are made to the composition of the various subsets until an arbitrarily satisfactory level of agreement between the statistical properties of the various data subsets has been reached, or by using a formal optimization approach to minimize a measure of difference between the statistical properties of the data subsets. In the papers reviewed, unsupervised data division methods were used 177 times ( Supervised data division methods were only used on 24 occasions, with an approximately equal split between trial and error and optimization based approaches for achieving similar statistical properties between the various data subsets. It should be noted that data division was not discussed in some of the papers reviewed. Even though the way the data are divided can have a significant impact on model performance, and the validity of the results presented, data division was conducted in an ad-hoc fashion on almost 150 occasions. Consequently, there is a need to pay increased attention to data division in the ANN model development process. Model (network) architecture determines the overall structure and information flow in ANN models. Consequently, it has a significant impact on the functional form of the relationship between model inputs and output(s), Traditionally, ANN architectures have been divided into feed-forward and recurrent networks ( An MLP uses three or more layers of artificial neurons with linear aggregation functions and linear and/or non-linear activation functions. The input layer neurons simply pass on the weighted inputs to the subsequent layer neurons. The possibility of using non-linear activation functions at the hidden and output layers of an MLP provide the capability of capturing the complexity and non-linearity inherent in the systems being modeled. A GRNN is capable of approximating any function using input and output data like an MLP but differs in its structure, which consists of four layers, an input layer, a pattern layer, a summation layer, and an output layer. Unlike MLPs, GRNNs do not rely on iterative procedures for their training and are based on a standard statistical technique called kernel regression. RBF networks are motivated by locally tuned biological neurons, whose response characteristics are bounded in a small range of the input stimuli. The structure of RBF networks is similar to that of the feedforward MLPs and consists of three layers, an input layer, a hidden layer, and an output layer. The major difference is that the hidden layer neurons are specified by radial basis functions and the output layer neurons necessarily use linear activation functions. The training of an RBF network is usually a two stage process in which the basis functions are established at the hidden layer in the first stage and the weights connecting hidden layer and output layer neurons are directly determined in the second stage. Neurofuzzy networks are based on an integration of neural networks and fuzzy logic. The learning capability of neural networks is exploited to design the complex fuzzy system (or generation of IF THEN rules) in a Neurofuzzy model. Neurofuzzy models offer the advantages of both fields and have provided more accurate results than a simple ANN model in many hydrological applications. Recently, SVMs have attracted the attention of some researchers. SVMs are machine learning algorithms in which the ‘empirical risk’ in terms of prediction error and structural risk associated with the model structure are minimized simultaneously. While feed-forward architectures are the most popular architectures among researchers, recurrent neural networks have also received some attention. In recurrent networks, information may propagate not only in the forward direction but also in the backward direction through feedback loops. The output layer neurons may feed back the output to input and/or hidden layer neurons. The existence of a feedback mechanism in recurrent networks makes it simpler for a neural network to model highly dynamic systems with time delays. Environmental and hydrological systems are extremely complex, non-linear, and dynamic in nature, involving a wide variety of physical variables that exhibit significant spatio-temporal variation and are often inter-related and uncertain in nature, thereby posing major challenges to the scientific community involved in modelling such systems. A single technique may not be able to capture the complex nature of environmental and hydrological systems. Consequently, a number of hybrid modelling approaches have been developed to exploit the advantages of the available modelling paradigms in order to capture the complexities involved in such systems ( In this paper, hybrid modelling frameworks that include ANN models have been divided into the following three classes (    The results obtained indicated that there has been a significant amount of activity on the development and evaluation of alternative network architectures in order to improve model performance between 1999 and 2007. While multilayer perceptrons (MLPs), which have been used traditionally in applications in hydrology and water resources ( Much effort has been directed towards the evaluation of existing ANN architectures and the development of and evaluation of new ANN architectures. The latter has been primarily in the form of hybrid ANN architectures that aim to exploit the strengths and eliminate the weaknesses of different modelling approaches. However, given the wide variety of hybrid modelling approaches and range of applications to which they have been applied, it is not possible to draw any conclusions as to which model architecture should be used in a particular circumstance. This should be the focus of future research efforts. Model (network) structure, together with model (network) architecture, defines the functional form of the relationship between model inputs and output(s), The taxonomy of methods for determining the optimal ANN structure is shown in Alternatively, a stepwise trial and error procedure can be used ( Other approaches to determining an appropriate network structure, such as using a trial-and-error approach to determining the optimal number of hidden nodes, rather than a strict constructive or pruning approach, or selecting a network structure based on experience and/or intuition, have been classified as ad-hoc. As can be seen in Despite the important role network structure plays in determining the desired relationship between model inputs and outputs, little effort has been directed into this area of the ANN model development process, with most studies adopting an ad-hoc approach to determining an appropriate network structure. There has been reasonable adoption of constructive, stepwise model building approaches, but the use of global optimization methods has received little attention. In order to ensure that the best possible ANN models are being developed, this step in the model development process requires further attention. The aim of model calibration (ANN training) is to find a set of model parameters (e.g. connection weights) that enables a model with a given functional form to best represent the desired input/output relationship. If overfitting is not considered to be a problem and the training data are representative of the modelling domain, this is achieved when a suitable error measure between actual and predicted training outputs is minimised. If overfitting is a possibility, optimal generalisation ability is achieved when a suitable error measure between actual and predicted outputs in the test set is minimised, provided that training and testing data are representative of the modelling domain. Determination of the combination of model parameter values (i.e. weights) that minimises the training or testing error is not a simple problem. As each combination of parameter values generally results in a different model error, an error surface exists in parameter (i.e. weight) space. This is illustrated for a model with a single parameter in Due to the difficulty of the ANN calibration problem outlined above, ANN calibration is generally conducted using a suitable optimization algorithm. The vast majority of these approaches are deterministic, in the sense that they attempt to identify a single parameter vector that minimises an error measure between predicted model outputs and their corresponding measured values for the training set. These methods generally belong to either local or global optimization approaches ( In order to account for parameter uncertainty during the calibration process, stochastic calibration methods can be used. These approaches can be used to obtain distributions of the model parameters, rather than finding a single parameter vector. This has the advantage that prediction limits can be obtained. In order to achieve this, Bayesian methods are commonly used. The results in In the majority of studies, first-order local search procedures, such as the backpropagation algorithm, were used, although second order methods were also used extensively in order to improve the computational efficiency of ANN calibration. However, there was little work on investigating the potential benefits of using global optimization techniques in terms of improving the predictive ability of ANN models, which is an area worthy of further exploration. In addition, although some work was done on the incorporation of parameter uncertainty into ANN model calibration, this also presents an area of future research. In order to determine which network structure is optimal, the performance of a calibrated model is evaluated against one or more criteria. This also applies to determining the optimal set of model inputs, if a model based input selection approach is used. As discussed previously, if overfitting is not considered to be a problem, model performance is assessed using the training data, whereas the test data are used for this purpose if overfitting is a concern. ANN model performance is usually assessed using a quantitative error metric. A taxonomy of the commonly used metrics is given in Information criteria, such as the Akaike information criterion (AIC) and Bayesian information criterion (BIC) consider model complexity in addition to model error. Consequently, they have the potential to result in more parsimonious models. In addition to the metrics mentioned above, there are a number of other statistics than can be used in order to evaluate model performance. An example of this are threshold statistics (TS), which are capable of providing the distribution of the number of data points predicted from an ANN model having various levels of absolute relative error (ARE). In addition, the performance of ANN models can also be based on the accuracy of predicting particular time series (e.g. hydrograph) characteristics, such as errors in estimating peak flow, timing of the peak and total volume. The results obtained indicate that a range of performance criteria were used in most studies ( Review of the 210 papers has indicated that a range of performance criteria was used in most of the studies. This increases confidence in the evaluation of the performance of the models developed, as different performance criteria generally emphasize different aspects of predictive performance. However, increased use of information criteria, such as the AIC and BIC, could be beneficial in an effort to balance predictive performance with model parsimony. Since the period 1992–1998, which is the subject of the review paper by As was the case from 1992 to 1998, the primary application area has been flow forecasting and prediction. Very few papers have focused on other water quantity variables and even fewer have considered water quality. If anything, the emphasis on flow modelling has increased in recent years, rather than diminished. Consequently, there is a need to broaden the application area of ANN models to focus on other predictive variables, especially those concerned with water quality. Given the universal function approximation capability of ANNs, they would seem to be ideally suited to modelling the complex relationships that are a feature of water quality processes. However, one factor limiting the application of ANNs in the water quality modelling arena might be the lack of good quality, long term data. The adoption of appropriate input determination approaches was an area identified as deficient by Another aspect of input selection that has received even less attention is the issue of input independence. While models with redundant inputs might perform well from the perspective of being able to obtain a good match to the calibration data, they increase model complexity and parameter uncertainty. As a result, this issue needs to receive increased attention in order to reduce the uncertainty surrounding ANN model outputs and to enable research into knowledge extraction from ANNs to proceed with increased confidence.  In relation to model architecture, there was a significant amount of research activity in the nine years covered by this review. The way in which optimal model structures are obtained is an area that has received little attention in the papers that form part of this review. As was the case in the findings of There was also little activity in relation to model calibration during the time period considered for this paper. As was the case from 1992 to 1998, first order local optimization methods were by far the most common, although an increasing number of second order local methods were used in the papers published between 1999 and 2007. However, surprisingly, there was little adoption of global optimization methods, which have been found to outperform more traditional methods when used in conjunction with other water resource modelling approaches in recent years. It was good to see that some effort was devoted towards the development of Bayesian and other stochastic approaches to model calibration in order to enable parameter uncertainty to be taken into account and to enable confidence limits on predictions to be obtained, but there is a need to expand this work into the future. In the majority of papers reviewed, different methods were used to evaluate model performance, which is considered good practice. However, there is scope for improving the way models are evaluated by applying the various measures in a consistent and informed manner (see Based on the review of 210 papers on the prediction and forecasting of water quantity and quality variables in rivers conducted in this paper, the following recommendations for future work are made: More work needs to be undertaken on the prediction of water quality variables (e.g. Work should continue on the development and evaluation of hybrid model architectures that attempt to draw on the strengths of alternative modelling approaches (e.g. Greater attention should be paid to the input variable selection and data division steps of the ANN model development process. Currently adopted ad-hoc methods in both of these areas have the potential to significantly degrade model performance and therefore need to be replaced with state-of-the art approaches. In relation to input variable selection, non-linear approaches that are able to account for input independence should be used (e.g. There has been increasing adoption of second order local methods for model calibration, but the use of global optimization methods is still limited. Consequently, there is scope for comparative studies investigating the relative performance of various global and local optimization algorithms in the context of ANN model calibration (training). Research into the best way to incorporate uncertainty into ANN models should be continued. Current work on the incorporation of parameter uncertainty via Bayesian and other stochastic calibration methods should be extended to include other types of uncertainty (e.g. Appropriate methods for determining the optimal ANN model structure remain elusive. Although some work has been done on this recently (e.g. The authors would like to thank Tim Rowan and Gayani Fernando for their assistance in obtaining the papers that form the basis of this review, Rob May for his initial work on the flowchart depicting the steps in the ANN model development process and the eight anonymous reviewers of this paper, whose thoughtful and insightful comments have improved the quality of this paper.