Diagnostic sampling, or surveying, of operating concentrators – with a view towards identifying flowsheet improvement opportunity – has long been a valuable field of endeavour, but has seen little publication. A quantitative protocol entitled Statistical Benchmark Surveying has been developed at Falconbridge, and was tested at the Raglan mine in Northern Québec. Several prototypes were tested, leading to this current proposal. It is shown that the field of applied statistics brings value to this approach by using the appropriate distribution models. Replicate two-hour survey units are taken. This engages the powerful averaging effects of the Central Limit Theorem. The effects of auto-correlation in time are broken by spacing the surveys with knowledge of the semivariogram. This importantly moves the sampling from auto-correlated to random. Use is made of the paymetal grade measurements (in this case nickel) to construct a system of reference distributions. This recognizes the dominant influence of ore grade in concentrator performance. Outlier rejection from the set of six replicate two-hour surveys is proposed by these reference distributions, which are designed to operate at the 95% confidence level. A composite is prepared from those surveys which pass these tests. As a result, this flotation feed composite has a mean paymetal grade close to that typically experienced at the operation. The flotation feed and associated suite of flowsheet composites are used for a mass and value balance, and are later presented to Qem∗SCAN for quantitative mineral measurement as a series of sized fractions.Of the three generally accepted steps from ore to pure metal, milling represents by far the most significant loss of pay metal for sulphide ores ( What little published literature is available was written by an Australian group of authors ( Commonly a flowsheet is functionally described, showing the logical flow of streams in sequence. A list of streams to be sampled is prepared. A team samples the plant during its normal operation according to the list of specified samples. The sampled streams are often also checked for solids and water flow as necessary inputs to mass balancing. After dewatering, the samples are used for various purposes such as overall chemical analysis, or size-by-size analysis. The duration of such survey sampling varies. Commonly a survey samples the plant operation across a few hours. One of the earlier references to this approach described an audit of the Broken Hill South concentrator, Australia ( The general rules emanating from this work were: construction of the actual flowsheet by physical inspection during the planning phase of the survey, a survey duration of at least four times the residence time of the process, no shift change at the time of the survey, a total number of ‘cuts’ for any stream between 20 and 50 to reduce the effect of any faulty cut, restricting, stopping or diverting all minor or continuous flows such as floor washings (‘spillage’), selection of personnel for the sampling with adequate and relevant training and expertise, diligent attention paid to the integrity and labelling of each sample bucket, including the recording of net mass before sampling, appropriate design and use of sample cutters ( The author correctly concluded that care and attention to detail in the preparation and execution of a sampling campaign is essential to the attainment of accurate and significant data. An example of diagnostic metallurgy based on a plant survey system for the Mount Lyell concentrator, Australia, was reported in 1977. This approach used a five-hour survey consisting of sample cuts every 30 In the analysis of a tin concentrator using a method comparable to that of Restarick, whose inputs to the plant survey design were acknowledged, it was shown that useful and robust mathematical models of the tin behaviour across the shaking table could be developed, correctly diagnosing the basic cause of poor tin recovery ( The role of quality control, and fundamental statistical analysis in achieving the ‘clear and unambiguous conclusions’ from these foregoing four surveys was not mentioned or used. Neither did these publications fundamentally address the issue of calculating the minimum sample mass required for any given stream from a suitably-designed sampling experiment. It appears that although the approaches were basically correct, they were heuristic, and probably exceeded Gy’s minimum sample mass model requirements – which is in one’s favour ( It is concluded from this review of past concentrator survey practice that: The aim of all four attempts was to establish a reliable surveying method. These were all in the period 1971–1984, and produced heuristic rule-based structures without quality control diagnostics. The common features between these four methods include the survey duration, the number of cuts, and the consistent approach of size-by-size classification and analysis of the samples. The only statistical test of the reliability of the data is the mass balancing exercise itself. This is a necessary element of representativity, but not a sufficient one: at no time is it verified that the feed is representative of typical mill feed. Earlier published work leads to the conclusion that the grade of ore milled, expressed as the percentage concentration of paymetal(s) in Rougher Float Feed for example, has a dominant effect on the metallurgical behaviour of the flotation circuit. A brief review of this work follows. The problem of controlling mill feed grade for a gold mine was solved by This work aimed at the provision of a timely measurement of daily gold input to the ‘reduction works’, or concentrator, so as to ensure daily production of refined gold within a desired range of targets. This valuable piece of work by Krige provided three key findings: That the (spatial) lognormal distribution of paymetal grades in ore mined was applicable in the time dimension as ore milled. The control limits so established at the mill, in terms of ‘ore milled’, were asymmetrical about the mean. That the 95% level of confidence was recommended in this application. The position of the Internal Reference Distribution in the  That the ore milled metal grade data were normally-distributed. That each data point is a random independent sample of the population of experimental outcomes for those conditions. That the two sample variances (i.e., of the ‘on’ or ‘off’ conditions) are estimates of the same population variance. The confidence limit was then either added to or subtracted from the mean difference in recovery to find the upper and lower confidence limits of the mean difference. It will be shown at a later stage of this manuscript that the first assumption of Napier-Munn, The spacing of the six two-hour survey units must respect two associated issues. One, the semivariogram defines the area of influence and the survey units must be taken as least as far apart as the minimum time needed to be outside that area of influence. Two, the area of influence contains auto-correlated data. Sampling whilst data are auto-correlated breaks an important statistical rule of independence. The review of the semivariogram is outside the scope of this paper, sufficient to indicate at this level that Matheron’s spherical model is used ( The residual effects of lognormality in concentrator data were reported by Project economics and the complex nature of remaining mineral resources have driven a developing focus on mineralogy, ore textures, and processing implications of an ore deposit. The requirement to achieve optimized operations startups – a key metric – faces increasing difficulty for this reason. The hybrid discipline known as Process Mineralogy is the product of this focus, and encompasses mineral processing, geology, and mineralogy. This has been progressed at Falconbridge by the further addition of a statistical and sampling focus in the Process Mineralogy Group ( Qem∗SCAN produces highly accurate mineral identification and automated measurements; however it can only describe the mineralogy of what is contained in that polished section. The very small sample mass contained in a polished section in comparison to the large tonnages of ore from which the samples were taken, define the sampling problem. What separates the sample from the specimen is a developing chain of quantitative sampling evidence from the flowsheet stream to that polished section. Obviously the use of various sizes of spinning rifflers along with Gy’s Safety Line and Minimum Sample Mass models ( In answer to the above challenge, an initial survey model was developed and used in Falconbridge ( The specific objectives of this paper are to rework a previous survey of the Raglan Concentrator, 1998, using the improved surveying model called Statistical Benchmark Surveying ( The following experimental method describes the improved surveying model called A period of two weeks is chosen in advance for which the survey is to be performed. The actual flowsheet is verified beforehand by physical inspection. Key operating parameters such as mill feed rate, reagent suite and dosage are frozen. A semivariogram is constructed from a download of Process Information (PI) data of the selected plant circuit. The sampling interval is 15 A continuous block of three months of Rougher Float Feed data is arranged to surround the survey week. Nickel grades are pooled into the External Reference Distribution at a shift frequency level, i.e., two measurements per day. These data are transformed into Naperian log values. The sample mean and standard deviation are calculated. Finally, the upper and lower limits at the 2.5% and 97.5% tail areas are calculated (in keeping with A total of six two-hour replicate survey units are performed across the survey week. Within each unit, a total of 16 cuts are taken of each flowsheet stream surveyed. Should a piece of operating equipment, such as a mill, trip out unexepectedly during the survey unit, that survey unit is disqualified. Obviously, floor washings, or spillage, are not returned into the flotation process at this time. These survey units are spaced by at least 24 It is a standard practice that treatment and process conditions have been defined and quantified, and that during each two-hour survey unit these treatments and processes operate within their typical limits. An important point should be made concerning the number of cuts taken during the two-hour survey unit. The standard error of the mean grade of that survey unit is an inverse function of the number of cuts. Assuming for simplicity that there is no auto-correlation in the errors, an exercise follows on the basis of the sampling standard deviation and standard error. To illustrate, taking the sampling standard deviation at an arbitrary 100%, the number of cuts in the two-hour survey unit affect the standard error Often each technician has to handle several different sampling points. It is possible to perform cuts at a 10-min interval. This would provide 12 cuts per survey, and would reduce the standard error to 100/(12) Generally six replicate two-hour survey units are conducted across a 7–14-day period of operations. This provides for the separation of each two-hour survey unit by at least one day in order for basic sample management to be addressed. This also allows for a separation of each survey unit into a random-stratified arrangement, which is likely to break or minimise the effects of auto-correlation in time. Random stratification is a non-punctual sampling arrangement which satisfies both the need for sample increments (surveys) to be taken outside the area of influence (wherein auto-correlation resides), as well as varying the timing thereof. On occasion, new staff who have insufficient experience in this matter and do not readily appreciate the subject of random stratification, sometimes take an opportunistic extra survey on a back-to-back basis from the previous survey unit when operating conditions are steady, in the belief that they are being cost-efficient. This practice is of no value. Instead, it will produce extra survey unit(s) with Rougher Flotation Feed grades that are unlikely to add as much information as the other surveys, thus negating the perceived benefits of ‘finishing up the surveys in as short a time as possible’. This in part amounts to the importance of both training and experience in the subject. The sample material from each two-hourly survey unit is separately stored. The Internal Reference Distribution is constructed from the nickel grades obtained from the six Rougher Float Feed samples. In this case, Sichel’s It is most desirable that the mean values of the External and Internal Reference Distributions agree closely. In that way, one may be assured that the survey composite that will be prepared will have been drawn form a grade of ore that is typical of operations at that time. Furthermore, it is measurable proof of representative sampling since the two distributions are independent of each other. Beyond this subjective intent, quantitative statistical measurements must be made to adjudicate how closely these two numbers should agree. Two stages of quality control now follow, and will by their design estimate the 95% confidence intervals within which any observations will be acceptable. Each of the six feed grades of the survey units is inspected using the Sichel confidence limits abovementioned. Any grade falling outside these limits is disqualified along with the associated suite of survey samples. The shortened data set is now recalculated. It is understood and accepted that this practice runs the risk of rejecting true observations which do belong to the data set, however with six survey units there is sufficient redundancy. There is no other known distribution model which readily applies to both the residually lognormal distribution and at such a small data set size. The individual data points of the shortened Internal Reference Distribution are now inspected using the External Reference Distribution. The confidence limits in this case are the equivalent of two sample standard deviations. Any data point falling outside these limits is disqualified along with the associated suite of survey samples. Those individual survey units whose feed grades have complied with the above two criteria are accepted into the final composite, along with the associated suite of flowsheet samples. The composite is presently prepared on an equal-mass increment basis. The Raglan concentrator operations, situated in the Ungava province of northern Québec, were used for testing various prototypes of this survey model. In this paper, the first survey, taken in June 1998 shortly after the project commissioning, will be used as a case study. The full details of how this surveying model were developed and improved are available elsewhere ( Measurements of nickel in Raglan Rougher Float Feed exist at the 15-min level. The method of measurement is by X-Ray Fluorescence (XRF) in the Courier system. The data extract was from 12h00 on the 1st June to 05h00 on the 2nd June 1998. A total of 69 data points resulted from this extract. All data within this extract were used. Inspection of the semivariogram in It should be noted that, in reworking a previous case study such as the Raglan Survey of June 1998, the implications of separating the two-hour survey unit in time with the knowledge of the semivariogram cannot be fully implemented because the survey occurs in the past tense. More recent surveys in Falconbridge which have been fully designed with the new survey model – and with the semivariogram – show that this feature has a significant impact on reducing the differences between reference distribution means ( A three-month External Reference Distribution of Raglan Rougher Float Feed was extracted from the operational records. The May–July 1998 Raglan Rougher Float Feed nickel data ( Although the original data from the 1998 survey were not produced from the new surveying model, but were obtained from the earlier Falconbridge heuristic prototype, they can be used to demonstrate the new benchmark surveying model. The following set of two-hour survey units was recorded. Sichel’s The conversion by Inspection of the raw data in The quality control protocols have thus moved the raw survey data set from a mean grade of 2.96% Ni–3.13% Ni. Comparison with the External Reference Distribution mean of 3.27% Ni indicates a sampling error of (3.27–3.13) The original outcome of the Raglan 1998 survey used the Falconbridge prototype. Using the same survey measurements as shown in The measurements of this distribution are: sample mean 3.13% Ni, sample standard deviation 0.344% Ni, observations 53. Acceptance limits are thus 3.82% and 2.44% Ni. Inspection of the Internal Reference Distribution, i.e., the individual surveys, shows that all six surveys are accepted at the second stage of adjudication. Therefore, all six surveys are accepted into the composite. A difference in reference distribution means of (2.96–3.13) This paper has attempted to summarise the essential features of the surveying model now in use at Falconbridge. The following conclusions have been drawn: The use of the lognormal platform produces appropriate description and quality control of the Rougher Float Feed grades. The two lognormal models, i.e., of Krige and Sichel, have produced entirely consistent outcomes in adjudication of the Internal Reference Distribution. Separation of the six two-hour survey units with knowledge of the semivariogram is key to breaking the auto-correlation effects in the paymetal grade of ore milled. However, this could not be fully tested in this case study for the reasons enumerated. The accepted survey composite mean grade agrees to within 3.69% of the independent External Reference Distribution mean. Had the quality controls of the reference distributions not been applied, and all six samples used, the difference would have been 8.92%. Comparison of this outcome to that of the original prototype model shows that the error has been reduced from 5.4% to 3.7%. Norman Lotter would like to thank the management of Falconbridge Limited for permission to publish this work. Dr. Michael G. King, Director of Metallurgical Technology, Falconbridge Limited, very kindly sponsored this study and provided much encouragement to the author to develop this model. Associate-Professor André Laplante, who supervised this thesis, provided exemplary guidance during the study but most unfortunately passed away very suddenly on the 5th March 2006. His searching questions and interesting discussions stand out from the detail. He will be well-remembered and is sorely missed. Dr. Dee Bradshaw, University of Cape Town, and Prof. Jim Finch, McGill University, have subsequently made many helpful suggestions in the editing of this manuscript in 2006.