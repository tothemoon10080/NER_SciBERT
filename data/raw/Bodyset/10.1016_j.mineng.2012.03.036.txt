Grade-recovery curves obtained from kinetic batch flotation testing are, like any other measurement, subject to experimental error. This leads to uncertainty in the true position of each cumulative grade-recovery point, the curve itself, and the kinetics. This uncertainty is rarely if ever taken into account when interpreting such curves, in particular when comparing curves obtained under different conditions. This paper proposes a methodology to deal with this problem.
                  The standard formula is used to establish true confidence intervals for the grade and recovery at each replicated timed concentrate point, and the 2-sample t-test is used to compare these point values between tests conducted under different conditions. The properties of the grade-recovery curves can be compared by fitting an appropriate model to the two data sets and using a bootstrap to create distributions of differences between the model parameters and the model predictions of recovery at any chosen concentrate grade, reflecting the uncertainty in the original data. It is then easy to construct hypothesis tests on the parameter differences and on the mean difference at the chosen grade(s) between the two curves. The same approach can be used to construct confidence intervals on the fitted curves and to test differences in estimated flotation rates. An extra sum of squares test can be used to compare the fitted grade-recovery curves as a whole. Details of the methods are presented, suitable for spreadsheets.
                  These methods are relatively easy to apply but require that all batch flotation tests be replicated. The alternative (single tests under each condition) ignores the existence of experimental error and renders the data susceptible to subjective and perhaps erroneous interpretation. Using these methods it is not unusual to find that grade-recovery curves thought to represent truly different flotation performance are not in fact statistically different, especially at the longer flotation times (high recoveries).Batch flotation testing is widely used to assess the flotation response of ores under particular conditions. The test usually comprises some standard procedure for grinding the ore and floating it in a batch cell. Sequential timed concentrates are taken to allow a cumulative concentrate grade-recovery curve to be constructed. This curve contains much useful information including the trade-off between grade and recovery and the kinetic characteristics implied in the shape and location of the curve. Batch flotation testing is described by Grade-recovery curves are used for many purposes. For example, in future ores testing on a mine site it is common practice to compare the flotation response of future ores to the currently treated material to determine whether the grind or flotation conditions will need to be changed. In testing new reagents or grinding media it is necessary to compare the flotation response of the new condition with the standard or current alternative to determine whether there has been an improvement. Mineral engineers seek to move the whole curve to a higher grade-recovery position through modifications to conditions. The ultimate theoretical curve is that prescribed by the liberation characteristics of the ore (  It is almost inevitable in such testing that grade-recovery curves will be compared in some way. Comparisons are usually made by eye with no reference to the inevitable experimental uncertainties inherent in the construction of the curve. Curves are implicitly deemed to be truly different, and elaborate explanations are then concocted for the observed difference, especially where the nature of the difference coincides with the natural prejudices of the experimenter. In this case it seems that Test B demonstrates a superior performance, with higher recoveries for a given concentrate grade over most of the range, though the curves appear to converge at the final concentrate where recovery is around 88%. In fact, as will be shown, many such comparisons are invalid because there is no statistically significant difference between the curves, over all or some of the range. This is due to the inherent uncertainties in the position of the curve due to the malign though inevitable influence of experimental error. This error arises from many sources, including sampling ( Two questions then arise: How can we report the uncertainty in the grade-recovery curve? How can we compare two such curves to determine if they are truly different? This paper suggests that point-by-point uncertainty is best expressed by the standard formula for a confidence interval. Grade-recovery points at the same flotation time can be compared statistically using the t-test. The significance of the difference in recovery at any given concentrate grade between two tests conducted under difference conditions can be determined by constructing a hypothesis test around the values predicted by a model fitted to the data many times using bootstrapping. A similar approach can be used to compare model parameters including rate constants, and to construct confidence intervals around the full curves. These methods require that batch flotation testing be replicated in order to measure experimental error. Some enlightened organisations already do this routinely, though these are the exceptions and one might also argue that the best use is not yet being made of the extra information in the replicates. Most however do not. This paper presents methods to allow statistically valid decisions to be made when comparing data from different batch flotation tests. The tests shown in Because the tests were replicated, confidence intervals can be calculated separately for each timed mean grade and recovery. The formula for the confidence interval, CI, is the usual one: The t-value can be obtained from a table of the t-distribution or from the Excel function =TINV( Eq. It is clear that there is considerable uncertainty at each point, in both ER and recovery. This is a product of the relatively high standard deviations, and the low value of Thus if we wished to determine the mean recovery at a particular time to ±2% with 90% confidence and the standard deviation of recovery under these conditions was known to be 2%, then three replicates would be sufficient ( The question now arises as to whether the mean ER and the mean recovery at a given flotation time are the same for the two collectors. This question can be asked and answered for each flotation time separately, because the replicated cumulative grade and recovery estimates at each time can be considered as an independent sample of the population of cumulative grades and recoveries at that time. The question cannot be asked simultaneously for all the flotation times (ie for the whole curve) because the error model for the cumulative curve is not known. This problem is discussed further below. Some indication can be obtained by inspecting the confidence intervals at the points to be compared (e.g. The P-values and corresponding confidence levels suggest that at Con.1 there is no difference in ER but the recovery with collector B is significantly higher than that with collector A (about 6%). At the final concentrate, there is some evidence for a higher ER with collector B but there is no difference in recovery. Similar conclusions hold for the intermediate concentrates (not shown), with no difference in recovery but P-values of 0.063 and 0.075 for the difference in ER for concentrates 2 and 3 respectively. These conclusions are not unexpected in the light of the confidence intervals shown in The comparison of grade-recovery points at a particular flotation time is valid only for that time. Its conclusion is independent of all other parts of the curve. A problem arises in considering particular points in the context of other points on the curve. To what do we attribute differences between points at a particular time? It may be that any significant difference truly reflects an improvement in flotation conditions with the new collector. However the difference may be due to other factors, and the two points, though apparently different, may in fact be on the same grade-recovery curve. This can only be tested by considering the curves as a whole. Equally we may want to test the differences in rate constants which requires a rate model to be fitted to the kinetic data. A rigorous comparison of two full grade-recovery curves is a different matter to comparing the grade or recovery at the same timed points. There are various ways to do this but some are complicated by the fact that the curves are cumulated, meaning that the results for each time are not independent and the error model is unclear. In addition, the approach will depend on what the user wishes to achieve with the comparison. As examples we shall consider four useful possibilities: Comparing the parameters of the first order rate models for the timed data. Comparing the parameters of models fitted to the grade-recovery data. Comparing predicted recovery at selected values of ER (or concentrate grade). This is equivalent to generalising the comparisons we made at the experimental flotation times, for which we used the t-test. Comparison of the two fitted grade-recovery curves as a whole. We first fit an appropriate model to the data by the usual method of least squares, in this case using Excel’s Solver routine. We then generate a large number of parameter estimates by bootstrapping, that is by fitting the model many times (say 1000 times) to the original model predictions perturbed by random noise reflecting the inherent uncertainty in these predictions. Because the tests were replicated, this uncertainty will reflect the real experimental error in the data. We will then have 1000 values of the quantities we are interested in, such as rate constant or the recovery at ER This strategy requires calling Solver 1000 times. Each time, normally distributed random numbers with mean zero and standard deviation equal to the standard error of the original model fit are added to the original model predictions. These form the new ‘data’ for Solver to use to fit the model. To perform this task we use the Excel add-in MCSimSolver ( It can repeatedly call Solver to perform the same fit, a defined number of times (e.g. 1000). It can store the resulting 1000 values of quantities that we choose to define, such as the model parameters and predictions. It includes a non-volatile random number generator called RANDOMNV() which is needed because once the set of random numbers is generated for a given fit we need to leave Solver to iterate to a solution; if we used a standard volatile Excel function such as RAND() then the values of recovery would change for each iteration and Solver would fail. It is often helpful to compare directly the kinetic parameters of the two separations. The four times at which concentrates were taken in Tests A and B were 1, 3, 6 and 11  The difference in the values of  Column A contains the triply replicated concentrate times, and Column B the corresponding experimental recoveries. Column C contains the recoveries predicted by the original fit of the rate model with the parameters shown in MCSimSolver can be set up to run any number of simulations (1000 is the default), and to record any cell selected in the worksheet. In this case cells H1 and H2 are selected because we wish to interrogate the distribution of the two model parameters. The output is 1000 values of The question we want to answer concerns the differences in model parameters between Tests A and B. We therefore construct 1000 differences between the values of the two parameters in Tests A and B and inspect the properties of these differences, as shown in The upper and lower 95% confidence limits are calculated simply as the 0.025 and 0.975 percentiles of the 1000 values of the differences, using Excel’s As we are searching for an improvement in the performance of Test B over that of Test A it is a 1-sided test. Clearly there is no significant difference in the values of We can obtain a visual impression of these hypothesis tests by inspecting the distribution of bootstrapped parameter differences as histograms, shown in 26% of the distribution of We can apply exactly the same tools to comparing the grade-recovery curves as we did to comparing the rate curves in Section   This formulation has two advantages. The parameters  The question ‘are the curves different?’ has several possible interpretations. Two important ones are: ‘are the parameters different?’ (as in the case of the rate curve) and ‘are the predicted recoveries at chosen values of ER different?’. This last question generalises the comparison of recoveries at the specific cumulative concentrates that we dealt with in Section Both these questions can be solved using the methods of Section We will also construct 95% confidence intervals for the fitted curves. This requires a column of ER values covering the range of interest in short intervals and a column of corresponding predicted recoveries from the current fit of the model. By selecting the column of recoveries prior to invoking MCSimSolver we will obtain 1000 estimates of recovery at each selected ER, from which we can extract the 95% confidence limits simply by computing the 2.5% and 97.5% percentiles. These can then be plotted as a smooth line on the grade-recovery graph.  The comparisons are instructive. None of the three parameters are statistically different between the two tests (1-sided  We have learned a lot about the contrasts in these two curves and their predictions. However we have not yet unequivocally answered the global question: are the curves different? One way to do this is by applying the ‘extra sums of squares’ principle. This compares the total sum of squares for the separate fits of the two data sets with that obtained by fitting the same model to the combined data set (a so-called global fit). The null hypothesis is that there is no significant reduction in the sum of squares using two fits compared to the global fit. The alternative hypothesis is that there is a significant reduction in sum of squares, and that the data are better represented by separate fits, which implies that the fitted curves are indeed different. The hypothesis is evaluated with an F-test. The calculations are quite simple and are shown in The global fit has only 3 parameters whereas the fit to the two separate data sets has 6, 3 for each model. The degrees of freedom are the number of data sets minus the number of parameters. The sums of squares are calculated in the course of using Solver, and are as defined in Eq. Let us first summarise what we have learned about these particular data in Sections There is a statistically significant difference in the Tests A and B rate constants. The magnitude of the difference is 0.47 The values of The three Bruey parameters, The difference in predicted recovery at an ER of 17 is 1.6%. The significance of this difference is equivocal, reaching significance at 90% confidence but not 95%. The difference in predicted recovery at an ER of 25 is 6.3%, which is highly significant. A better fit is obtained by fitting the model separately to the two data sets rather than globally to the combined data set. This implies that the two grade-recovery curves are really different overall. This particular data set illustrates well the need for careful interpretation of the question ‘are they different?’ It depends on what we mean by ‘different’ and the answers must be interpreted accordingly. For some data sets all the answers are clearly ‘no’ and for others ‘yes’. In this case, which is not at all unusual, it depends on how the question is formulated. This does not detract from the utility of the process. It simply reminds us, if we needed reminding, that these curves contain a lot of information, and are subject to the usual experimental uncertainties. Rate constants tell us different things from grade-recovery relationships, and the latter may themselves differ over the range of the data. Asking whether the parameters are different is a different question from asking if the curves as a whole are different. A systematic assessment of the differences between two batch flotation data sets, using the tools suggested in this paper, can give rigorous conclusions of value to the experimenter. The present grade-recovery example has recovery plotted on the Likewise there is no absolute need to use enrichment ratio rather than concentrate grade. It has been found however that ER is often more meaningful because it is normalised to feed grade which may vary even in closely controlled laboratory experiments. In plant data ER is often necessary to reproduce the conventional shape of a grade-recovery curve which is not possible using concentrate grade alone because of uncontrolled variations in feed grade. The example given in this paper uses an unweighted least squares criterion for fitting models. It is also possible to apply weighted least squares, using for example the variances of the actual grade (ER) and recovery measurements at each time as the inverse weights for each time, if these are known. The proposed bootstrap solution can be used to compare any replicated data sets for which appropriate models are available, including other forms of flotation performance curves from batch tests, pilot tests or production data, separability curves in general, and the comparison of the linear recovery-feed grade relationships in plant trials discussed by It makes no assumptions regarding the linearity of the data. It is distribution-free, that is, it makes no assumptions as to the distribution of the original data. It only assumes that the random errors are normally distributed. It does not require that the two fitted grade-recovery models give parallel curves. When they are not parallel then several comparisons may be necessary at different values of ER. The bootstrap comparison method does depend on the assumption that the model forms chosen to represent the data, whether kinetic or grade-recovery, are correct in the sense that any lack of fit is attributable only to experimental error and not functional form. The use of 1000 repetitions is a compromise between the desired precision of estimate (10,000 might be a better number) and the time required for the bootstrap. The Bruey 3-parameter model took about 3 Grade-recovery curves, like any other empirical measurement, are subject to experimental error. In order to ensure that informed conclusions are drawn from inspection of these curves, this error should be embraced and managed. Standard statistical procedures such as confidence intervals and hypothesis tests can be used to calculate the uncertainty in each mean grade-recovery point and to compare such points. A new bootstrap method has been introduced to compare the kinetic curves in terms of rate parameters, and the full grade-recovery curves in terms of model parameters and recoveries at any selected values of enrichment ratio. This involves repeatedly fitting a model to each data set perturbed by random errors with standard deviation equal to the original model fit standard error, to generate a distribution of model parameters. These are then used to generate many estimates of the quantities of interest (parameters and predictions) and thus many estimates of the difference in those quantities between two data sets. These differences have statistical properties which correctly reflect the uncertainties in the original data. The distribution of differences is used to perform non-parametric hypothesis tests of the significance of the observed mean difference and to calculate confidence intervals on the differences. Confidence intervals on the fitted curves can be computed in a similar way. These procedures are relatively easy to implement in a spreadsheet. No-one wants to be told to do three or four (or more) tests where historically one would have been regarded as the norm. However replicate testing is essential if these methods are to be utilised. The alternative is to ignore the inevitable presence of experimental error and perhaps draw misleading or erroneous conclusions from the data. It is therefore recommended that all batch flotation tests be replicated and that confidence intervals be reported such as those in The fact that the two grade-recovery curves shown in The author’s interest in this problem arose out of stimulating discussions with Dr. Neville Plint of Anglo Platinum, Deryck de Vaux of Anglo Research, Prof. Dee Bradshaw of the JKMRC, Dr. Chris Greet of Magotteaux Australia and Dr. Frank Bruey of Cytec. He thanks Dr. Bruey for permission to quote his re-parameterisation of Vera’s function. He also acknowledges helpful discussions with Prof. Bill Whiten of the JKMRC. Dr. Rob Morrison of the JKMRC kindly read an early version of paper and made useful suggestions. Some of the ideas in the paper were first presented at the SAIMM Minerals Processing 09 conference in Cape Town in August 2009.