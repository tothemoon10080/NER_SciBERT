The authors describe a Fortran-90 program for empirical maximum likelihood kriging. More efficient estimates are obtained by solving the estimation problem in the ‘Gaussian domain’ (i.e., using the normal scores of the experimental data), where the simple kriging estimate is equivalent to the maximum likelihood estimate and to the conditional expectation. The transform to normality is done using the empirical cumulative probability distribution function. A Bayesian approach is adopted to ensure a conditionally unbiased estimate, which is obtained as the mean of the posterior distribution. The posterior distribution also provides a complete specification of the probability of the variable and thus provides the basis for a more realistic evaluation of uncertainty by various methods: inverting Gaussian confidence intervals, confidence intervals measured from the posterior distribution, variance measured from the posterior distribution or intervals obtained using the likelihood ratio statistic. A detailed case study is used to demonstrate the use of the program.Linear kriging (simple kriging, ordinary kriging and universal kriging) is a well-known spatial estimator of point and integral values that provides unbiased estimates with minimum estimation variance. One advantage of linear kriging is that, as it makes no distributional assumptions, it is a distribution-free estimator. The corresponding disadvantage is that it delivers only an estimate and the associated estimation variance. This is of no consequence when the experimental data follow a multivariate Gaussian distribution because the kriging estimator then coincides with the conditional expectation, which is the most efficient estimator available (linear or otherwise) For a specified probability distribution a functional transform of the data can be used and it is then possible, in principle, to determine the back-transform of the Gaussian estimates that yields conditionally unbiased estimates in the original domain. For the lognormal distribution, for example, conditionally unbiased estimates are obtained by using the back-transformation: Conditional unbiasedness guarantees that estimates are unbiased in the original domain, which is ultimately the domain of interest; the Gaussian domain is simply an intermediate state for improving the efficiency of the estimates. As a rule in earth science applications, the multivariate distribution of the experimental data is unknown. Even the marginal probability distribution, inferred from the experimental histogram, is uncertain and thus functional back-transforms, such as that in Eq. An approximation given by The approach proposed in this paper comprises the following steps, as given in more detail in  For values that do not coincide with the experimental data the normal score value is estimated by linear interpolation:    The NLLF may be calculated for any value of The mean-PD is then a conditionally unbiased estimate and solves the kriging problem in the general case. There are, however, additional advantages of empirical maximum likelihood kriging: The posterior distribution provides more information about the possible values of the unknown random variable The posterior distribution provides the most realistic assessment of uncertainty of the estimates. There are various ways of assessing the uncertainty of the estimates from the posterior distribution, such as inverting the Gaussian confidence intervals, reading confidence intervals directly from the posterior distribution, calculating the variance of the posterior distribution or calculating confidence intervals using the likelihood ratio statistic ( EMLK2D is a Fortran-90 program for estimating point or integral values on a grid. The experimental data are assumed to have a point support but the program could be easily modified to deal with integrated experimental values. There is a main program, EMLK2D, and 10 external subroutines as shown in The first line contains the name of the file that contains the experimental data. The experimental data file must be an ASCII file with three columns separated by any number of blank spaces. The first column contains the The second line is the order of the drift. This is an integer value equal to 0, 1 or 2. The most common case is a drift order 0 in which the mean is assumed constant i.e. second order stationarity: Drift orders 1 and 2 represent non-stationary cases in which the mean is modelled by a linear or quadratic polynomial, respectively: A moving neighbourhood is defined for each location for which an estimate is required and only data inside that neighbourhood are considered. The fourth line is the maximum number of neighbours to be selected inside a given neighbourhood. The closest neighbours to the estimation location are chosen. The fifth line is the minimum number of neighbours and the sixth line is the radius of the circular search neighbourhood. A location with fewer neighbours than the number specified in the fourth line of the parameter file will not be estimated. The estimation grid is defined in the next four lines. The seventh line contains the coordinates of the first point of the estimation grid (location of the lower left corner, i.e. the most south-eastern location) in the The eleventh line contains the name of the file that specifies the covariance model for the normal scores. An example of a covariance model file is given in The name of the first output file containing the estimates (mean of the posterior distribution and maximum likelihood estimate) is specified in the twelfth line. The thirteenth line contains the name of the second output file that contains the estimation variances and confidence intervals (68% and 95% CI) provided by the three methods. In the penultimate line, 1 indicates that the posterior distribution for each estimation location is required. Note that each posterior distribution is estimated at 2401 discrete values and thus a large estimation will generate a very large output file. The name of the output file is POSTDIST.DAT. The final line contains a threshold value, Note that POSTDIST.DAT and POSTPROB.DAT are fixed file names and will be overwritten each time the program is run. If output files are to be retained they should be renamed. The format of the covariance (semi-variogram) model is shown in For each node of the estimation grid, the first output file contains: An example of the application of EMLK2D for a second-order stationary case is given in  The posterior distribution for location (10.0, 15.0) is shown in  Finally, Empirical maximum likelihood kriging offers a practical solution to the problem of efficient spatial interpolation overcoming the restrictions of linear kriging. Although linear kriging provides minimum variance unbiased estimates they are only the most efficient when the experimental data follow a multivariate Gaussian distribution. In all other cases, and particularly when the experimental data come from a skewed distribution, a transformation to normality is performed using the empirical cumulative distribution function. The advantage of this transformation is that there is no need for unverifiable distributional assumptions, i.e., no need to fit a parametric model to the experimental histogram. Although the transformation to a marginal normal distribution does not imply transformation to a multivariate Gaussian distribution, it is reasonable to assume that the data will be closer to that distribution than the original data and, in any case, the multivariate distribution of the data is indeterminate when only one realization of the random function is available. Using the normal scores, the covariance (or semi-variogram) is estimated and the negative log-likelihood profile can then be constructed. Finally, the posterior distribution is obtained via a Bayesian approach. This distribution contains all the information that is required for a complete estimation: point estimates, interval estimates, confidence intervals and measures of uncertainty. The more interesting advantages of empirical maximum likelihood kriging are: It provides the posterior distribution of the random variable, which should be the ultimate goal of estimation. The mean of the posterior distribution is the conditionally unbiased estimate of the variable in the original space. Other point estimates can be obtained together with interval estimates. Realistic confidence intervals are available by several different methods. The implementation of the approach in a computer program is straightforward and it will automatically deal with any underlying distribution without the need to fit a parametric model to it. Point estimates: mean-PD and maximum likelihood estimate. 68% and 95% confidence intervals calculated by inverting Gaussian confidence intervals. 68% and 95% confidence intervals from the posterior distribution. 68% and 95% confidence intervals from the likelihood ratio statistic. Estimation variance from the posterior distribution. The entire posterior distribution. The probability that the variable Finally, it should be noted that EMLK is not a multivariate Gaussian algorithm as demonstrated by the fact that the posterior distribution derived in the case study is not Gaussian. The work reported in this paper was funded by EPSRC (Engineering and Physical Sciences Research Council) Grant number GR/M72944.