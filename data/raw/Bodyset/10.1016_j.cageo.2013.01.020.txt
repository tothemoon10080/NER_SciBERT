Multiple-point geostatistics has opened a new field of methodologies by which complex geological phenomena have been modeled efficiently. In this study, a modified form of direct sampling (DS) method is introduced which not only keeps the strength of DS simulation technique but also speeds it up by one or two orders of magnitude. While previous methods are based on pasting only one point at a time, here the simulation is done by pasting a bunch of nodes at a time, effectively combining the flexibility of DS with the computational advantages of patch-based methods. This bears the potential of significantly speeding up the DS method. The proposed simulation method can be used with unilateral or random simulation paths. No overlap occurs in the simulation procedure because the bunch takes the shape of the empty space around the simulated nodes. Systematic tests are carried on different training images including both categorical and continuous variables, showing that the realizations preserve the patterns existent in the training image. To illustrate the method, a Matlab implementation of the method is attached to the paper.Complex geological scenarios pose many difficulties in the process of modeling and simulation. Meander channels in hydrocarbon reservoirs, post-mineralization phenomena in mineral deposits, complex underground water conduits and labyrinth secondary permeability in fractured reservoirs are some examples of such complexity. Two-point geostatistics ( One way to deal with the above mentioned complexities is to simulate the objects rather than points. Such methods are so called object-based methods ( Multiple-point geostatistical simulation was firstly introduced by Some unique features of the DS are its ability to work with multiple variables simultaneously, to use specific distances such as the transform-invariant distances ( In the next sections the method is described and evaluated with systematic tests. The performance of the proposed method in conditioning is tested with satisfying results. Patterns reproduction is examined for several training images, and validation is carried on using quantitative tools. Compared to original DS algorithm, this computational gain is found to scale linearly with the bunch size, without significant loss of quality in the results except for very large bunch sizes.           The DS method was originally developed by The idea of DS simulation is derived from To avoid repeating the description of DS simulation, the readers are referred to Define a random or unilateral path through which nodes are visited For each node under simulation do: Extract Using a random or unilateral path through which Based on the lag vectors by which If the dissimilarity is less than the minimum of distances which are calculated so far, store the central node's value of If the distance is less than the pre-defined distance threshold, assign the value of the central node of If the number of iterations is more than a pre-defined maximum, assign the training image's data event central node corresponding to the minimum distance. End of the simulation. In the original implementation of the DS algorithm, once a location is sampled in the TI, only one point is pasted at a time, which takes a lot of CPU time. In the proposed methodology, a “ In the DS, the scan of the TI can be seen as a search for appropriate nodes locations in the TI. When a suitable At first, a simulation path, unilateral or random, is defined through the SG. The methodology is illustrated in The The bunch shape is defined based on lag vectors (in the case of a bunch of size nine; Having pasted the first bunch of nodes, the Since searching the whole The used distance function depends on the type of variable under study. Although several types of distance have been proposed ( In the case of dealing with continuous variable the function changes into the following: Pasting bunch of nodes instead of one can deteriorate the conditioning capabilities of the DS algorithm. For this problem, one idea is that when computing the distance, one can use a different weight for each pixel in the data event. A larger weight for the pixels corresponding to conditioning data can be used. For example, if one of the pixels is a conditioning point, it counts 10 times more in the distance than the other pixels. This is also what is implemented in FILTERSIM ( In this study systematic tests have been carried out to assess the potential of bunch-pasting DS algorithm in simulating complex phenomena. This section briefly introduces the training images used, and then the corresponding realizations and the results are shown and discussed further. Six training images are used which are introduced and illustrated in     Training image  The major parameters of the TIs are summarized in This section shows and discusses the results of the bunch-pasting DS algorithm. Before going any further, and since many of the tests are done in a conditional simulation mode, the procedure to generate the conditioning data is described. One possibility is to keep the values but to randomize their location so that the samples are taken with the correct histogram. This procedure preserves the histogram, but not the variogram (or higher order measures) since the coordinates of samples are randomized. In order to keep both histogram and variogram, we first produce a non-conditional realization from the training image (using MPS methods), from which samples are taken. In this study, the MPS simulation method which is applied is DS in its original mode ( The input parameters of each realization may differ than the other one. In this regard the initial parameters used for each one is provided at the bottom of each figure that illustrates a realization using bunch DS. 20 realizations were produced conditioned to 100 conditioning data. One conditional realization is shown in The variability is expected to be reduced in the vicinity of conditioning data. To verify this, hard data are taken throughout the training image except for a gap zone in the upper-right corner (highlighted by a red rectangle in Bunch pasting DS algorithm is applied on TI  The performance of bunch DS for a categorical TI is checked in this section. An important issue in the field of Geophysical modeling and underground fracture detection is to produce realizations which honor the presence of known geobodies. For example, geophysical attributes are used to visualize channels, mounds, clinoforms, etc., in order to improve reservoir modeling ( In this In this TI all facies are interconnected. The realization produced using this TI is shown in The main advantage of using bunch-pasting is the CPU gain. Pixel-based and bunch-based DS simulations are compared in terms of CPU time, using the TI For validation purposes, a series of criteria are evaluated to compare the statistical properties of the simulations and those of the TI. These include the reproduction of histogram, variogram and connectivity, considering the TI as reference. Since bunch size is one of the most important factors in the bunch-DS algorithm, the reproduction of statistics of different orders should be analyzed when the method takes different bunch sizes for simulation. In all cases four bunch sizes are considered: 1, 9, 25 and 49. These validation tests necessitate a large number of realizations. Since we use a Matlab non-optimized implementation, in order to keep computing times reasonable the size of all training images and simulation grids are reduced to 150×150. All other settings are kept identical. Evaluating the reproduction of the histogram is done using continuous variable TIs In the case of TI In this section the reproduction of variogram is checked out and its sensitivity to bunch size is analyzed and for TIs The omnidirectional variograms are calculated considering different values of bunch size. Reproduction of connectivity and the distribution of geobodies area are evaluated using TIs TI The sensitivity of the algorithm to some of the input parameters is tested in this section. The four most important parameters are checked which are simulation path, bunch shape and bunch size. The sensitivity of these different parameters is evaluated using the different training images presented above, each time choosing the training image( In general the unilateral path produces better patterns which are due to the Markovian character of the simulation Three bunch shapes are considered: square, circle and disc, and for each of which one realization is produced. In this case we have used TI Similar as in the original DS method, the number of conditioning nodes considered The main parameter governing the method is the bunch size. Although this parameter has already been investigated in The first lag of the variogram (assimilated to the nugget effect) is used to represent small-scale noise. Moreover by increasing the bunch size, the size of Multiple-point geostatistical simulation has been a topic of interest in the last two decades. The existing algorithms are either pixel-based or patch-based. A new hybrid methodology is introduced that consists in pasting a bunch of nodes rather than one at a time. Our method is intermediate between pixel-based and bunch-based since the bunch size is flexible. The idea proposed in this paper is implemented in the DS method which allows such flexibility due to the absence of storage. The performance of the proposed method is checked with a series of TIs of both categorical and continuous variables. In all cases it can reasonably well reproduce the patterns that exist in the TI, although there is a general trend of decreased quality with increased bunch size. The most important contribution of bunch-pasting simulation is the computational gain it can offer with reasonable compromise regarding patterns reproduction or honoring conditioning data. Our tests have shown that the CPU time generally scales down in a quasi-linear fashion when the bunch size is increased. The significant reduction in CPU cost opens avenues for applications involving very large simulations. However, one may be cautious since bigger bunches just copy and paste the patterns existent in the TI. For this reason, very large bunches may result in artifacts in the simulations and lack variability. Based on the sensitivity analysis carried out in the paper, a bunch size between 9 and 25 is recommended which speeds up the DS by at least a factor of 10. Implementation of the bunch DS in C or C++, including parallel computing ( Most pixel-based methods are based on computing the probability of the value at the central node conditional to the neighbors. With bunch-pasting, this probability cannot be computed since it would be the joint probability of all pixels in the bunch. Therefore the bunch-pasting principle is specifically applicable with DS because no probability is computed. Instead a location is sampled in the TI, making it possible to extract a bunch around this location. This principle could not be used with methods storing probabilities, such as SNESIM or IMPALA. A Matlab implementation of the method presented in this paper is available for the readers. The authors would like to express their thanks to Sébastien Strebelle from Chevron Texaco for providing with TI