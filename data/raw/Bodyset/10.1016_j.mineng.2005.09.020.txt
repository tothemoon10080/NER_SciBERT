The efficient operation of any modern metallurgical facility depends on the accurate measurement and estimation of flow rates, inventories, and composition of their intermediate and final products. All of this information is subject to both statistical errors and gross errors, which can lead to poor estimation of efficiency, yields and specific energy consumption. The detection and the elimination of these errors require not only plant data, but also product transactions and the operational events. Once the gross errors have been eliminated, it is possible to estimate validated performance indicators, such as grade recovery or yields.
                  This paper describes the methodology to implement a unification and gross error detection system using the available infrastructure of both information and data reconciliation system. It covers the different infrastructure layers, from the data collection layer to the data validation and reconciliation layer. In addition, the impact of these methodologies on the decision-making process is presented.It is widely known that the analysis of plant performance requires validated information. Despite of the recent advances in data collection systems, it is still a challenge to implement a data validation system for process information, since raw data is still sensible to different sources of errors from wrong inputs on manually collected data to measurement errors from automatically collected systems. One of the biggest challenges for the analysis of operational performance is the acquisition, validation and reconciliation of process information. Validated and reliable information are necessary for the support of any business decision. Therefore, it is necessary to implement a reconciliation system that unifies and validates the plant data. This paper deals with the methodology to transform process raw data into accurate and valid information. In the case of the metallurgical industry, the data are collected from different processes units and their connecting flows and meters. The data might come from silos, piles, bins, mills, and laboratories data in case of chemical compositions. Due to the inherent nature of this data, errors can accumulate to cause serious inconsistencies. The objective of data reconciliation is to provide a methodology that eliminates gross errors while satisfying the conservation principles, such as mass and composition balance. This validated data is useful for yield accounting, process optimization, and process control. In addition, it improves the maintenance of meters and indicators by locating those that are working far from specification. The methodology to implement a data reconciliation system has several requirements. First, the algorithm that is able to balance and reconcile the plant data has to be robust and has to perform correctly against any process topology or configuration. In the past, several mathematical and statistical tools have been developed to solve the reconciliation problem. However, a mathematical algorithm without an information infrastructure is of little value. Second, the right infrastructure to connect the object oriented model to the real time process data has to be in place. A database that allows storage and manipulation of elements is necessary. The system has to adapt to changes in the process topology since, for example, a meter going out of service is enough to change the mass balance of a process network. Additionally, this object-oriented database should be able to communicate with the real time information system. Third, the real time system acts as repository of process data, both raw and reconciled, that allows the distribution of data to all plant staff, from the operators to the plant manager. Once the data is reconciled, a unique mass balance can be shared among engineers, accountants and managers. Another benefit of data reconciliation is the increase of valuable information, since the reconciliation system should provide mathematically observable process variables. These variables, such as composition or flows, are not measured directly due to technical difficulties or cost constrains. However, they are inferred from other variables using mass and composition balance. The operating cost of any mining operation relates to the amount of materials mined and handled. Profit is directly proportional to ore grade and its quality. Economic and technical considerations establish the optimum grade to optimize this profit. There are several studies that discuss the benefits for the integration of mine and mill operations. A critical problem in the process of ore extraction is the variability of the different elements that conforms the ore ( The typical problems with process data in industrial plants are: Overwhelming amount of data. Low confidence of the available data. Lack of consistency —“does not make sense”. Violates known constraints (mass and energy balances). Poor data quality creates decision-making “fog” at all levels in an organization and is a financial penalty. A real time information infrastructure emerges as the requirement to automate the collection, gross error detection and archiving of the information from the mining, controls systems, inventories, grades, departmental systems and ERP systems ( Disturbances in mine operations affect grade recovery performance. Many times the sampling occurs at the end of the process, when is late for any preventive change in the operation. A better understanding and prediction of process variables that affect the operation are needed. Materials and their compositions have to be tracked from their sources to plant inventories, such as silos and piles of materials. A consistent plant balance of total mass and composition, and a tracking system of the ore at every step in the process are needed. The tracking system should account for the discrete amounts of materials that are loaded to the piles. The use of balance and tracking systems allows estimating the compositions of important inventories that cannot be measured directly ( The data reconciliation and validation systems consist of a group of infrastructure tools that allow executing data reconciliation algorithms to produce a reconciled balance of the operation. Different processes and their connections can be modeled to create a connected collection of elements that composes a model. The model describes both the topology of the process and the measuring system. It should be able to describe any piece of equipment or process, such as mills, crushers, and concentrators. Another important element that can be described is the discrete amount of materials that are moved from the mine to the concentrator plant. Typically, these transactions have the properties of both events and flows, since they have a start time and end time but also convey a material in the same manner as process flows ( The other critical component of the reconciliation system is the group of business rules that analyze the plant topology and data. These rules can be conservation principles, such as conservation of total mass, composition or energy. In the case of grade recovery, the reconciliation of chemical composition of every process flow is necessary. In addition, these rules can describe the consumption of reagents or energy used in the different unit operations. The description of every process unit has to be ad hoc for the user. This description is done by creating attributes that specify every property of the element. For example, a mill has properties, such as ball load, rotating speed, material flow, and ball size distribution. Some of these data are static while others are a function of time. In addition, some attributes are arrays of information while others are integer or real numbers. All of these can be used to describe a piece of equipment of process. One other important point is that the values of these properties can reside in any information system or database. A universal infrastructure that allows the connectivity to any source is desirable for this type of modeling. Once the data is reconciled, it can be sent to the information system where it can be distributed to all the users, from operators to engineers and managers. The infrastructure of the data reconciliation system has to adapt to any changes to the process flow or the measuring system, since both process topology and data are not static. The following figure shows a model consisting of some analyzers and process units.  The user might review the data or connections in the model using this interface also. In addition, static tables of information that are used by the application can be created and configured. This information can be process parameters and equation coefficients, or any other information that does not change frequently. During the model setup and tuning, the tolerance of the measuring devices is entered into the model. Typically, this information is static; it does not change frequently as live data, which is entered automatically via interfaces to the real time system. Once the data is present and the tolerances have been established, it is possible to reconcile the data. The reconciliation algorithm estimates the best mass balance for the operation and provides statistical tests for every instrument. The mathematical method satisfies mass and composition constrains and provides the least amount of adjustment to the measurements according to their individual tolerances. Reports of instrument performance are valuable to prioritize maintenance in meters with gross error and bias. Sigmafine, a robust reconciliation system, was implemented in a copper concentrator plant. A model was built using the graphical user interface. The model represented every process unit and flow of the plant. After validation of the model, every attribute of the unit models was connected to the real time information system. The implementation of this general model was completed in a week at the plant site. After the tuning and validation of the model, the user was able to run reconciliations daily. Operational problems that affected the economic performance of the process were detected thanks to the correct operation of the reconciliation system ( Each analyzer contained the metal compositions for the period of analysis. The model was run daily to produced reconciled reports. In addition, the reconciled data was sent to the real time information system where it was available to engineers and managers.  The following steps define the process for building a plant mass balance: Define the transactions, nodes and equipment components (stockpiles, reactors, separators, mixers, tanks, nodes, etc.). Define the streams (feeds, intermediates, products, tails, reagents, utilities, water, etc.). Configure the process flow diagram from a business perspective. Define connectivity to access the data, and in this case, the analysis framework is used to develop a process flow diagram connecting flow meters, tank inventories, stockpiles and composition analysis for the defined streams. A plug-in for data reconciliation and gross error is used to perform the calculations. The user interface allows the user to create elements graphically, in the same way that an engineer develops a process flow diagram using computer-aided design (CAD) software. The element properties, defined in the template, are available for the user at run time. Data from by different sources can be monitored using the different connectors for each data source. Data transformed by analysis rules is also available in the element property list. In the case of gross error and data reconciliation, reconciled and validated data is written to the element properties and are marked as analysis outputs, which help the user to distinguish between raw and analyzed data.   Additional implementations of hydrometallurgical processes are in production enabling the analysis of leaching, solvent extraction efficiency, electrowinning and cathode production. All process variables, events, grade are registered and transformed into actionable information. Real time based costing emerges as a reporting exercise when the proper application framework for real time information management is used. This integrated approach enables collaboration between operations, engineering, accounting and management to drive the organization’s bottom line according to their business strategy. At the same time, personnel can look for opportunities using alternative processing methods and strategies. Integration of metallurgical complexes is a reality. Companies are using integrated information architecture as a strategic investment for enabling agile operations. Making profitable, intelligent business decisions is a complex process, made easier using a real time performance management (RtPM) strategy. Thanks to the speed and ease of the integrated system, users increased the frequency of closing their balances, from month to daily, without an increase in personnel. Different groups can collaborate and solve production problems. The reduced number of hours required for their daily closing enables the team to increase time available for analysis and continuous improvements. Manual data entry is reduced and data is transformed into information by using data aggregation tools which use time weighted averages and statistics. Plant wide reporting is simplified for analysis of products and raw materials processing and movements. The generation of production and inventory reports is made with consistent information. The additional analysis provides benefits in identifying re-instrumentation studies, analysis of existing instrumentation and sampling. Uncertainty in calculating unmeasured flows and losses is reduced. The results can be summarized as follows: improved quality and speed of plant diagnosis, optimizing plant overall process effectiveness (production, quality, costs, availability, environmental and safety), extended plant availability, improved production and regulatory information.