A good domain name can help a company rapidly increase their brand awareness, attract more visitors, and therefore obtain more customers. Due to the exponential increase in the number of domain names, registrants are often frustrated because their preferred domain names are already taken. In order to enhance registrants’ satisfaction and efficiency, as well as to increase the revenue of registrars (e.g. GoDaddy, Yahoo, Squarespace), it is important to suggest alternative domain names that are available. The first step is to detect registrants’ needs by classifying the attempted domain name to one of the categories.
                  This study is the first that defines the problem of domain name classification, which classifies a registrant’s preferred domain name into pre-defined categories. The paper proposes deep neural networks with subword embeddings that are built in multiple strategies. We build embeddings for character n-grams of a domain name by learning from training data, learning from external corpus, or learning from external corpus and adjusting based on training data. The experiments show that the proposed methods significantly outperform the baselines.Domain names have been at the forefront of the digital experience for decades. They provide the real estate for businesses to build their online presence and provide doorways for their customers to find them ( Indeed, the domain name industry is a billion-dollar industry because of the competitiveness involved in securing the perfect domain name. Stories abound of domains that were purchased for $8 dollars 15 years ago being sold today for millions ( With the explosive growth in the number of domain names, preferred domain names are often already registered. According to a white paper ( In the cases that the preferred domain names are not available, to assist the registrant to find an available name quickly and easily, registrars recommend alternatives that have not been taken yet, by adding a prefix and/or suffix, editing words, and/or changing the TLD of the original requested domain name. To generate highly relevant recommendations, registrars must well understand the needs of registrants by analyzing the preferred domain names. To understand a domain name query for further transforming it, one intuitive way is to classify it into one of the pre-specified topical categories, such as business, sports or arts. The outcome can be used for downstream processors to make the preferred domain names available: For example, a set of modifiers pre-defined in the category can be used to transform the domain name. For instance, a good classifier correctly assigns However, accurate topical classification of domain names is highly challenging for several reasons. First of all, when a domain name is requested, the actual website is not available yet. Thus, the meta-data of the website, such as description, traffic, and registration information, are not available. The only information that can be utilized is the requested domain name itself. Second, domain names are extremely short, and thus are ambiguous in nature. Since shorter domain names are more memorable to customers, domain names are designed to be as concise as possible: most domain names have only 1–3 tokens (after word segmentation), making it challenging to identify the meaning. For example, it is hard to tell whether desktopsolutions.net is a website selling desktop furniture or providing IT services. Third, domain names usually contain noise. For example, in To accurately classify domain names, we propose utilizing the subword (i.e., character n-grams) information of the domain names. With well-represented subword semantics, we propose deep neural network-based models. In particular, the input of the models is a domain name which is segmented into tokens. The subword information of each token is modeled by latent vectors (i.e., embeddings). The subword embeddings are aggregated to represent the semantic of each token. Fed with token semantic representations, domain name semantic representation, and the TLD, a Recurrent Neural Network (RNN) ( With our models, to make recommendation based on these domain names, in practice, a recommender system can rank the possible categories of a user-submitted domain name by the predicted probabilities. The recommendation list can include recommended domain names from all of the first several highest categories. For example, the predicted probability distribution of “desktopsolutions.com” is 60% for Computer and 40% for Home. Modifiers in both categories alter this unavailable domain name into a list of available domain names. These new domain names can be ranked by the product of the confidences of each modifier and the predicted classification probabilities. Hence, the recommendation result can consist of new domain names from both categories. Those from the Computer category might be ranked higher than those from the Home category. This work will benefit both users and firms on the sell side of the domain name registration. Users can receive more relevant alternative domain names. The firms can obtain more revenue by selling more domain names. In addition, the proposed method can also be applied in phishing website detection (given the assumption that whether a website can be malicious can be partially told by its domain name). Being fed by a large scale of labeled data on phishing detection, the proposed model can classify domains into one of the two categories: Malicious or Benign. The contributions of our paper are as follows: 1) We define a new research problem, topical classification of domain names. It can significantly benefit domain name recommendation, currently a billion-dollar industry: A user-submitted domain name is classified by its topic. A set of domain modifiers specific to each category can be then triggered to alter the original domain name. As a result, a topical classifier of domain names can suggest available domains that users may would like to purchase. A good solution may reduce users’ effort to find available domains and boost domain name registrars’ revenue. 2) Due to the polymorphism and noisiness in domain names, we propose to use character-level RNN-based and CNN-based models, which have been used in text classification tasks. To better capture the semantics of domain names, we propose to compute abstract representations for both the domain names tokens and the entire domains. 3) We evaluate our models on a publicly available dataset. The results show that our models significantly outperform the baselines. 4) Besides domain name recommendation, the proposed method can also benefit other fields, such as Internet security, in which malicious websites can be detected from the links and domains. The rest of the paper is organized as follows: Section To the best of our knowledge, none of the existing work focuses on topical classification of domain names. Several existing studies attempted to classify Uniform Resource Locators (URLs) into categories in two main applications. One of the main applications of URL classification is to detect malicious or phishing websites based on their URLs without accessing the content of Web sites. Thus, it eliminates the run-time latency and the possibility of exposing users to the browser-based vulnerabilities. The work ( The other application is identifying the topic of a webpage merely based on its URL. In contrast to the existing work of URL classification, domain name classification has several characteristics as following: Compared to a domain name, which is a just part of a URL, a URL contains more information about a web page: A URL has more text in the sub-directory part (refer to URLs have significant patterns, especially URLs under the same web site. For example, a web page about news may follow patterns, like In the application of domain name recommendation, users submit the domain names that they want to register. Since the web sites with the domain names do not exist yet, external domain name features utilized in Extensive studies have proposed to applied deep neural networks to solve natural language processing problem. Based on how the input words are processed, existing studies can be categorized in three groups: word-level, character-level, and hybrid.  Generally, word-level representations directly capture word semantics from training corpus. However, it requires a large vocabulary. It is not able to handle out-of-vocabulary words. On the other hand, character-level representation can handle unseen words. It is also insensitive to word morphology. However, it may have large computational cost, as character-level representations have to be aggregated to the word-level. Deep learning has been used in many NLP applications, such as news classification, sentiment analysis, and machine translation. However, as far as we know, there is no existing studies on topical classification for domain names. In our study, as a domain name is no longer available for registration once it is ready taken, many domain names contain variations, abbreviations (e.g., “med” for “medicine”), fillers (e.g., “abc”, “123”), and/or word stems (e.g., affixes). Therefore, relying on word-level representation leads to low classification performance due to out-of-vocabulary words and noise. In addition, domain names are extremely short. Most domain names have only 1–3 tokens. Thus, it is not meaningful to use more advanced models, such as Long Short-Term Memory (LSTM), attention ( There are multiple systems of terminology for URLs. To make it clear, below is the one used in this paper. A typical URL contains a  Domain names are first segmented by dots among subdomains, root names, and top-level domains (TLD). Subdomains and root domains may consist of multiple words which are sometimes concatenated without any delimiters, e.g., “aboutit”. Thus, a non-trivial method should be applied for word segmentation. The segmented words are referred to Besides tokens, our proposed model also takes In this project, we use a publicly available dataset, i.e., the Open Directory Project (ODP) DMOZ dataset, As discussed earlier, topical classification of domain names is highly challenging. To address it, we have several observations. First, domains are extremely Second, domain names are Third, top-level domains (TLD), e.g., com, edu, and org, sometimes indicate the topics. For instance, “columbia.edu” is the official website of Columbia University, while “columbia.com” is linked to a sportswear company. The TLDs can help distinguish them. Due to large variability in domain names, we propose to capture subword semantics, instead of directly capturing the meaning of a token as a whole. The main reasons are 1) Domain names usually contain abbreviations. A number of abbreviations are subwords of the original words, e.g., “med” is short for “medicine”. Directly building embeddings for entire words may not be able to handle unseen abbreviations in test data. 2) Registrants often attach affixes to a word stem to form an available domain name. Using subword embedding can reduce the impact of these affixes. The meanings of subwords are filtered and aggregated for the entire token. However, it is not evident how subword embeddings should be combined to a token. Surprisingly, simply averaging word embeddings of all words in a text has proven to be a strong feature across a multitude of tasks ( Subword embeddings have been proven to be effective in fastText. FastText represents the meaning of words by unsupervisedly learning low-rank vectors from a large textual collection. The vector of a word is obtained by summing vectors of the char n-grams appearing in the word. In this case, unlike Word2Vec ( In this project, we investigate several ways to learn subword embeddings and evaluate them empirically. The first method is to initialize the subword embeddings as what we do for other parameters. Random initialization ( The second approach to learn subword embeddings is to train the model on an external corpus. A model is trained on a Wikipedia dump ( The third method is to use the embeddings that are learned from the external corpus in the previous method to initialize the subword embeddings, and then further update the embeddings during model training. In the experiments, an RNN model and a CNN model with such initialized subword embeddings are denoted as Since each method has pros and cons, it is not clear which one best fit our application. Thus, in the experiment, we evaluate all three strategies by comparing the end performance of classification built upon them. To extract the subwords, domain names need to be segmented. Domain names are first segmented into a list of tokens. For each token, we extract the subwords. A domain name may contain a combination of numbers, letters, and hyphens. It is also allowed to use multiple instances of hyphens, but not a double hyphen. Other forms of punctuation, symbols or accent characters cannot be used. Therefore, a domain can be first segmented by periods and hyphens. For instance, the root domain part of Word segmentation is an essential natural language processing step in the languages (e.g., Chinese and Japanese) wherein words are not delimited by spaces. A common practice is training a statistical model to decide where the word boundaries are. In this project, we use a publicly available API, wordsegment ( Each token of a domain name is then split into subwords (i.e., char n-grams). The semantics of the subwords are represented by subword embeddings discussed in Section All subword embeddings of a domain name is fed into a neural network based model. The model classifies the domain name into one of the topical categories. This paper propose two types of models: RNN-based (Section An RNN is a class of neural networks that can handle sequences with variable lengths. Mimicking human reading behavior, RNN reads through the input text from left to right and finally generates a low-rank vector to represent the semantics of the entire input text.  In addition, it is observed that the segmentation module may mistakenly segment domains because domains may contain non-regular English words and/or unseen words. For instance, in the example of Due to the sparse semantic carried by domain tokens, multiple fully connected layers are stacked to better abstractize and enrich the features. To alleviate overfitting, we add a dropout layer after each fully connected layer. Dropout ( It is also observed that domain names are usually Therefore, a CNN-based method is proposed to overcome this issue. A Convolutional Neural Network (CNN) (  As introduced in Section 90% domain names are assigned to the training set, while the rest of the domain names are randomly and equally assigned to the validation and test set. In other words, the ratio of training, validation and test sets are 18:1:1. The validation set is used in the early stopping strategy in order to avoid overfitting: At the end of each epoch, the model obtained in the epoch is evaluated on the validation set. The model with the highest F-score is stored on disk. The total number of epoch is set to be 60. After 60 epochs, the model on the disk got the best performance. It is finally used to predict the test dataset. The experimental results are reported by threefold cross-validation. Classification models are implemented in Python. All neural networks are implemented in TensorFlow. The training process is accelerated by NVIDIA GeForce GTX 1060. The CPU processor is Intel Core i7. The RAM is 32 GB. We experimented with different parameters for the deep neural networks. Below are the parameter combinations that lead to the best classification performance. The RNN model outputs 300 hidden neurons. The CNN model has one convolutional layer with 512 filters and one max-pooling layer. The dropout rate and the learning rate of both kinds of models are 0.5 and 0.001, respectively. We use three fully connected layers, each of which has 300 hidden neurons. The models are trained through 40 epochs with batch sizes of 512. Early stopping is adopted to avoid overfitting. The model snapshot with the lowest validation log-loss is stored on the disk. The test dataset is only predicted using the best model found on the validation data. The variants of the neural network-based methods are compared with several baselines below:   Through experiments, we consider 4–5-6–7-8-grams, which lead to the best performance. We first conduct experiments to evaluate the performance of the proposed classifiers. Since the size of each topical category significantly varies, we use precision, recall, and F-score as the evaluation metrics. In addition, we also use accuracy (with 0.5 as the decision threshold) to give us a more intuitive indicator of the classification performance. The precision is the fraction of the test domains labeled that are correctly labeled. The recall is the fraction of the domain names in a category are that correctly labeled. F-score is the harmonic mean of precision and recall.  According to the result, the token-based method performs the worst because it only considers tokens extracted from tokens. As a result, its feature vectors are highly sparse. Domains have little chance to share the same tokens. The char n-gram based method performs much better; it uses one-hot encoding to model subword information. In contrast to the token-based method, it can better identify domain names which share the same words with variants. As mentioned previously, word variants are common in domain names because two domain names cannot be the same. Identifying domain names with the same word stem is highly important. We initialize the subword embeddings in different ways: 1) “random”: The embeddings are randomly initialized; 2) “initial”: The embeddings are initialized by the char-gram embeddings learned from the Wikipedia dump. The embeddings are adjusted during model training; 3) “frozen”: The embeddings are initialized by the char-gram embeddings learned from the Wikipedia dump. They are frozen during model training. The result shows that, with frozen embeddings, RNN-frozen is not as effective as CNN-frozen. The reason is that the output of RNN takes all char n-grams into account. However, the signal-to-noise ratio of domain names is often low. For instance, chances are one out of two that a word in a domain name is irrelevant to the topic of the website. Thus, RNN may mistakenly include noise. In contrast, the pooling layer in a CNN is able to ignore the least significant signal. The CNN with frozen subword embeddings performs the best. Randomly initializing the subword embeddings does not lead to good performance. The reason is that it is highly difficult to learn char n-grams semantic representation completely from scratch on the domain name dataset because there are tons of unique subwords. The ODP dataset is not large enough for neural networks to fully capture subword semantics. On the other hand, Wikipedia contains subwords with sufficient occurrence. Thus, embeddings built upon Wikipedia can capture meanings more accurately. Also, Wikipedia covers more unique subwords so that “CNN-initial” and “CNN-frozen” have less unseen subwords in the test data. In addition, it is interesting to see that freezing the subword embeddings learned from Wikipedia outperforms making the embeddings trainable, i.e., “CNN-initial”. To minimize the log-loss on the training data, the deep neural networks may overfit and thus deviate the subword embeddings that are learned from Wikipedia. We also present the impact of different filter sizes, the numbers of hidden neurons in the fully connected layers, and the dropout rates. We first vary the filter sizes of the proposed CNN models from 128 to 1024. Similar to other parameters in deep neural networks, the filter size is trade-off between under-fitting and over-fitting: The larger the filter size is, the higher complexity of the model has and the more likely it is that the model overfits the training data. The results in We then vary the number of hidden neurons in the fully connected layers from 100 to 500. The results in We finally try different dropout rates from 0% (i.e., no dropout) to 75%. The higher the dropout rate is, the stronger regularization the model has. The results in In some business scenarios, accurately classifying a domain name into one single category may not be necessary. For instance, given a user input domain name, a domain name recommendation system may not return available domain candidates from only one category, but candidates from multiple categories. As accurately classifying a domain name is highly challenging, enhancing recommendation diversity can minimize the risk. For example, a user submits Therefore, besides classification metrics, we also evaluate our models using ranking metrics: Mean Reciprocal Rank (MRR) and Average Rank. The mean reciprocal rank is a statistical measure for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness. The reciprocal rank of a query response is the multiplicative inverse of the rank of the first correct answer. Eq. Since MRR only cares about the single highest-ranked relevant item, it is suitable for our problem where only one out of 13 categories is the true label of a given domain name. The higher the MMR, the better the model. In addition, as a more intuitive metric, average rank is the mean of the true category in the prediction of all test domain names. Therefore, the lower the average rank, the better the model. A classifier with an accuracy of 1 has an average rank of 1. The worst classifier has an average rank of 13 (13 categories in total).   It is interesting to see that the performance in each category is correlated with the size of the category. The Pearson’s R between the count and the recall is 0.755. This is a strong positive correlation, which means that large category size goes with high recall scores (and vice versa). In addition, there is a weak negative correlation between category size and precision scores (Pearson’s R = −0.0957). This is reasonable because a classifier may learn larger categories better and tend to assign more large category labels. Thus, the recalls of large categories are high. In this case, their precision may be inevitably hurt. As a result, the Pearson’s R between F-scores and the category sizes is 0.6094. This is a moderate positive correlation. Hence, generally speaking, the classifier performs well in large categories.  The result shows that “Business” is the most “popular” category in the prediction results. This is the main reason why its recall is the highest in The “Home” category is one of the smallest categories. Example domains in this category include The domain name service is a billion-dollar industry. In order to suggest relevant and available alternatives to registrants, it is important to understand the topic of the preferred domain name initially submitted. The proposed method can be used as the first step of domain name recommendation. The classifier identifies the user intent by assigning the user-submitted domain names into one of the pre-defined topical categories. The cost of the mis-classification can be significantly reduced by diversifying domain recommendations. Recommended domain names from different categories can be ranked by the predicted relevance. Top domains from diverse categories can be all shown on the first page. In this case, even if the most possible category is incorrect, users may still see relevant suggestions in the rest of the return list. The proposed method can improve user intent identification so that the correct sets of modifiers can be later triggered. The outcome can reduce users’ effort of searching for relevant and available domain names. Also, it may boost domain registrars’ revenue. This paper addresses the problem of domain name classification, which is a critical part of domain name understanding. We propose to utilize subword information, and design deep neural network-based models to assign a domain name to one of 13 topical categories. We also propose three strategies to compute subword representation. Experimental evaluation verifies the effectiveness of our proposed models. The CNN with frozen subword embeddings learned from Wikipedia performs the best.  The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.