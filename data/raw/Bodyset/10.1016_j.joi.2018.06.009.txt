We have studied the efficiency of research in the EU by a percentile-based citation approach that analyzes the distribution of country papers among the world papers. Going up in the citation scale, the frequency of papers from efficient countries increases while the frequency from inefficient countries decreases. In the percentile-based approach, this trend, which is uniform at any citation level, is measured by the e
                     p index that equals the Ptop 1%/Ptop 10% ratio. By using the e
                     p index we demonstrate that EU research on fast-evolving technological topics is less efficient than the world average and that the EU is far from being able to compete with the most advanced countries. The e
                     p index also shows that the USA is well ahead of the EU in both fast- and slow-evolving technologies, which suggests that the advantage of the USA over the EU in innovation is due to low research efficiency in the EU. In accord with some previous studies, our results show that the European Commission’s ongoing claims about the excellence of EU research are based on a wrong diagnosis. The EU must focus its research policy on the improvement of its inefficient research. Otherwise, the future of Europeans is at risk.Production and cost analysis plays a central role in the management of all productive systems, because it is the starting point for obtaining better and more profitable products. Research is also a productive process, for which production and costs should likewise be analyzed in order to improve its societal benefits. However, there are multiple examples of countries’ research policies that are established without any production and cost analysis, either on the assumption that research is always profitable or taking for granted conclusions about its output that have never been demonstrated. The most remarkable case of the latter is the research policy of the EU. For a long time, it has been held that the EU’s technological weakness lies in its inferiority in transforming scientific breakthroughs and technological achievements into industrial and commercial successes; this has been known as the “European paradox” ( Currently, two main documents have been produced to give support to the new EU research program that will substitute for Horizon 2020: the “Interim Evaluation of Horizon 2020” ( One factor that might explain the reluctance of the European Commission to accept the academic findings could be the complexity of academic approaches. To solve this problem a recently developed approach based on the well-established percentile apportionment method ( By using these two new mathematically based indicators, this study aimed to answer the question of whether research in the EU is excellent, as proposed by the European Commission, or weak, as proposed by several academic publications. Furthermore, we centered this study on technology, performing bibliometric searches on the research topics that support technological advancements in the forefront of knowledge. The question addressed in this study is whether the research excellence of EU research that is assumed by policy makers is actually true. Since 1995, when the existence of a “European paradox” was proposed ( In scientometrics, references to excellence are very frequent (e.g., Consistent with this fuzzy concept, a publication from the EU’s Joint Research Center entitled “Composite Indicators or Research Excellence” ( Moreover, the use of the number of highly cited publications as an indicator of research excellence underlays the assumption that research excellence equates to a high scientific impact. However, although this impact may be estimated from the number of highly cited papers ( In the aforementioned European Commission documents, the 10% percentile is selected to measure research excellence ( In addition to the complex issue of the citation or percentile threshold from which excellence should be established, another issue is that although, in principle, excellence is a size-independent concept, its evaluation by some methods is size dependent ( This variation can easily be demonstrated because the distribution of publications in percentiles follows a simple power law function that fits a wide range of percentiles ( Finally, dividing by To solve this conundrum about the meaning of research excellence and the difficulties of its quantification, we propose to associate excellence with efficiency, which does have a quantitative meaning. However, this association implies neither a link with productivity—as in “Productivity is the quintessential indicator of efficiency in any production system” ( Also important for the purpose of our study is that our definition of excellence in terms of To measure the The The proportion the world’s discoveries or breakthroughs achieved by a country depends on two terms, the size and In addition to the Given the considerations described above in this section, the P In several publications and rankings the P To obtain a preliminary assessment of the level of research in the EU from published data, we calculated the P In advanced technological nations, universities play a central role in country’s research ( Although interesting, the results shown in In both cases, these discrepancies occur because EU research is not homogeneously weak; it is competitive in areas of slow growth and uncompetitive in hot technological topics ( These observations indicate that in order to obtain a reliable diagnosis of the EU research system our study has to analyze hot and quiescent areas independently without averaging the results. On the other hand, the most relevant studies should be performed in technological fields that are the most likely to produce the breakthroughs that support the knowledge-based economy. This notion is summarized with the sentence “The sort of research that matters is thus the kind that can deliver high financial returns through scientific breakthroughs and their commercialization” (Sorensen et al., 2016, p. 224). Therefore, in the first place, we identified research topics at the forefront of technological research. For this purpose, in a preliminary study we identified 14 fast evolving technological topics (hereafter referred to as FETT) from among a large number of research fields by their high citation rates and current technological importance. These topics were: graphene, solar cells, nanotechnology, electronics, Li Furthermore, because it is known that EU research is weak in several of the selected FETT ( The worldwide number of articles in FETT and SETT were very similar, 194,147 and 180,196, respectively, in 2014. In contrast, citation distributions were very different. For example, in SETT articles, only five (0.003%) received more than 300 citations while in FETT articles, 207 (0.1%) exceeded that number of citations (searches on January 5, 2018). For this number of articles the use of the P’ For the purpose of our study we divided the world into three geographical research areas: ERA, USA, and Others (i.e., all countries excluding ERA and USA). These areas were analyzed independently, omitting collaborative publications between them. In addition, in view of the large differences that exist in research between Switzerland or the UK and other ERA countries ( Bibliometric searches were performed in the Science Citation Index Expanded of the Web of Science Core Collection (WoS), using the “Advanced Search” feature and retrieving only publications labeled as “Articles” (this implies that review publications are not counted). For FETT we used: TS=(energy transfer OR fuel cell* OR quantum dot* OR composite material* OR transistor* OR semiconductor* OR superconductor* OR graphene OR batter* OR solar cell* OR electronic* OR nano* OR metal organic framework* OR wireless). For SETT we used: SU = ((mechanics OR engineering OR materials science OR energy & fuels OR electrochemistry OR robotics OR metallurgy & metallurgical engineering OR automation & control systems OR instruments & instrumentation OR operations research & management science OR telecommunications) NOT computer science); we used the Boolean operator NOT to exclude FETT. We determined the number of publications in nine percentiles: 1, 2, 4, 7, 12, 20, 35, 60, and 100% by ordering publications according to their number of citations. The ordering of publications with the same number of citations was that provided by the database. To assign countries’ publications at a specific world percentile we used the worldwide and country lists provided by the database and the number of citations to determine the country percentile limits. When the threshold occurred in a series of publications with the same number of citations both in the world and in the country, the country’s threshold was situated by the proportional method as described previously ( For fractional counting, the downloaded publications from WoS were fractionally counted based on country’s author affiliations. In a few cases, we found authors with affiliations in two countries and we counted these papers as fractional = 1 for both countries. However, we investigated this issue and found that it is irrelevant. Even in Singapore, where we found the highest number of double affiliations, counting a paper as either 1 or 0 had irrelevant effects for the purpose of this study. All percentile-based citation distributions were analyzed by fitting to power laws as described previously ( Although the Finally, for publications funded by the ERC (European Research Council) we used the tag FT = ERC. To determine the research performance level in Europe, we calculated the In FETT publications ( Using the In SETT publications ( Taken together the results revealed an alarmingly low level of technological research in the EU, especially in FETT, where the Attending first to the Attending to the P' To show country differences independently of their size, According to several documents from the European Commission, ERC funded projects are at the forefront of research excellence. For example: “As shown by the interim evaluation of Horizon 2020, the ERC has become a global beacon of scientific excellence” ( The remarkable increase in the Our study aimed to demonstrate the weakness of research in the EU. For this purpose we used of the Future studies applying the same approach might reveal different findings in other research fields such as, for example, biomedicine, astrophysics, or particle physics. Taking as a reference point a value of the Also disappointing are the In SETT the EU research performance is better than in FETT, but here too the values of the The assumption that “the ERC has become a global beacon of scientific excellence” ( In summary, our results, which use an indicator that has a mathematical definition and that is based on the existing correlation between highly cited papers and important breakthroughs ( The status of technological research in the EU that we have described is overwhelmingly dire because not so long ago Europe was a beacon of progress. At the end of the 19th century Europe was an indisputable scientific and technological leader: “There is a dynamism about nineteenth century Europe that far exceeds anything previously known. Europe vibrated with power as never before: with technical power, economic power, cultural power. Its prime symbols were engines―the locomotives, the gasworks, the electrical dynamos” ( Although the causes of this scientific decline deserve specific studies, it is hard to believe that something other than research policy is the cause of this decline. More than 10 years ago, two academic studies called attention to this decline: “the European picture shows worrying signs of weakness with respect to the generation of both scientific knowledge and technological innovation” ( Before trying to find an explanation for the weakness of technological research in the EU, it is worth noting that in slow evolving scientific fields, research quality in the EU and the USA is similar. This similarity has been demonstrated by double rank analysis in “plant sciences” ( Considering the complex mechanisms through which researchers bring about scientific progress ( In addition to this risk avoidance, the presumption of EU research excellence by the European Commission might have also promoted weak performance at the leading edge of knowledge in some countries. In the first place, this is because some national governments have internalized this assumption, reducing their interest in boosting research—why improve what is already excellent? In the second place because amid the euphoria about excellence the European Commission has failed to develop its member countries’ research surveillance. The case of Spain provides an example: its traditionally low investments in academic research suffered a 50% reduction due to the economic crisis, which has produced a very significant dismantling of the research system that had been developed over more than 30 years. The reconstruction of the system will cost far more than the money saved and will take many years. Incomprehensibly, although Spain is a recipient of cohesion funds, this research policy was never censored by the European Commission. An unlucky explanation for our results is that the distribution of the As described above in Sections A high number of empirical studies have demonstrated that innovation entails much more than research but also that innovation depends on novel knowledge (e.g., The question which then arises is whether the EU can compete with other countries that produce much more efficient research. Although the answer to that question is not within the scope of this study, it is highly probable that the poor performance of the EU in technological research has had an important influence on innovation and competitiveness. Taking into consideration the low values of the Even if the reasons for the EU’s record of weak innovation were in doubt, it should not perform the experiment of maintaining the current low research efficiency expecting to find out that innovation can be improved by other means. It is obvious that some non-EU countries are not going to stop improving their own research systems while they wait for the end of the EU experiment. Research activity in Singapore was insignificant 25 years ago, but over this period its output of papers has increased 25 times and, much more importantly, it now seems to have the highest level in the world on the It follows from these considerations that the EU should increase the efficiency of its research. Thus, the statement: “It is essential – also as a strong signal to the rest of the world – that both the EU and its Member States finally undertake to reach the 3% target of GDP invested in R&I” ( Making the analysis of research profitability more complex, effectiveness should also be considered. This issue can be summarized in the following question: Does the EU investigate what it needs? As discussed above (Section Because most, if not all, of its problems with research seem to derive from “wrong diagnoses and misguided policies” as detailed more than 10 years ago ( None. Alonso Rodríguez-Navarro: Concieved and designed the analysis; Collected the data; Contributed data or analysis tools; Performed the analysis; Wrote the paper. Ricardo Brito: Concieved and designed the analysis; Collected the data; Contributed data or analysis tools; Performed the analysis; Wrote the paper. We thank an anonymous reviewer for suggesting the term